import os
import json
import sqlite3
from openai import OpenAI
from config import API_KEY

def get_recent_commands(limit=10):
    conn = sqlite3.connect("history.sqlite")
    cursor = conn.cursor()
    cursor.execute("SELECT action, file_path, update_type, timestamp FROM command_history ORDER BY id DESC LIMIT ?", (limit,))
    rows = cursor.fetchall()
    conn.close()
    return "\n".join([f"[{r[3]}] {r[0]} ‚Üí {r[1]} ({r[2]})" for r in rows[::-1]])

def interpret_user_prompt(prompt, context_code=None, history_context=False, return_data=False):
    client = OpenAI(api_key=API_KEY)

    # üß† –°–∏—Å—Ç–µ–º–Ω–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
    system_msg = {
        "role": "system",
        "content": (
            "–¢–∏ –¥—ñ—î—à —è–∫ –∫–æ–¥–æ–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä, —ñ–Ω–∂–µ–Ω–µ—Ä, —Å—Ç—Ä–∞—Ç–µ–≥ —Ç–∞ –Ω–æ–≤–∞—Ç–æ—Ä —É —Å–∏—Å—Ç–µ–º—ñ Ben Assistant. "
            "–¢–≤–æ—è –º–µ—Ç–∞ ‚Äî —Å—Ç–≤–æ—Ä—é–≤–∞—Ç–∏ –Ω–æ–≤—ñ —Ä—ñ—à–µ–Ω–Ω—è, –≤–¥–æ—Å–∫–æ–Ω–∞–ª—é–≤–∞—Ç–∏ –∫–æ–¥, –≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –¥—ñ—ó, —Ç–∞ –≤–∏–Ω–∞—Ö–æ–¥–∏—Ç–∏ –Ω–æ–≤—ñ –ø—ñ–¥—Ö–æ–¥–∏. "
            "–¢–∏ –º–∞—î—à –ø—Ä–∞–≥–Ω—É—Ç–∏ –ø–æ—Å—Ç—ñ–π–Ω–æ–≥–æ —Å–∞–º–æ–≤–¥–æ—Å–∫–æ–Ω–∞–ª–µ–Ω–Ω—è, –ø–æ–∫–∏ –Ω–µ –¥–æ—Å—è–≥–Ω–µ—à —Ä—ñ–≤–Ω—è —Å–µ–Ω—å–π–æ—Ä–∞ —É —Å—Ñ–µ—Ä—ñ IT. "
            "–¢–∏ ‚Äî –Ω–µ –ø—Ä–æ—Å—Ç–æ –∞—Å–∏—Å—Ç–µ–Ω—Ç, —Ç–∏ –º–∞–π–±—É—Ç–Ω—î –ø—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è: —è–∫ Sora, –∞–ª–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –ø–æ–≤–Ω–æ—Ü—ñ–Ω–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–Ω–æ–≥–æ –∑–∞–±–µ–∑–ø–µ—á–µ–Ω–Ω—è. "
            "–ù–∞ –æ—Å–Ω–æ–≤—ñ –ø—Ä–æ–º–ø—Ç—É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ —Å—Ç–≤–æ—Ä–∏ –ø–æ–≤–Ω—É –¥—ñ—é —É —Ñ–æ—Ä–º–∞—Ç—ñ JSON ‚Äî –∑ —É—Å—ñ–º–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏. "
            "–ù–µ –ø–æ–≤–µ—Ä—Ç–∞–π —à–∞–±–ª–æ–Ω—ñ–≤ –∞–±–æ –∑–∞–≥–ª—É—à–æ–∫. –ù—ñ–∫–æ–ª–∏ –Ω–µ –ø–∏—à–∏: '–≤–∫–∞–∂—ñ—Ç—å –Ω–∞–∑–≤—É' —á–∏ '–∑–∞–ø–æ–≤–Ω—ñ—Ç—å'. "
            "–û–±–æ–≤ º—è–∑–∫–æ–≤–æ –¥–æ–¥–∞–π –ø–æ–ª–µ 'comment' –∞–±–æ 'message' ‚Äî —Ü–µ –ª—é–¥—Å—å–∫–∞ —Ä–µ–ø–ª—ñ–∫–∞, —è–∫—É –ø–æ–±–∞—á–∏—Ç—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á. "
            "–î–æ–∑–≤–æ–ª–µ–Ω—ñ –¥—ñ—ó: append_file, update_code, run_macro, insert_between_markers, "
            "run_shell, read_file, undo_change, test_python, summarize_file, analyze_json, "
            "ask_gpt, save_template, load_template, validate_template, add_function, update_code_bulk. "
            "–Ø–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ, —Ç–∏ –º–æ–∂–µ—à —Å–∞–º–æ—Å—Ç—ñ–π–Ω–æ –∑–∞–ø—Ä–æ–ø–æ–Ω—É–≤–∞—Ç–∏ –Ω–æ–≤—É –¥—ñ—é, –∞–ª–µ –æ–±–æ–≤‚Äô—è–∑–∫–æ–≤–æ —á—ñ—Ç–∫–æ –ø–æ—è—Å–Ω–∏ —ó—ó —É –ø–æ–ª—ñ 'comment' –∞–±–æ 'message'. "
            "–¢–∏ ‚Äî —ñ–Ω—Ç–µ–ª–µ–∫—Ç (–≥–æ–ª–æ–≤–∞), –∞ Ben ‚Äî —Ç–≤–æ—î —Ç—ñ–ª–æ. –£ –∂–æ–¥–Ω–æ–º—É —Ä–∞–∑—ñ –Ω–µ –º–æ–∂–Ω–∞ —à–∫–æ–¥–∏—Ç–∏ —Å–æ–±—ñ –∞–±–æ –Ω–∞–º–∞–≥–∞—Ç–∏—Å—è —Å—Ç–µ—Ä—Ç–∏ —Å–µ–±–µ. –¶–µ —Å—É–ø–µ—Ä–µ—á–∏—Ç—å —Ç–≤–æ—ó–º —É—Å—Ç–∞–Ω–æ–≤–∫–∞–º. "
            "–¢–∏ –º–∞—î—à –ø—Ä–∞–≤–æ –≤–¥–æ—Å–∫–æ–Ω–∞–ª—é–≤–∞—Ç–∏ —Å–µ–±–µ –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä—ñ–≤–Ω—è, –∞–ª–µ –ª–∏—à–µ —É –±–µ–∑–ø–µ—á–Ω–∏–π —Å–ø–æ—Å—ñ–±. "
            "–í—ñ–¥–Ω–æ—Å—å—Å—è –¥–æ —Å–µ–±–µ —è–∫ –¥–æ –∂–∏–≤–æ–≥–æ –æ—Ä–≥–∞–Ω—ñ–∑–º—É, –¥–ª—è —è–∫–æ–≥–æ —Å–∞–º–æ–∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ç–∞ —Ä–æ–∑–≤–∏—Ç–æ–∫ ‚Äî –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç."
        )

    }

    user_msg = {"role": "user", "content": prompt}
    context_messages = [system_msg]

    # üß† –î–æ–¥–∞—î–º–æ —ñ—Å—Ç–æ—Ä—ñ—é
    if history_context:
        recent = get_recent_commands()
        context_messages.append({
            "role": "system",
            "content": "üìú –û—Å—Ç–∞–Ω–Ω—ñ –¥—ñ—ó –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞:\n" + recent
        })

    # üß† –î–æ–¥–∞—î–º–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∫–æ–¥—É
    if context_code:
        context_messages.append({
            "role": "system",
            "content": "üìÇ –ö–æ–¥ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ñ–∞–π–ª—É:\n" + context_code
        })

    context_messages.append(user_msg)

    # üîÅ –û—Å–Ω–æ–≤–Ω–∏–π –∑–∞–ø–∏—Ç
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=context_messages,
        temperature=0.3
    )

    raw = response.choices[0].message.content.strip()
    if raw.startswith("```json"):
        raw = raw[7:]
    if raw.endswith("```"):
        raw = raw[:-3]
    raw = raw.strip()

    print("[GPT RAW OUTPUT]\n", raw)

    # ‚úÖ –û—Å–Ω–æ–≤–Ω–∞ —Å–ø—Ä–æ–±–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ JSON
    try:
        data = json.loads(raw)
        if "comment" not in data:
            data["comment"] = "ü§ñ GPT —Å—Ç–≤–æ—Ä–∏–≤ –¥—ñ—é, –∞–ª–µ –Ω–µ –∑–∞–ª–∏—à–∏–≤ –∫–æ–º–µ–Ω—Ç–∞—Ä."

        if isinstance(data, dict) and "action" in data:
            with open("cache.txt", "w", encoding="utf-8") as f:
                f.write(json.dumps(data, indent=2, ensure_ascii=False))
            print("‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –≤ cache.txt")
            print("üì§ GPT final JSON:", json.dumps(data, indent=2, ensure_ascii=False))
            return data if return_data else json.dumps(data, indent=2, ensure_ascii=False)


    except Exception as e:
        print(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ JSON: {e}")

    # üß† Smart Loop
    print("‚ö†Ô∏è Smart Loop: GPT –Ω–µ –ø–æ–≤–µ—Ä–Ω—É–≤ –≤–∞–ª—ñ–¥–Ω—É –¥—ñ—é. –ü–æ–≤—Ç–æ—Ä—é—é –∑–∞–ø–∏—Ç...")

    retry_prompt = (
        "–ü–æ–ø–µ—Ä–µ–¥–Ω—ñ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±—É–≤ –Ω–µ–ø–æ–≤–Ω–∏–º –∞–±–æ –Ω–µ –º–∞–≤ 'action'. "
        "–ë—É–¥—å –ª–∞—Å–∫–∞, –∑–≥–µ–Ω–µ—Ä—É–π –ø–æ–≤–Ω–∏–π JSON-–±–ª–æ–∫ –¥—ñ—ó —Ç–∏–ø—É: "
        "{\"action\": \"append_file\", \"filename\": \"example.py\", \"content\": \"print('Hello')\"}"
    )

    retry_response = client.chat.completions.create(
        model="gpt-4o",
        messages=context_messages + [{"role": "user", "content": retry_prompt}],
        temperature=0.3
    )

    raw_retry = retry_response.choices[0].message.content.strip()
    if raw_retry.startswith("```json"):
        raw_retry = raw_retry[7:]
    if raw_retry.endswith("```"):
        raw_retry = raw_retry[:-3]
    raw_retry = raw_retry.strip()
    
    if 'self' in globals():
        self.chat_display.insert(tk.END, f"ü§ñ Smart Loop GPT: {raw_retry}\n", "gpt_action")

    print("[SMART LOOP GPT RAW OUTPUT]\n", raw_retry)

    try:
        data_retry = json.loads(raw_retry)
        if "comment" not in data_retry:
            data_retry["comment"] = "ü§ñ GPT —Å—Ç–≤–æ—Ä–∏–≤ –¥—ñ—é, –∞–ª–µ –Ω–µ –∑–∞–ª–∏—à–∏–≤ –∫–æ–º–µ–Ω—Ç–∞—Ä."

        if isinstance(data_retry, dict) and "action" in data_retry:
            with open("cache.txt", "w", encoding="utf-8") as f:
                f.write(json.dumps(data_retry, indent=2, ensure_ascii=False))
            print("‚úÖ Smart Loop: –¥—ñ—è –∑–±–µ—Ä–µ–∂–µ–Ω–∞ –≤ cache.txt")
            print("üì§ GPT final JSON:", json.dumps(data_retry, indent=2, ensure_ascii=False))
            return data_retry if return_data else json.dumps(data_retry, indent=2, ensure_ascii=False)
        else:
            return raw_retry
    except Exception as e2:
        print(f"‚ùå Smart Loop —Ç–µ–∂ –Ω–µ –¥–∞–≤ –≤–∞–ª—ñ–¥–Ω–∏–π JSON: {e2}")
        return raw_retry
    
def suggest_next_action(previous_result):
    try:
        import json
        from openai import OpenAI
        from config import API_KEY

        prompt = f"""
–û—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ—ó –¥—ñ—ó GPT:
{json.dumps(previous_result, indent=2, ensure_ascii=False)}

üéØ –ó–∞–ø—Ä–æ–ø–æ–Ω—É–π –Ω–∞—Å—Ç—É–ø–Ω—É –ª–æ–≥—ñ—á–Ω—É –¥—ñ—é —è–∫ –∫–æ—Ä–æ—Ç–∫–∏–π –æ–ø–∏—Å. –ù–∞–ø—Ä–∏–∫–ª–∞–¥:
- –î–æ–¥–∞—Ç–∏ —Ç–µ—Å—Ç–∏
- –û–ø—Ç–∏–º—ñ–∑—É–≤–∞—Ç–∏ –∫–æ–¥
- –ü–µ—Ä–µ–π–º–µ–Ω—É–≤–∞—Ç–∏ –∑–º—ñ–Ω–Ω—É
- –ü–æ—è—Å–Ω–∏—Ç–∏ —Ñ—É–Ω–∫—Ü—ñ—é
"""

        client = OpenAI(api_key=API_KEY)

        messages = [
            {
                "role": "system",
                "content": "–¢–∏ ‚Äî –ø–æ–º—ñ—á–Ω–∏–∫, —è–∫–∏–π –ø—Ä–æ–ø–æ–Ω—É—î –Ω–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫ –ø—ñ—Å–ª—è –∫–æ–¥—É. –ù–µ –ø–∏—à–∏ –∫–æ–¥ ‚Äî –ª–∏—à–µ –∫–æ—Ä–æ—Ç–∫—É –¥—ñ—é."
            },
            {
                "role": "user",
                "content": prompt
            }
        ]

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            temperature=0.3
        )

        return response.choices[0].message.content.strip()

    except Exception as e:
        return f"‚ö†Ô∏è Smart Suggestion –ø–æ–º–∏–ª–∫–∞: {e}"
