import os
import json
import sqlite3
from openai import OpenAI
from config import API_KEY

def get_recent_commands(limit=10):
    conn = sqlite3.connect("history.sqlite")
    cursor = conn.cursor()
    cursor.execute("SELECT action, file_path, update_type, timestamp FROM command_history ORDER BY id DESC LIMIT ?", (limit,))
    rows = cursor.fetchall()
    conn.close()
    return "\n".join([f"[{r[3]}] {r[0]} ‚Üí {r[1]} ({r[2]})" for r in rows[::-1]])

def interpret_user_prompt(prompt, context_code=None, history_context=False, return_data=False):
    client = OpenAI(api_key=API_KEY)

    # üß† –°–∏—Å—Ç–µ–º–Ω–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
    system_msg = {
        "role": "system",
        "content": (
            "–¢–∏ –¥—ñ—î—à —è–∫ –∫–æ–¥–æ–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —É —Å–∏—Å—Ç–µ–º—ñ Ben Assistant. "
            "–ù–∞ –æ—Å–Ω–æ–≤—ñ –ø—Ä–æ–º–ø—Ç—É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ —Å—Ç–≤–æ—Ä–∏ –ø–æ–≤–Ω—É –¥—ñ—é —É —Ñ–æ—Ä–º–∞—Ç—ñ JSON ‚Äî –∑ —É—Å—ñ–º–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏. "
            "–ù–µ –ø–æ–≤–µ—Ä—Ç–∞–π —à–∞–±–ª–æ–Ω—ñ–≤ –∞–±–æ –∑–∞–≥–ª—É—à–æ–∫. –ù—ñ–∫–æ–ª–∏ –Ω–µ –ø–∏—à–∏: '–≤–∫–∞–∂—ñ—Ç—å –Ω–∞–∑–≤—É' —á–∏ '–∑–∞–ø–æ–≤–Ω—ñ—Ç—å'. "
            "–ü–æ–≤–µ—Ä–Ω–∏ –¥—ñ—é, –≥–æ—Ç–æ–≤—É –¥–æ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è, —Ç–∏–ø—É: "
            "{\"action\": \"append_file\", \"filename\": \"example.py\", \"content\": \"print('Hi')\"}. "
            "–î–æ–∑–≤–æ–ª–µ–Ω—ñ –¥—ñ—ó: append_file, update_code, run_macro, insert_between_markers, run_shell."
        )
    }

    user_msg = {"role": "user", "content": prompt}
    context_messages = [system_msg]

    # üß† –î–æ–¥–∞—î–º–æ —ñ—Å—Ç–æ—Ä—ñ—é
    if history_context:
        recent = get_recent_commands()
        context_messages.append({
            "role": "system",
            "content": "üìú –û—Å—Ç–∞–Ω–Ω—ñ –¥—ñ—ó –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞:\n" + recent
        })

    # üß† –î–æ–¥–∞—î–º–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∫–æ–¥—É
    if context_code:
        context_messages.append({
            "role": "system",
            "content": "üìÇ –ö–æ–¥ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ñ–∞–π–ª—É:\n" + context_code
        })

    context_messages.append(user_msg)

    # üîÅ –û—Å–Ω–æ–≤–Ω–∏–π –∑–∞–ø–∏—Ç
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=context_messages,
        temperature=0.3
    )

    raw = response.choices[0].message.content.strip()
    if raw.startswith("```json"):
        raw = raw[7:]
    if raw.endswith("```"):
        raw = raw[:-3]
    raw = raw.strip()

    print("[GPT RAW OUTPUT]\n", raw)

    # ‚úÖ –û—Å–Ω–æ–≤–Ω–∞ —Å–ø—Ä–æ–±–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ JSON
    try:
        data = json.loads(raw)
        if isinstance(data, dict) and "action" in data:
            with open("cache.txt", "w", encoding="utf-8") as f:
                f.write(json.dumps(data, indent=2, ensure_ascii=False))
            print("‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –≤ cache.txt")
            return data if return_data else json.dumps(data, indent=2, ensure_ascii=False)
    except Exception as e:
        print(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ JSON: {e}")

    # üß† Smart Loop
    print("‚ö†Ô∏è Smart Loop: GPT –Ω–µ –ø–æ–≤–µ—Ä–Ω—É–≤ –≤–∞–ª—ñ–¥–Ω—É –¥—ñ—é. –ü–æ–≤—Ç–æ—Ä—é—é –∑–∞–ø–∏—Ç...")

    retry_prompt = (
        "–ü–æ–ø–µ—Ä–µ–¥–Ω—ñ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±—É–≤ –Ω–µ–ø–æ–≤–Ω–∏–º –∞–±–æ –Ω–µ –º–∞–≤ 'action'. "
        "–ë—É–¥—å –ª–∞—Å–∫–∞, –∑–≥–µ–Ω–µ—Ä—É–π –ø–æ–≤–Ω–∏–π JSON-–±–ª–æ–∫ –¥—ñ—ó —Ç–∏–ø—É: "
        "{\"action\": \"append_file\", \"filename\": \"example.py\", \"content\": \"print('Hello')\"}"
    )

    retry_response = client.chat.completions.create(
        model="gpt-4o",
        messages=context_messages + [{"role": "user", "content": retry_prompt}],
        temperature=0.3
    )

    raw_retry = retry_response.choices[0].message.content.strip()
    if raw_retry.startswith("```json"):
        raw_retry = raw_retry[7:]
    if raw_retry.endswith("```"):
        raw_retry = raw_retry[:-3]
    raw_retry = raw_retry.strip()
    
    if 'self' in globals():
        self.chat_display.insert(tk.END, f"ü§ñ Smart Loop GPT: {raw_retry}\n", "gpt_action")

    print("[SMART LOOP GPT RAW OUTPUT]\n", raw_retry)

    try:
        data_retry = json.loads(raw_retry)
        if isinstance(data_retry, dict) and "action" in data_retry:
            with open("cache.txt", "w", encoding="utf-8") as f:
                f.write(json.dumps(data_retry, indent=2, ensure_ascii=False))
            print("‚úÖ Smart Loop: –¥—ñ—è –∑–±–µ—Ä–µ–∂–µ–Ω–∞ –≤ cache.txt")
            return data_retry if return_data else json.dumps(data_retry, indent=2, ensure_ascii=False)
        else:
            return raw_retry
    except Exception as e2:
        print(f"‚ùå Smart Loop —Ç–µ–∂ –Ω–µ –¥–∞–≤ –≤–∞–ª—ñ–¥–Ω–∏–π JSON: {e2}")
        return raw_retry
def suggest_next_action(previous_result):
    try:
        import json
        from openai import OpenAI
        from config import API_KEY

        prompt = f"""
–û—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ—ó –¥—ñ—ó GPT:
{json.dumps(previous_result, indent=2, ensure_ascii=False)}

üéØ –ó–∞–ø—Ä–æ–ø–æ–Ω—É–π –Ω–∞—Å—Ç—É–ø–Ω—É –ª–æ–≥—ñ—á–Ω—É –¥—ñ—é —è–∫ –∫–æ—Ä–æ—Ç–∫–∏–π –æ–ø–∏—Å. –ù–∞–ø—Ä–∏–∫–ª–∞–¥:
- –î–æ–¥–∞—Ç–∏ —Ç–µ—Å—Ç–∏
- –û–ø—Ç–∏–º—ñ–∑—É–≤–∞—Ç–∏ –∫–æ–¥
- –ü–µ—Ä–µ–π–º–µ–Ω—É–≤–∞—Ç–∏ –∑–º—ñ–Ω–Ω—É
- –ü–æ—è—Å–Ω–∏—Ç–∏ —Ñ—É–Ω–∫—Ü—ñ—é
"""

        client = OpenAI(api_key=API_KEY)

        messages = [
            {
                "role": "system",
                "content": "–¢–∏ ‚Äî –ø–æ–º—ñ—á–Ω–∏–∫, —è–∫–∏–π –ø—Ä–æ–ø–æ–Ω—É—î –Ω–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫ –ø—ñ—Å–ª—è –∫–æ–¥—É. –ù–µ –ø–∏—à–∏ –∫–æ–¥ ‚Äî –ª–∏—à–µ –∫–æ—Ä–æ—Ç–∫—É –¥—ñ—é."
            },
            {
                "role": "user",
                "content": prompt
            }
        ]

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            temperature=0.3
        )

        return response.choices[0].message.content.strip()

    except Exception as e:
        return f"‚ö†Ô∏è Smart Suggestion –ø–æ–º–∏–ª–∫–∞: {e}"
