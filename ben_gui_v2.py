import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import tkinter as tk
import threading
from tkinter import ttk, scrolledtext, Menu
import json
from datetime import datetime, timezone
timestamp = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%S")
from gpt_interpreter import interpret_user_prompt, suggest_next_action  # üîå –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä–∞
from gpt_agent_cache import get_command_by_id, handle_command, save_to_memory # üß† –ê–≤—Ç–æ–≤–∏–∫–æ–Ω–∞–Ω–Ω—è –∫–æ–º–∞–Ω–¥
from openai import OpenAI                          # üß† GPT API –¥–ª—è –ø–æ—è—Å–Ω–µ–Ω–Ω—è –∫–æ–¥—É
from config import API_KEY
import time

def generate_ai_insight(response_json):
    from gpt_interpreter import interpret_user_prompt

    prompt = f"""
–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π —Ü—é –¥—ñ—é GPT. –í–∏–∑–Ω–∞—á:
- –©–æ —Å–∞–º–µ –∑—Ä–æ–±–ª–µ–Ω–æ?
- –ß–∏ —Ü–µ –±—É–ª–æ –¥–æ—Ü—ñ–ª—å–Ω–æ?
- –©–æ —Ä–µ–∫–æ–º–µ–Ω–¥—É—î—à –ø–æ–∫—Ä–∞—â–∏—Ç–∏?
- –Ø–∫–∏–π –Ω–∞—Å—Ç—É–ø–Ω–∏–π –ª–æ–≥—ñ—á–Ω–∏–π –∫—Ä–æ–∫?

–û—Å—å –≤—ñ–¥–ø–æ–≤—ñ–¥—å:–ó
{json.dumps(response_json, indent=2, ensure_ascii=False)}
"""

    try:
        insight = interpret_user_prompt(prompt)
        return insight
    except Exception as e:
        return f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ AI Insight: {e}"
    
def generate_ai_insight(result):
    try:
        from gpt_interpreter import interpret_user_prompt
        message = result.get("message", "")
        prompt = f"""
–Ø–∫–∞ –¥—ñ—è –±—É–ª–∞ —â–æ–π–Ω–æ –≤–∏–∫–æ–Ω–∞–Ω–∞: {message}
–ó—Ä–æ–±–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –≤–∏—Å–Ω–æ–≤–æ–∫ —É 2-3 —Ä–µ—á–µ–Ω–Ω—è—Ö:
- –©–æ –∑—Ä–æ–±–ª–µ–Ω–æ?
- –ß–∏ –≤—Å–µ –≥–∞—Ä–∞–∑–¥?
- –©–æ –º–æ–∂–Ω–∞ –ø–æ–∫—Ä–∞—â–∏—Ç–∏ –∞–±–æ –Ω–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫?

–ü–∏—à–∏ —è–∫ GPT-–∫–æ–º–µ–Ω—Ç–∞—Ä –¥–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞.
"""
        insight = interpret_user_prompt(prompt)
        return insight.strip()
    except Exception as e:
        return f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ AI Insight: {e}"

class BenAssistantGUI:
    def __init__(self, root):
        self.root = root
        self.root.title("Ben Assistant v2")
        self.root.geometry("1200x700")

        self.current_chat_file = None
        self.chat_history = []
        self.last_action_id = None
        self.action_counter = 1  # üî¢ –î–ª—è –ø—Ä–∏—Å–≤–æ—î–Ω–Ω—è —É–Ω—ñ–∫–∞–ª—å–Ω–æ–≥–æ ID –¥—ñ—è–º
        self.command_counter = 1  # üî¢ –î–ª—è —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö history_id
        self.current_file_content = ""  # üß† –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∫–æ–¥ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ñ–∞–π–ª—É
        self.start_live_log_updater()
        self.setup_layout()
        self.start_feedback_report_updater()
        
        # üé® –°—Ç–∏–ª—ñ–∑–∞—Ü—ñ—è –¥–ª—è —Ç–µ–≥—É gpt_action  
        self.chat_display.tag_configure("gpt_action", foreground="#0a84ff", font=("Arial", 10, "bold"))
        self.root.bind_all("<Control-c>", lambda e: self.root.focus_get().event_generate("<<Copy>>"))
        self.root.bind_all("<Control-v>", lambda e: self.root.focus_get().event_generate("<<Paste>>"))
        self.root.bind_all("<Control-x>", lambda e: self.root.focus_get().event_generate("<<Cut>>"))
        self.root.bind_all("<Control-a>", lambda e: self.root.focus_get().event_generate("<<SelectAll>>"))

        os.makedirs("chats", exist_ok=True)
        self.load_chats()

    def setup_layout(self):
        self.left_panel = tk.Frame(self.root, width=250, bg="#f0f0f0")
        self.left_panel.pack(side="left", fill="y")

        self.project_label = tk.Label(self.left_panel, text="üóÇÔ∏è –°—Ç—ñ–ª", bg="#f0f0f0", font=("Arial", 12, "bold"))
        self.project_label.pack(pady=(10,0))

        self.project_tree = ttk.Treeview(self.left_panel)
        self.project_tree.pack(expand=True, fill="both", padx=5, pady=(0,5))
        self.populate_tree("C:/Users/DC/my-bot-project", "")

        self.chat_label = tk.Label(self.left_panel, text="üí¨ –ß–∞—Ç–∏", bg="#f0f0f0", font=("Arial", 12, "bold"))
        self.chat_label.pack(pady=(10, 0))

        self.chat_list = tk.Listbox(self.left_panel)
        self.chat_list.pack(fill="both", expand=False, padx=5, pady=(0, 10))
        self.chat_list.bind("<<ListboxSelect>>", self.load_selected_chat)

        self.center_panel = tk.Frame(self.root, bg="#ffffff")
        self.center_panel.pack(side="left", fill="both", expand=True)

        self.chat_display = scrolledtext.ScrolledText(self.center_panel, wrap="word", height=30)
        self.chat_display.pack(fill="both", expand=True, padx=10, pady=(10, 0))
        self.add_context_menu(self.chat_display)

        self.chat_display.tag_bind("gpt_action", "<Button-1>", self.on_action_click)
        self.chat_display.tag_bind("gpt_action", "<Button-3>", self.on_action_right_click)

       
        self.prompt_entry = tk.Entry(self.center_panel, font=("Arial", 12))
        self.prompt_entry.pack(fill="x", padx=10, pady=5)

        self.send_button = tk.Button(self.center_panel, text="–í—ñ–¥–ø—Ä–∞–≤–∏—Ç–∏", command=self.send_prompt)
        self.send_button.pack(padx=10, pady=(0,10))
        
        self.autopilot_button = tk.Button(self.center_panel, text="üß† Autopilot", command=self.run_autopilot_prompt)
        self.autopilot_button.pack(padx=10, pady=(0,5))

        self.right_panel = tk.Frame(self.root, width=400, bg="#f9f9f9")
        self.right_panel.pack(side="right", fill="y")

        self.code_label = tk.Label(self.right_panel, text="üëÅÔ∏è –ü–æ–ø–µ—Ä–µ–¥–Ω—ñ–π –∫–æ–¥", bg="#f9f9f9", font=("Arial", 12, "bold"))
        self.code_label.pack(pady=10)

        self.code_preview = scrolledtext.ScrolledText(self.right_panel, wrap="none", height=30)
        self.code_preview.pack(fill="both", expand=True, padx=10)
        self.add_context_menu(self.code_preview)

        self.explain_button = tk.Button(self.right_panel, text="üß† –ü–æ—è—Å–Ω–∏ –∫–æ–¥ —Å–ø—Ä–∞–≤–∞", command=self.explain_code_preview)
        self.explain_button.pack(pady=5)

        # üìä –û–±–ª–∞—Å—Ç—å –¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –æ—Å—Ç–∞–Ω–Ω—å–æ–≥–æ Feedback
        feedback_frame = ttk.LabelFrame(self.right_panel, text="üìä GPT Feedback")
        feedback_frame.pack(fill="both", expand=True, padx=10, pady=10)

        self.feedback_area = scrolledtext.ScrolledText(feedback_frame, wrap="word", height=10)
        self.feedback_area.pack(fill="both", expand=True)

        self.analyze_all_button = tk.Button(self.right_panel, text="üß† –ê–Ω–∞–ª—ñ–∑—É–π –≤–µ—Å—å —Å—Ç—ñ–ª", command=self.analyze_all_code)
        self.analyze_all_button.pack(pady=5)

        self.explain_last_action_button = tk.Button(
            self.right_panel,
            text="üß† –ü–æ—è—Å–Ω–∏ –æ—Å—Ç–∞–Ω–Ω—é –¥—ñ—é",
            command=self.explain_last_action
        )
        self.explain_last_action_button.pack(pady=5)
        
        self.autopilot_button = tk.Button(self.right_panel, text="üß† –ó–∞–ø—É—Å—Ç–∏—Ç–∏ Autopilot", command=self.start_autopilot)
        self.autopilot_button.pack(pady=5)

    def add_context_menu(self, widget):
        menu = Menu(widget, tearoff=0)
        menu.add_command(label="–ö–æ–ø—ñ—é–≤–∞—Ç–∏", command=lambda: widget.event_generate("<<Copy>>"))
        menu.add_command(label="–í—Å—Ç–∞–≤–∏—Ç–∏", command=lambda: widget.event_generate("<<Paste>>"))
        menu.add_command(label="–í–∏—Ä—ñ–∑–∞—Ç–∏", command=lambda: widget.event_generate("<<Cut>>"))
        menu.add_command(label="–í–∏–¥—ñ–ª–∏—Ç–∏ –≤—Å–µ", command=lambda: widget.event_generate("<<SelectAll>>"))

        def show_menu(event):
            menu.tk_popup(event.x_root, event.y_root)

        widget.bind("<Button-3>", show_menu)


    def start_live_log_updater(self):
        def update_loop():
            prev_log = ""
            while True:
                try:
                    with open("debug.log", "r", encoding="utf-8") as f:
                        log = f.read()
                    if log != prev_log:
                        self.response_area.delete("1.0", tk.END)
                        self.response_area.insert(tk.END, log[-5000:])  # –æ—Å—Ç–∞–Ω–Ω—ñ 5000 —Å–∏–º–≤–æ–ª—ñ–≤
                        prev_log = log
                    time.sleep(5)
                except:
                    pass
        threading.Thread(target=update_loop, daemon=True).start()

    def start_feedback_report_updater(self):
        def update_loop():
            prev_report = ""
            while True:
                try:
                    files = sorted(
                        [f for f in os.listdir() if f.startswith("feedback_report_") and f.endswith(".txt")],
                        reverse=True
                    )
                    if files:
                        latest = files[0]
                        with open(latest, "r", encoding="utf-8") as f:
                            content = f.read()
                        if content != prev_report:
                            timestamp = latest.replace("feedback_report_", "").replace(".txt", "")
                            self.chat_display.insert(tk.END, f"\nüß† GPT Feedback ({timestamp}):\n", "gpt_action")
                            self.chat_display.insert(tk.END, content + "\n")
                            self.chat_display.see(tk.END)
                            prev_report = content
                    time.sleep(6)
                except Exception as e:
                    print("‚ùå Feedback log error:", e)
                    time.sleep(6)
        threading.Thread(target=update_loop, daemon=True).start()

    def explain_code_preview(self):
        code = self.code_preview.get("1.0", tk.END).strip()
        if not code:
            self.chat_display.insert(tk.END, "‚ö†Ô∏è –ù–µ–º–∞—î –∫–æ–¥—É –¥–ª—è –ø–æ—è—Å–Ω–µ–Ω–Ω—è\n\n")
            return

        try:
            client = OpenAI(api_key=API_KEY)
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "–ü–æ—è—Å–Ω–∏, —â–æ —Ä–æ–±–∏—Ç—å –Ω–∞—Å—Ç—É–ø–Ω–∏–π Python-–∫–æ–¥ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Å—Ç–∏—Å–ª–æ:"},
                    {"role": "user", "content": code}
                ],
                temperature=0.5
            )
            explanation = response.choices[0].message.content.strip()
            self.chat_display.insert(tk.END, f"ü§ñ –ü–æ—è—Å–Ω–µ–Ω–Ω—è –∫–æ–¥—É:\n{explanation}\n\n")
            self.chat_display.see(tk.END)

        except Exception as e:
            self.chat_display.insert(tk.END, f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø–æ—è—Å–Ω–µ–Ω–Ω—è –∫–æ–¥—É: {e}\n\n")

    def run_autopilot_prompt(self):
        user_input = self.prompt_entry.get()
        if not user_input.strip():
            return

        self.chat_display.insert(tk.END, f"ü§ñ [Autopilot] {user_input}\n")
        self.chat_history.append({"role": "user", "content": user_input})

        try:
            from gpt_interpreter import interpret_user_prompt
            from gpt_agent_cache import handle_command
            from utils import save_to_memory

            response_json = interpret_user_prompt(user_input, history_context=True, return_data=True)

            if response_json:
                history_id = f"auto_{self.command_counter:03}"
                response_json["history_id"] = history_id
                if self.last_action_id:
                    response_json["target_id"] = self.last_action_id
                self.last_action_id = history_id

                self.chat_display.insert(tk.END, f"üß† GPT Autopilot –∑–≥–µ–Ω–µ—Ä—É–≤–∞–≤ –¥—ñ—é ‚úÖ [{history_id}]\n", "gpt_action")
                self.chat_display.insert(tk.END, f"üì© –ö–æ–º–∞–Ω–¥—É –∑–±–µ—Ä–µ–∂–µ–Ω–æ\n", "gpt_action")

                save_to_memory(response_json)
                result = handle_command(response_json)
                self.chat_display.insert(tk.END, f"üì§ –í–∏–∫–æ–Ω–∞–Ω–æ: {result.get('message', '‚õî –ù–µ–≤—ñ–¥–æ–º–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å')}\n")
                self.chat_history.append({"role": "assistant", "content": result.get('message', '')})
                
                # üí° Smart Suggestion ‚Äî –Ω–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫ GPT
                try:
                    suggestion = suggest_next_action(result)
                    self.chat_display.insert(tk.END, f"üí° –ù–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫ GPT: {suggestion}\n", "gpt_action")
                    self.chat_display.see(tk.END)
                except Exception as e:
                    print("‚ö†Ô∏è Smart Suggestion –ø–æ–º–∏–ª–∫–∞:", e)

                try:
                    from ai_insight import generate_ai_insight
                    ai_msg = generate_ai_insight(result)
                    self.chat_display.insert(tk.END, f"üí¨ AI Insight: {ai_msg}\n", "gpt_action")
                except:
                    pass

                self.command_counter += 1
                self.chat_display.insert(tk.END, "\n")
                self.chat_display.see(tk.END)

        except Exception as e:
            self.chat_display.insert(tk.END, f"‚ùå Autopilot –ø–æ–º–∏–ª–∫–∞: {e}\n")
            self.chat_display.see(tk.END)

    def populate_tree(self, path, parent):
        for item in os.listdir(path):
            abspath = os.path.join(path, item)
            isdir = os.path.isdir(abspath)
            oid = self.project_tree.insert(parent, "end", text=item, open=False, values=(abspath,))
            if isdir:
                self.populate_tree(abspath, oid)

        self.project_tree.bind("<<TreeviewSelect>>", self.on_file_select)

    def load_chats(self):
        self.chat_list.delete(0, tk.END)
        files = sorted(os.listdir("chats"))
        for f in files:
            if f.endswith(".json"):
                self.chat_list.insert(tk.END, f)

        if not files:
            self.create_new_chat()

    def create_new_chat(self):
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        self.current_chat_file = f"chats/chat_{timestamp}.json"
        self.chat_history = []
        self.save_chat()
        self.load_chats()
        self.chat_list.selection_set(tk.END)

    def load_selected_chat(self, event):
        selection = self.chat_list.curselection()
        if not selection:
            return
        filename = self.chat_list.get(selection[0])
        path = os.path.join("chats", filename)
        try:
            with open(path, "r", encoding="utf-8") as f:
                self.chat_history = json.load(f)
            self.current_chat_file = path
            self.chat_display.delete("1.0", tk.END)
            for msg in self.chat_history:
                role = "üë§" if msg["role"] == "user" else "ü§ñ GPT"
                self.chat_display.insert(tk.END, f"{role} {msg['content']}\n\n")
        except:
            self.chat_display.insert(tk.END, "‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —á–∞—Ç")

    def save_chat(self):
        if self.current_chat_file:
            with open(self.current_chat_file, "w", encoding="utf-8") as f:
                json.dump(self.chat_history, f, indent=2, ensure_ascii=False)

    def on_file_select(self, event):
        selected = self.project_tree.focus()
        path = self.project_tree.item(selected, "values")[0]
        if os.path.isfile(path):
            try:
                with open(path, "r", encoding="utf-8") as f:
                    content = f.read()
                self.current_file_content = content
                self.code_preview.delete("1.0", tk.END)
                self.code_preview.insert(tk.END, content)
            except Exception as e:
                self.code_preview.delete("1.0", tk.END)
                self.code_preview.insert(tk.END, f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –≤—ñ–¥–∫—Ä–∏—Ç–∏ —Ñ–∞–π–ª: {e}")

    def send_prompt(self):
        user_input = self.prompt_entry.get()
        if not user_input.strip():
            return

        self.chat_display.insert(tk.END, f"üë§ {user_input}\n")
        self.chat_history.append({"role": "user", "content": user_input})

        try:
            response_json = interpret_user_prompt(
                user_input,
                context_code=self.current_file_content,
                history_context=True,
                return_data=True
            )

            # üÜî –ì–µ–Ω–µ—Ä—É—î–º–æ ID –¥–ª—è –¥—ñ—ó
            history_id = f"id_{self.action_counter:03}"
            assistant_msg = f"GPT: –ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ –¥—ñ—é ‚úÖ [{history_id}]"
            self.action_counter += 1

            # üíæ –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ü–µ–π ID —è–∫ –æ—Å—Ç–∞–Ω–Ω—é –¥—ñ—é
            self.last_action_id = history_id

            self.chat_display.insert(tk.END, f"ü§ñ {assistant_msg}\n", "gpt_action")
            self.chat_history.append({"role": "assistant", "content": assistant_msg})

            if response_json:
                code = response_json.get("code") or response_json.get("content")
                if code:
                    self.code_preview.delete("1.0", tk.END)
                    self.code_preview.insert(tk.END, code)

                # üß© –ì–µ–Ω–µ—Ä—É—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω–∏–π ID –¥–ª—è –∫–æ–º–∞–Ω–¥–∏
                history_id = f"cmd_{self.command_counter:03}"
                response_json["history_id"] = history_id

                # ‚úÖ –î–æ–¥–∞—î–º–æ —Ç–∞–∫–æ–∂ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –æ—Å—Ç–∞–Ω–Ω—é –¥—ñ—é –¥–ª—è rollback
                if self.last_action_id:
                    response_json["target_id"] = self.last_action_id

                with open("cache.txt", "w", encoding="utf-8") as f:
                    f.write(json.dumps(response_json, indent=2, ensure_ascii=False))

                self.chat_display.insert(tk.END, f"üì© [{history_id}] –ö–æ–º–∞–Ω–¥—É –∑–∞–ø–∏—Å–∞–Ω–æ –≤ cache.txt\n", "gpt_action")
                self.command_counter += 1
                
                save_to_memory(response_json)  # üíæ –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ø–æ–≤–Ω—É –∫–æ–º–∞–Ω–¥—É –∑ code/content

                result = handle_command(response_json)
                self.chat_display.insert(tk.END, f"üì§ –í–∏–∫–æ–Ω–∞–Ω–æ: {result.get('message', '‚õî –ù–µ–≤—ñ–¥–æ–º–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å')}\n")
                self.chat_history.append({"role": "assistant", "content": result.get('message', '‚õî –ù–µ–≤—ñ–¥–æ–º–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å')})
                # üí° Smart Suggestion ‚Äî –Ω–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫ GPT
                try:
                    suggestion = suggest_next_action(result)
                    self.chat_display.insert(tk.END, f"üí° –ù–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫ GPT: {suggestion}\n", "gpt_action")
                    self.chat_display.see(tk.END)
                except Exception as e:
                    print("‚ö†Ô∏è Smart Suggestion –ø–æ–º–∏–ª–∫–∞:", e)

                # üß† AI Insight –ø—ñ—Å–ª—è –≤–∏–∫–æ–Ω–∞–Ω–Ω—è
                try:
                    ai_insight = generate_ai_insight(result)
                    self.chat_display.insert(tk.END, f"üß† AI Insight: {ai_insight}\n", "gpt_action")
                    self.chat_display.see(tk.END)
                except Exception as insight_err:
                    print("‚ö†Ô∏è AI Insight –ø–æ–º–∏–ª–∫–∞:", insight_err)
     
        except Exception as e:
            self.chat_display.insert(tk.END, f"‚ùå –ü–æ–º–∏–ª–∫–∞ GPT: {e}\n")
            self.chat_history.append({"role": "assistant", "content": f"‚ùå –ü–æ–º–∏–ª–∫–∞ GPT: {e}"})

        self.chat_display.insert(tk.END, "\n")
        self.chat_display.see(tk.END)
        self.prompt_entry.delete(0, tk.END)
        self.save_chat()

    def start_autopilot(self):
        import threading, time
        from gpt_interpreter import interpret_user_prompt, generate_ai_insight

        def autopilot_loop():
            self.chat_display.insert(tk.END, "üß† Autopilot —É–≤—ñ–º–∫–Ω–µ–Ω–æ. GPT —Å–∞–º –∫–µ—Ä—É—î –¥—ñ—è–º–∏...\n", "gpt_action")
            self.chat_display.see(tk.END)

            prompt = "–ü—Ä–æ—Å—Ç–æ —Å–∫–∞–∂–∏ –ü—Ä–∏–≤—ñ—Ç"

            while True:
                try:
                    # 1. –í–∏–≤–æ–¥–∏–º–æ prompt
                    self.chat_display.insert(tk.END, f"üë§ {prompt}\n")
                    self.chat_display.see(tk.END)

                    # 2. GPT –≥–µ–Ω–µ—Ä—É—î –¥—ñ—é
                    response_json = interpret_user_prompt(
                        prompt,
                        context_code=self.current_file_content,
                        history_context=True,
                        return_data=True
                    )
                    
                    print("üîç DEBUG: –í—ñ–¥–ø–æ–≤—ñ–¥—å GPT:", response_json)
                    print("üß† DEBUG response_json:", response_json)
                    print("‚úÖ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ JSON –ø—Ä–æ–π–¥–µ–Ω–∞.")

                    if not isinstance(response_json, dict):
                        self.chat_display.insert(tk.END, f"‚ö†Ô∏è GPT –ø–æ–≤–µ—Ä–Ω—É–≤ –Ω–µ JSON: {response_json}\n", "gpt_action")
                        self.chat_display.see(tk.END)
                        prompt = "‚ùå GPT –Ω–µ –¥–∞–≤ –¥—ñ—ó. –ü–æ–≤—Ç–æ—Ä–∏—Ç–∏..."
                        continue

                    gpt_text = response_json.get("comment") or response_json.get("message") or "ü§ñ GPT: –î—ñ—è —Å—Ñ–æ—Ä–º–æ–≤–∞–Ω–∞."
                    self.chat_display.insert(tk.END, f"{gpt_text}\n", "gpt_action")
                    self.chat_display.see(tk.END)

                    if not response_json:
                        self.chat_display.insert(tk.END, "‚ùå GPT –Ω–µ –ø–æ–≤–µ—Ä–Ω—É–≤ –≤–∞–ª—ñ–¥–Ω—É –¥—ñ—é.\n", "gpt_action")
                        self.chat_display.see(tk.END)
                        prompt = "‚ùå GPT –Ω–µ –¥–∞–≤ –¥—ñ—ó. –ü–æ–≤—Ç–æ—Ä–∏—Ç–∏..."
                        continue

                    # 3. –ü—Ä–∏—Å–≤–æ—é—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω–∏–π ID
                    history_id = f"auto_{self.command_counter:03}"
                    response_json["history_id"] = history_id

                    if self.last_action_id:
                        response_json["target_id"] = self.last_action_id

                    self.last_action_id = history_id

                    # 4. –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ cache.txt
                    with open("cache.txt", "w", encoding="utf-8") as f:
                        f.write(json.dumps(response_json, indent=2, ensure_ascii=False))

                    self.chat_display.insert(tk.END, f"üì© [{history_id}] –ö–æ–º–∞–Ω–¥—É –∑–∞–ø–∏—Å–∞–Ω–æ –≤ cache.txt\n", "gpt_action")

                    # 5. –í–∏–∫–æ–Ω—É—î–º–æ –¥—ñ—é
                    result = handle_command(response_json)
                    self.chat_display.insert(tk.END, f"üì§ –í–∏–∫–æ–Ω–∞–Ω–æ: {result.get('message', '‚õî')}\n", "gpt_action")
                    self.chat_display.see(tk.END)
                    
                    if result.get("status") == "error" and "–ù–µ–≤—ñ–¥–æ–º–∞ –¥—ñ—è" in result.get("message", ""):
                        self.chat_display.insert(tk.END, f"üÜï GPT –∑–∞–ø—Ä–æ–ø–æ–Ω—É–≤–∞–≤ –Ω–æ–≤—É –¥—ñ—é: {response_json.get('action')}.\n", "gpt_action")
                        self.chat_display.see(tk.END)

                    # 6. AI Insight
                    try:
                        ai_insight = generate_ai_insight(result)
                        self.chat_display.insert(tk.END, f"üß† AI Insight: {ai_insight}\n", "gpt_action")
                        self.chat_display.insert(tk.END, f"üó£Ô∏è GPT Feedback:\n{ai_insight}\n", "gpt_action")
                    except Exception as insight_err:
                        print("‚ö†Ô∏è AI Insight –ø–æ–º–∏–ª–∫–∞:", insight_err)
                    # üí° Smart Suggestion ‚Äî –Ω–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫ GPT
                    try:
                        suggestion = suggest_next_action(result)
                        self.chat_display.insert(tk.END, f"üí° –ù–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫ GPT: {suggestion}\n", "gpt_action")
                        self.chat_display.see(tk.END)
                    except Exception as e:
                        print("‚ö†Ô∏è Smart Suggestion –ø–æ–º–∏–ª–∫–∞:", e)

                    # 7. –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ prompt
                    prompt = f"üìå –ù–∞—Å—Ç—É–ø–Ω–∞ –¥—ñ—è –ø—ñ—Å–ª—è: {result.get('message', '')}"
                    self.command_counter += 1
                    self.chat_display.insert(tk.END, "\n")
                    self.chat_display.see(tk.END)

                    time.sleep(15)

                except Exception as e:
                    self.chat_display.insert(tk.END, f"‚ùå Autopilot –ø–æ–º–∏–ª–∫–∞: {e}\n")
                    self.chat_display.see(tk.END)
                    break

        threading.Thread(target=autopilot_loop, daemon=True).start()


    def suggest_next_action(response):
        try:
            prompt = f"""
    –û—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ—ó –¥—ñ—ó GPT:
    {json.dumps(response, indent=2, ensure_ascii=False)}

    üéØ –ó–∞–ø—Ä–æ–ø–æ–Ω—É–π –Ω–∞—Å—Ç—É–ø–Ω—É –ª–æ–≥—ñ—á–Ω—É –¥—ñ—é —è–∫ –æ–¥–∏–Ω –∫–æ—Ä–æ—Ç–∫–∏–π –æ–ø–∏—Å. –ù–∞–ø—Ä–∏–∫–ª–∞–¥:
    - –î–æ–¥–∞—Ç–∏ —Ç–µ—Å—Ç –¥–æ test_*.py
    - –ü–µ—Ä–µ–π–º–µ–Ω—É–≤–∞—Ç–∏ —Ñ—É–Ω–∫—Ü—ñ—é
    - –î–æ–¥–∞—Ç–∏ –ª–æ–≥—É–≤–∞–Ω–Ω—è
    - –ü–æ—è—Å–Ω–∏—Ç–∏ –∫–æ–¥
    """
            from gpt_interpreter import interpret_user_prompt
            suggestion = interpret_user_prompt(prompt)
            return suggestion.strip()
        except Exception as e:
            return f"‚ö†Ô∏è Smart Suggestion –ø–æ–º–∏–ª–∫–∞: {e}"

    def on_action_click(self, event):
        index = self.chat_display.index(f"@{event.x},{event.y}")
        line = self.chat_display.get(index + " linestart", index + " lineend")

        self.code_preview.delete("1.0", tk.END)
        self.code_preview.insert(tk.END, f"üîç –í–∏ –æ–±—Ä–∞–ª–∏ –¥—ñ—é:\n{line}\n\n")

        # –ü—ñ–¥—Å–≤—ñ—Ç–∏—Ç–∏ —Ä—è–¥–æ–∫
        self.chat_display.tag_remove("highlighted", "1.0", tk.END)
        self.chat_display.tag_add("highlighted", index + " linestart", index + " lineend")
        self.chat_display.tag_configure("highlighted", background="#d0ebff")

        # –í–∏—Ç—è–≥–Ω—É—Ç–∏ history_id
        if "[" in line and "]" in line:
            start = line.find("[") + 1
            end = line.find("]")
            history_id = line[start:end]
        else:
            history_id = None

        # –ü–æ–∫–∞–∑–∞—Ç–∏ –∫–æ–¥ –∑ —ñ—Å—Ç–æ—Ä—ñ—ó
        if history_id:
            cmd = get_command_by_id(history_id)
            if cmd:
                content = cmd.get("code") or cmd.get("content") or ""
                if content:
                    self.code_preview.insert(tk.END, f"\nüì¶ –ö–æ–¥ –∑ ID {history_id}:\n{content}")

    def on_action_right_click(self, event):
        index = self.chat_display.index(f"@{event.x},{event.y}")
        selected_line = self.chat_display.get(index + " linestart", index + " lineend").strip()

        # –í–∏—Ç—è–≥–Ω—É—Ç–∏ history_id –∑ —Ä—è–¥–∫–∞ (—è–∫—â–æ —î)
        if "[" in selected_line and "]" in selected_line:
            start = selected_line.find("[") + 1
            end = selected_line.find("]")
            target_id = selected_line[start:end]
        else:
            target_id = None

        def rollback_action():
            if not target_id:
                self.chat_display.insert(tk.END, "‚ö†Ô∏è –ù–µ–º–æ–∂–ª–∏–≤–æ –≤–∏–∑–Ω–∞—á–∏—Ç–∏ history_id –¥–ª—è –≤—ñ–¥–∫–∞—Ç—É\n")
                return
            try:
                command = {"action": "undo_change", "target_id": target_id}
                with open("cache.txt", "w", encoding="utf-8") as f:
                    f.write(json.dumps(command, indent=2, ensure_ascii=False))
                result = handle_command(command)
                self.chat_display.insert(tk.END, f"üîÅ –í—ñ–¥–∫–∞—Ç {target_id}: {result.get('message', '‚õî –ü–æ–º–∏–ª–∫–∞')}\n", "gpt_action")
            except Exception as e:
                self.chat_display.insert(tk.END, f"‚ùå –ü–æ–º–∏–ª–∫–∞ –≤—ñ–¥–∫–∞—Ç—É: {e}\n", "gpt_action")

        def delete_action():
            self.chat_display.insert(tk.END, f"üóëÔ∏è –í–∏–¥–∞–ª–µ–Ω–æ –¥—ñ—é: {selected_line}\n")

        menu = Menu(self.root, tearoff=0)
        menu.add_command(label="‚è™ –í—ñ–¥–∫–æ—Ç–∏—Ç–∏", command=rollback_action)
        menu.add_command(label="‚ùå –í–∏–¥–∞–ª–∏—Ç–∏", command=delete_action)
        menu.tk_popup(event.x_root, event.y_root)

        def show_menu(event):
            menu.tk_popup(event.x_root, event.y_root)

        event.widget.bind("<Button-3>", show_menu)

    def explain_last_action(self):
        if not hasattr(self, "last_action_id") or not self.last_action_id:
            self.chat_display.insert(tk.END, "‚ö†Ô∏è –ù–µ–º–∞—î –æ—Å—Ç–∞–Ω–Ω—å–æ—ó –¥—ñ—ó –¥–ª—è –ø–æ—è—Å–Ω–µ–Ω–Ω—è\n")
            return

        try:
            with open(".ben_memory.json", "r", encoding="utf-8") as f:
                memory = json.load(f)

            # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –∫–æ–º–∞–Ω–¥—É –∑–∞ last_action_id
            cmd = next((item for item in reversed(memory) if item.get("history_id") == self.last_action_id), None)
            if not cmd:
                self.chat_display.insert(tk.END, f"‚ö†Ô∏è –ö–æ–º–∞–Ω–¥—É –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {self.last_action_id}\n")
                return

            code = cmd.get("code") or cmd.get("content")
            if not code:
                self.chat_display.insert(tk.END, f"‚ö†Ô∏è –ù–µ–º–∞—î –∫–æ–¥—É –¥–ª—è –ø–æ—è—Å–Ω–µ–Ω–Ω—è\n")
                return

            client = OpenAI(api_key=API_KEY)
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "–ü–æ—è—Å–Ω–∏, —â–æ —Ä–æ–±–∏—Ç—å —Ü–µ–π Python-–∫–æ–¥ —Å—Ç–∏—Å–ª–æ –π –∑—Ä–æ–∑—É–º—ñ–ª–æ:"},
                    {"role": "user", "content": code}
                ],
                temperature=0.4
            )

            explanation = response.choices[0].message.content.strip()
            self.chat_display.insert(tk.END, f"üß† –ü–æ—è—Å–Ω–µ–Ω–Ω—è –æ—Å—Ç–∞–Ω–Ω—å–æ—ó –¥—ñ—ó:\n{explanation}\n\n")
            self.chat_display.see(tk.END)

        except Exception as e:
            self.chat_display.insert(tk.END, f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø–æ—è—Å–Ω–µ–Ω–Ω—è: {e}\n")
    
    def analyze_all_code(self):
        base_dir = os.path.abspath("..")
        all_code = ""
        scanned_files = []

        for root_dir, _, files in os.walk(base_dir):
            if any(x in root_dir for x in ["__pycache__", ".git", "venv"]):
                continue
            for file in files:
                if file.endswith(".py"):
                    file_path = os.path.join(root_dir, file)
                    try:
                        with open(file_path, "r", encoding="utf-8") as f:
                            content = f.read()
                            relative = os.path.relpath(file_path, base_dir)
                            all_code += f"# –§–∞–π–ª: {relative}\n{content}\n\n"
                            scanned_files.append(relative)
                    except:
                        continue

        if not all_code.strip():
            self.chat_display.insert(tk.END, "‚ö†Ô∏è –ù–µ–º–∞—î .py —Ñ–∞–π–ª—ñ–≤ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É\n\n")
            return

        # üîé –ó–∞–ø–∏—Å—É—î–º–æ –ª–æ–≥ –ø—Ä–æ —Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è
        log_path = os.path.join(base_dir, "debug.log")
        with open(log_path, "a", encoding="utf-8") as log:
            log.write(f"[GPT] üîç –°–∫–∞–Ω–æ–≤–∞–Ω–æ {len(scanned_files)} —Ñ–∞–π–ª—ñ–≤:\n")
            for name in scanned_files:
                log.write(f" - {name}\n")

        try:
            client = OpenAI(api_key=API_KEY)
            analyzing = True
            iteration = 1

            while analyzing:
                self.chat_display.insert(tk.END, f"üîé GPT: –ê–Ω–∞–ª—ñ–∑ —ñ—Ç–µ—Ä–∞—Ü—ñ—è {iteration}...\n")
                self.chat_display.see(tk.END)

                response = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π –Ω–∞–≤–µ–¥–µ–Ω–∏–π –∫–æ–¥. –Ø–∫—â–æ –≤—Å–µ –¥–æ–±—Ä–µ ‚Äî –Ω–∞–ø–∏—à–∏ '‚úÖ –í—Å–µ –¥–æ–±—Ä–µ'. –Ø–∫—â–æ —î –ø–æ–º–∏–ª–∫–∏ ‚Äî –∑–≥–µ–Ω–µ—Ä—É–π JSON-–∫–æ–º–∞–Ω–¥—É —É —Ñ–æ—Ä–º–∞—Ç—ñ Ben –¥–ª—è —ó—Ö –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è."},
                        {"role": "user", "content": all_code}
                    ],
                    temperature=0.4
                )

                result = response.choices[0].message.content.strip()
                self.chat_display.insert(tk.END, f"ü§ñ GPT:\n{result}\n\n")
                self.chat_display.see(tk.END)

                with open(log_path, "a", encoding="utf-8") as log:
                    log.write(f"[GPT] üìä –†–µ–∑—É–ª—å—Ç–∞—Ç —ñ—Ç–µ—Ä–∞—Ü—ñ—ó {iteration}:\n{result}\n\n")

                if "‚úÖ" in result:
                    analyzing = False
                    break

                try:
                    command = json.loads(result)
                    with open("cache.txt", "w", encoding="utf-8") as f:
                        f.write(json.dumps(command, indent=2, ensure_ascii=False))
                    exec_result = handle_command(command)
                    self.chat_display.insert(tk.END, f"üì§ –í–∏–∫–æ–Ω–∞–Ω–æ: {exec_result.get('message', '‚õî –ù–µ–≤—ñ–¥–æ–º–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å')}\n\n")
                    self.chat_display.see(tk.END)
                except Exception as e:
                    self.chat_display.insert(tk.END, f"‚ùå –ü–æ–º–∏–ª–∫–∞ JSON-–∫–æ–º–∞–Ω–¥–∏ –∞–±–æ —ó—ó –≤–∏–∫–æ–Ω–∞–Ω–Ω—è: {e}\n\n")
                    break

                time.sleep(1)
                iteration += 1

        except Exception as e:
            self.chat_display.insert(tk.END, f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∞–Ω–∞–ª—ñ–∑—É GPT: {e}\n\n")


if __name__ == "__main__":
    root = tk.Tk()
    app = BenAssistantGUI(root)
    root.mainloop()
