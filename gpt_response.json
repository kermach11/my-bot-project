[
  {
    "status": "ok",
    "message": "üìÇ –£—Å–ø—ñ—à–Ω–æ –ø—Ä–æ—Å–∫–∞–Ω–æ–≤–∞–Ω–æ –≤—Å—ñ —Ñ–∞–π–ª–∏",
    "files": {
      ".\\auto_feedback.py": "import json\nimport os\nfrom datetime import datetime\nfrom gpt_interpreter import interpret_user_prompt\n\ndef run_feedback_analysis():\n    print(\"üîÑ –ü–æ—á–∏–Ω–∞—é –∞–Ω–∞–ª—ñ–∑...\")\n\n    try:\n        with open(\"gpt_response.json\", \"r\", encoding=\"utf-8\") as f:\n            response = json.load(f)\n\n        if isinstance(response, list):\n            response = response[-1]\n\n        filename = response.get(\"filename\") or response.get(\"file_path\")\n\n        # üõ°Ô∏è –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ç–∏–ø—É —Ñ–∞–π–ª—É ‚Äî –∞–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —Ç—ñ–ª—å–∫–∏ .py\n        if filename and not filename.endswith(\".py\"):\n            print(f\"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ –∞–Ω–∞–ª—ñ–∑: '{filename}' –Ω–µ —î Python-—Ñ–∞–π–ª–æ–º\")\n            return\n\n        prompt = f\"\"\"\n–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π –Ω–∞—Å—Ç—É–ø–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å GPT –Ω–∞ –≤–∏–∫–æ–Ω–∞–Ω—É –¥—ñ—é. –í–∏–∑–Ω–∞—á:\n- –ß–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –æ—á—ñ–∫—É–≤–∞–Ω–Ω—é?\n- –Ø–∫—â–æ –Ω—ñ ‚Äî —â–æ –≤–∏–ø—Ä–∞–≤–∏—Ç–∏?\n- –Ø–∫–∏–π –Ω–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫ –ª–æ–≥—ñ—á–Ω–∏–π?\n\n–û—Å—å –≤—ñ–¥–ø–æ–≤—ñ–¥—å:\n{json.dumps(response, indent=2, ensure_ascii=False)}\n\"\"\"\n\n        result = interpret_user_prompt(prompt)\n        print(f\"[DEBUG] GPT –ø–æ–≤–µ—Ä–Ω—É–≤:\\n{result}\\n\")\n\n        if not isinstance(result, str):\n            raise ValueError(\"GPT –ø–æ–≤–µ—Ä–Ω—É–≤ None –∞–±–æ –Ω–µ—Å—Ç—Ä–æ–∫–æ–≤–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç\")\n\n        timestamp = datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n        filename = f\"feedback_report_{timestamp}.txt\"\n\n        with open(filename, \"w\", encoding=\"utf-8\") as f:\n            f.write(result)\n\n        print(f\"üìù Feedback –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {filename}\")\n\n    except Exception as e:\n        print(f\"‚ùå Feedback –ø–æ–º–∏–ª–∫–∞: {e}\")\n\nif __name__ == \"__main__\":\n    print(\"‚úÖ –Ü–º–ø–æ—Ä—Ç –ø—Ä–æ–π—à–æ–≤ —É—Å–ø—ñ—à–Ω–æ\")\n    run_feedback_analysis()\n",
      ".\\auto_macro_loop.py": "import time\nimport json\nfrom datetime import datetime\nfrom gpt_interpreter import interpret_user_prompt\n\nINTERVAL_MINUTES = 10\n\ndef log_debug(message):\n    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    with open(\"debug.log\", \"a\", encoding=\"utf-8\") as f:\n        f.write(f\"[{timestamp}] {message}\\n\")\n\ndef loop():\n    while True:\n        try:\n            now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n            print(f\"[{now}] ‚è≥ GPT –∞–≤—Ç–æ–æ–Ω–æ–≤–ª–µ–Ω–Ω—è –º–∞–∫—Ä–æ—Å—É...\")\n            log_debug(\"‚è≥ GPT –∞–≤—Ç–æ–æ–Ω–æ–≤–ª–µ–Ω–Ω—è –º–∞–∫—Ä–æ—Å—É...\")\n\n            # üîÅ –û–Ω–æ–≤–ª–µ–Ω–Ω—è –º–∞–∫—Ä–æ—Å—É\n            prompt = \"–û–Ω–æ–≤–∏ –º–∞–∫—Ä–æ—Å, —â–æ–± –ø–æ–∫—Ä–∞—â–∏—Ç–∏ —Ä–æ–±–æ—Ç—É –∑ —Ñ–∞–π–ª–∞–º–∏\"\n            gpt_result = interpret_user_prompt(prompt)\n\n            with open(\"macro_command.json\", \"w\", encoding=\"utf-8\") as f:\n                json.dump(gpt_result, f, indent=2)\n\n            print(f\"[{now}] ‚úÖ –ú–∞–∫—Ä–æ—Å –æ–Ω–æ–≤–ª–µ–Ω–æ!\")\n            log_debug(\"‚úÖ –ú–∞–∫—Ä–æ—Å –æ–Ω–æ–≤–ª–µ–Ω–æ\")\n\n            # üîç –ê–≤—Ç–æ–ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–æ–¥—É\n            try:\n                result = interpret_user_prompt(\"–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π —è–∫—ñ—Å—Ç—å –∫–æ–¥—É –≤ –ø—Ä–æ–µ–∫—Ç—ñ —Ç–∞ –∑–Ω–∞–π–¥–∏ —Å–ª–∞–±–∫—ñ –º—ñ—Å—Ü—è\")\n                with open(\"autocheck_report.txt\", \"w\", encoding=\"utf-8\") as f:\n                    f.write(result)\n                print(\"üß™ –ê–≤—Ç–æ–ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞\")\n                log_debug(\"üß™ –ê–≤—Ç–æ–ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞\")\n            except Exception as e:\n                err_msg = f\"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –∞–≤—Ç–æ–ø–µ—Ä–µ–≤—ñ—Ä–∫–∏: {e}\"\n                print(err_msg)\n                log_debug(err_msg)\n\n        except Exception as e:\n            err_msg = f\"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å —Ü–∏–∫–ª—É: {e}\"\n            print(err_msg)\n            log_debug(err_msg)\n\n        time.sleep(INTERVAL_MINUTES * 60)\n\nif __name__ == \"__main__\":\n    loop()\n",
      ".\\ben_assistant_core.py": "\n\ndef create_and_finalize_script(script_name, script_content):\n    \"\"\"\n    Creates a new script file with the given name and content, then performs any finalization steps required.\n    \"\"\"\n    try:\n        with open(script_name, 'w') as script_file:\n            script_file.write(script_content)\n        # Add any additional finalization steps here\n        print(f\"Script {script_name} created and finalized successfully.\")\n    except Exception as e:\n        print(f\"An error occurred while creating the script: {e}\")\n",
      ".\\ben_gui_v2.py": "import sys\nimport os\nsys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n\nimport tkinter as tk\nimport threading\nfrom tkinter import ttk, scrolledtext, Menu\nimport json\nfrom datetime import datetime, timezone\ntimestamp = datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S\")\nfrom gpt_interpreter import interpret_user_prompt, suggest_next_action  # üîå –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä–∞\nfrom gpt_agent_cache import get_command_by_id, handle_command, save_to_memory # üß† –ê–≤—Ç–æ–≤–∏–∫–æ–Ω–∞–Ω–Ω—è –∫–æ–º–∞–Ω–¥\nfrom openai import OpenAI                          # üß† GPT API –¥–ª—è –ø–æ—è—Å–Ω–µ–Ω–Ω—è –∫–æ–¥—É\nfrom config import API_KEY\nimport time\n\n# ‚úÖ –Ü–∫–æ–Ω–∫–∏ –¥–ª—è Autopilot —Å—Ç–∞—Ç—É—Å—É\nAUTOPILOT_ON_ICON = \"üü¢ Autopilot –£–í–Ü–ú–ö–ù–ï–ù–ò–ô\"\nAUTOPILOT_OFF_ICON = \"üî¥ Autopilot –í–ò–ú–ö–ù–ï–ù–ò–ô\"\n\n\ndef generate_ai_insight(response_json):\n    from gpt_interpreter import interpret_user_prompt\n\n    prompt = f\"\"\"\n–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π —Ü—é –¥—ñ—é GPT. –í–∏–∑–Ω–∞—á:\n- –©–æ —Å–∞–º–µ –∑—Ä–æ–±–ª–µ–Ω–æ?\n- –ß–∏ —Ü–µ –±—É–ª–æ –¥–æ—Ü—ñ–ª—å–Ω–æ?\n- –©–æ —Ä–µ–∫–æ–º–µ–Ω–¥—É—î—à –ø–æ–∫—Ä–∞—â–∏—Ç–∏?\n- –Ø–∫–∏–π –Ω–∞—Å—Ç—É–ø–Ω–∏–π –ª–æ–≥—ñ—á–Ω–∏–π –∫—Ä–æ–∫?\n\n–û—Å—å –≤—ñ–¥–ø–æ–≤—ñ–¥—å:–ó\n{json.dumps(response_json, indent=2, ensure_ascii=False)}\n\"\"\"\n\n    try:\n        insight = interpret_user_prompt(prompt)\n        return insight\n    except Exception as e:\n        return f\"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ AI Insight: {e}\"\n    \ndef generate_ai_insight(result):\n    try:\n        from gpt_interpreter import interpret_user_prompt\n        message = result.get(\"message\", \"\")\n        prompt = f\"\"\"\n–Ø–∫–∞ –¥—ñ—è –±—É–ª–∞ —â–æ–π–Ω–æ –≤–∏–∫–æ–Ω–∞–Ω–∞: {message}\n–ó—Ä–æ–±–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –≤–∏—Å–Ω–æ–≤–æ–∫ —É 2-3 —Ä–µ—á–µ–Ω–Ω—è—Ö:\n- –©–æ –∑—Ä–æ–±–ª–µ–Ω–æ?\n- –ß–∏ –≤—Å–µ –≥–∞—Ä–∞–∑–¥?\n- –©–æ –º–æ–∂–Ω–∞ –ø–æ–∫—Ä–∞—â–∏—Ç–∏ –∞–±–æ –Ω–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫?\n\n–ü–∏—à–∏ —è–∫ GPT-–∫–æ–º–µ–Ω—Ç–∞—Ä –¥–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞.\n\"\"\"\n        insight = interpret_user_prompt(prompt)\n        return insight.strip()\n    except Exception as e:\n        return f\"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ AI Insight: {e}\"\n\nclass BenAssistantGUI:\n    def __init__(self, root):\n        self.root = root\n        self.root.title(\"Ben Assistant v2\")\n        self.root.geometry(\"1200x700\")\n\n        self.current_chat_file = None\n        self.chat_history = []\n        self.last_action_id = None\n        self.action_counter = 1  # üî¢ –î–ª—è –ø—Ä–∏—Å–≤–æ—î–Ω–Ω—è —É–Ω—ñ–∫–∞–ª—å–Ω–æ–≥–æ ID –¥—ñ—è–º\n        self.command_counter = 1  # üî¢ –î–ª—è —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö history_id\n        self.current_file_content = \"\"  # üß† –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∫–æ–¥ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ñ–∞–π–ª—É\n        self.start_live_log_updater()\n        self.setup_layout()\n        self.start_feedback_report_updater()\n        self.update_gpt_explanation()\n\n        # üé® –°—Ç–∏–ª—ñ–∑–∞—Ü—ñ—è –¥–ª—è —Ç–µ–≥—É gpt_action  \n        self.chat_display.tag_configure(\"gpt_action\", foreground=\"#0a84ff\", font=(\"Arial\", 10, \"bold\"))\n        self.root.bind_all(\"<Control-c>\", lambda e: self.root.focus_get().event_generate(\"<<Copy>>\"))\n        self.root.bind_all(\"<Control-v>\", lambda e: self.root.focus_get().event_generate(\"<<Paste>>\"))\n        self.root.bind_all(\"<Control-x>\", lambda e: self.root.focus_get().event_generate(\"<<Cut>>\"))\n        self.root.bind_all(\"<Control-a>\", lambda e: self.root.focus_get().event_generate(\"<<SelectAll>>\"))\n\n        os.makedirs(\"chats\", exist_ok=True)\n        self.load_chats()\n\n    def setup_layout(self):\n        self.left_panel = tk.Frame(self.root, width=250, bg=\"#f0f0f0\")\n        self.left_panel.pack(side=\"left\", fill=\"y\")\n        \n        self.project_label = tk.Label(self.left_panel, text=\"üóÇÔ∏è –°—Ç—ñ–ª\", bg=\"#f0f0f0\", font=(\"Arial\", 12, \"bold\"))\n        self.project_label.pack(pady=(10,0))\n\n        self.project_tree = ttk.Treeview(self.left_panel)\n        self.project_tree.pack(expand=True, fill=\"both\", padx=5, pady=(0,5))\n        self.populate_tree(\"C:/Users/DC/my-bot-project\", \"\")\n\n        self.chat_label = tk.Label(self.left_panel, text=\"üí¨ –ß–∞—Ç–∏\", bg=\"#f0f0f0\", font=(\"Arial\", 12, \"bold\"))\n        self.chat_label.pack(pady=(10, 0))\n\n        self.chat_list = tk.Listbox(self.left_panel)\n        self.chat_list.pack(fill=\"both\", expand=False, padx=5, pady=(0, 10))\n        self.chat_list.bind(\"<<ListboxSelect>>\", self.load_selected_chat)\n\n        self.center_panel = tk.Frame(self.root, bg=\"#ffffff\")\n        self.center_panel.pack(side=\"left\", fill=\"both\", expand=True)\n\n        self.notebook = ttk.Notebook(self.center_panel)\n        self.notebook.pack(fill=\"both\", expand=True, padx=10, pady=(10, 0))\n\n        # üì¶ MacroBuilder Tab\n        self.macro_tab = ttk.Frame(self.notebook)\n        self.notebook.add(self.macro_tab, text=\"üì¶ MacroBuilder\")\n\n        ttk.Label(self.macro_tab, text=\"üß± –ü–æ–±—É–¥–æ–≤–∞ Macro-–∫—Ä–æ–∫—ñ–≤\", font=(\"Arial\", 12, \"bold\")).pack(pady=10)\n\n        self.macro_steps_box = scrolledtext.ScrolledText(self.macro_tab, height=15, wrap=\"word\")\n        self.macro_steps_box.pack(fill=\"both\", expand=True, padx=10)\n\n        self.generate_macro_btn = tk.Button(self.macro_tab, text=\"ü™Ñ –ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –∑ –ø—Ä–æ–º–ø—Ç—É\", command=self.generate_macro_from_prompt)\n        self.generate_macro_btn.pack(pady=5)\n\n        self.run_macro_btn = tk.Button(self.macro_tab, text=\"üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç–∏ Macro\", command=self.run_macro_from_text)\n        self.run_macro_btn.pack(pady=5)\n\n        self.chat_display = scrolledtext.ScrolledText(self.center_panel, wrap=\"word\", height=30)\n        self.chat_display.pack(fill=\"both\", expand=True, padx=10, pady=(10, 0))\n        self.add_context_menu(self.chat_display)\n\n        self.chat_display.tag_bind(\"gpt_action\", \"<Button-1>\", self.on_action_click)\n        self.chat_display.tag_bind(\"gpt_action\", \"<Button-3>\", self.on_action_right_click)\n         \n        self.prompt_entry = tk.Entry(self.center_panel, font=(\"Arial\", 12))\n        self.prompt_entry.pack(fill=\"x\", padx=10, pady=5)\n\n        self.send_button = tk.Button(self.center_panel, text=\"–í—ñ–¥–ø—Ä–∞–≤–∏—Ç–∏\", command=self.send_prompt)\n        self.send_button.pack(padx=10, pady=(0,10))\n        \n        self.right_panel = tk.Frame(self.root, width=400, bg=\"#f9f9f9\")\n        self.right_panel.pack(side=\"right\", fill=\"y\")\n\n        self.autopilot_button = tk.Button(self.center_panel, text=\"üß† Autopilot\", command=self.run_autopilot_prompt)\n        self.autopilot_button.pack(padx=10, pady=(0,5))\n\n        # –î–æ–¥–∞—î–º–æ –∫–Ω–æ–ø–∫—É –¥–ª—è –∑—É–ø–∏–Ω–∫–∏ –∞–≤—Ç–æ–ø—ñ–ª–æ—Ç–∞\n        self.stop_autopilot_btn = tk.Button(self.right_panel, text=\"üõë –ó—É–ø–∏–Ω–∏—Ç–∏ Autopilot\", command=self.stop_autopilot)\n        self.stop_autopilot_btn.pack(pady=5)\n\n        # üü¢/üî¥ –°—Ç–∞—Ç—É—Å –∞–≤—Ç–æ–ø—ñ–ª–æ—Ç–∞\n        self.autopilot_status_label = tk.Label(self.right_panel, text=AUTOPILOT_OFF_ICON, font=(\"Arial\", 10, \"bold\"), fg=\"green\")\n        self.autopilot_status_label.pack(pady=5)\n\n        self.code_label = tk.Label(self.right_panel, text=\"üëÅÔ∏è –ü–æ–ø–µ—Ä–µ–¥–Ω—ñ–π –∫–æ–¥\", bg=\"#f9f9f9\", font=(\"Arial\", 12, \"bold\"))\n        self.code_label.pack(pady=10)\n\n        self.code_preview = scrolledtext.ScrolledText(self.right_panel, wrap=\"none\", height=30)\n        self.code_preview.pack(fill=\"both\", expand=True, padx=10)\n        self.add_context_menu(self.code_preview)\n\n        self.explain_button = tk.Button(self.right_panel, text=\"üß† –ü–æ—è—Å–Ω–∏ –∫–æ–¥ —Å–ø—Ä–∞–≤–∞\", command=self.explain_code_preview)\n        self.explain_button.pack(pady=5)\n\n        # üìä –û–±–ª–∞—Å—Ç—å –¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –æ—Å—Ç–∞–Ω–Ω—å–æ–≥–æ Feedback\n        feedback_frame = ttk.LabelFrame(self.right_panel, text=\"üìä GPT Feedback\")\n        feedback_frame.pack(fill=\"both\", expand=True, padx=10, pady=10)\n\n        self.feedback_area = scrolledtext.ScrolledText(feedback_frame, wrap=\"word\", height=10)\n        self.feedback_area.pack(fill=\"both\", expand=True)\n\n        self.analyze_all_button = tk.Button(self.right_panel, text=\"üß† –ê–Ω–∞–ª—ñ–∑—É–π –≤–µ—Å—å —Å—Ç—ñ–ª\", command=self.analyze_all_code)\n        self.analyze_all_button.pack(pady=5)\n\n        self.explain_last_action_button = tk.Button(\n            self.right_panel,\n            text=\"üß† –ü–æ—è—Å–Ω–∏ –æ—Å—Ç–∞–Ω–Ω—é –¥—ñ—é\",\n            command=self.explain_last_action\n        )\n        self.explain_last_action_button.pack(pady=5)\n\n        # üìò GPT –ü–æ—è—Å–Ω–µ–Ω–Ω—è\n        explanation_label = tk.Label(self.right_panel, text=\"üß† GPT –ü–æ—è—Å–Ω–µ–Ω–Ω—è:\", bg=\"#f9f9f9\", font=(\"Arial\", 10, \"bold\"))\n        explanation_label.pack(anchor=\"w\", padx=10, pady=(10, 0))\n\n        self.gpt_explanation_area = tk.Text(self.right_panel, height=6, wrap=\"word\", bg=\"#f5f5f5\")\n        self.gpt_explanation_area.pack(fill=\"x\", padx=10, pady=5)\n        self.gpt_explanation_area.insert(tk.END, \"‚Äî –¢—É—Ç –∑ º—è–≤–ª—è—Ç–∏–º–µ—Ç—å—Å—è GPT –ø–æ—è—Å–Ω–µ–Ω–Ω—è –ø—ñ—Å–ª—è –∞–≤—Ç–æ—Ñ—ñ–∫—Å—É ‚Äî\")\n        self.gpt_explanation_area.configure(state=\"disabled\")\n      \n    def add_context_menu(self, widget):\n        menu = Menu(widget, tearoff=0)\n        menu.add_command(label=\"–ö–æ–ø—ñ—é–≤–∞—Ç–∏\", command=lambda: widget.event_generate(\"<<Copy>>\"))\n        menu.add_command(label=\"–í—Å—Ç–∞–≤–∏—Ç–∏\", command=lambda: widget.event_generate(\"<<Paste>>\"))\n        menu.add_command(label=\"–í–∏—Ä—ñ–∑–∞—Ç–∏\", command=lambda: widget.event_generate(\"<<Cut>>\"))\n        menu.add_command(label=\"–í–∏–¥—ñ–ª–∏—Ç–∏ –≤—Å–µ\", command=lambda: widget.event_generate(\"<<SelectAll>>\"))\n\n        def show_menu(event):\n            menu.tk_popup(event.x_root, event.y_root)\n\n        widget.bind(\"<Button-3>\", show_menu)\n\n\n    def start_live_log_updater(self):\n        def update_loop():\n            prev_log = \"\"\n            while True:\n                try:\n                    with open(\"debug.log\", \"r\", encoding=\"utf-8\") as f:\n                        log = f.read()\n                    if log != prev_log:\n                        self.response_area.delete(\"1.0\", tk.END)\n                        self.response_area.insert(tk.END, log[-5000:])  # –æ—Å—Ç–∞–Ω–Ω—ñ 5000 —Å–∏–º–≤–æ–ª—ñ–≤\n                        prev_log = log\n                    time.sleep(5)\n                except:\n                    pass\n        threading.Thread(target=update_loop, daemon=True).start()\n\n    def start_feedback_report_updater(self):\n        def update_loop():\n            prev_report = \"\"\n            while True:\n                try:\n                    files = sorted(\n                        [f for f in os.listdir() if f.startswith(\"feedback_report_\") and f.endswith(\".txt\")],\n                        reverse=True\n                    )\n                    if files:\n                        latest = files[0]\n                        with open(latest, \"r\", encoding=\"utf-8\") as f:\n                            content = f.read()\n                        if content != prev_report:\n                            timestamp = latest.replace(\"feedback_report_\", \"\").replace(\".txt\", \"\")\n                            self.chat_display.insert(tk.END, f\"\\nüß† GPT Feedback ({timestamp}):\\n\", \"gpt_action\")\n                            self.chat_display.insert(tk.END, content + \"\\n\")\n                            self.chat_display.see(tk.END)\n                            prev_report = content\n                    time.sleep(6)\n                except Exception as e:\n                    print(\"‚ùå Feedback log error:\", e)\n                    time.sleep(6)\n        threading.Thread(target=update_loop, daemon=True).start()\n\n    def explain_code_preview(self):\n        code = self.code_preview.get(\"1.0\", tk.END).strip()\n        if not code:\n            self.chat_display.insert(tk.END, \"‚ö†Ô∏è –ù–µ–º–∞—î –∫–æ–¥—É –¥–ª—è –ø–æ—è—Å–Ω–µ–Ω–Ω—è\\n\\n\")\n            return\n\n        try:\n            client = OpenAI(api_key=API_KEY)\n            response = client.chat.completions.create(\n                model=\"gpt-4o\",\n                messages=[\n                    {\"role\": \"system\", \"content\": \"–ü–æ—è—Å–Ω–∏, —â–æ —Ä–æ–±–∏—Ç—å –Ω–∞—Å—Ç—É–ø–Ω–∏–π Python-–∫–æ–¥ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Å—Ç–∏—Å–ª–æ:\"},\n                    {\"role\": \"user\", \"content\": code}\n                ],\n                temperature=0.5\n            )\n            explanation = response.choices[0].message.content.strip()\n            self.chat_display.insert(tk.END, f\"ü§ñ –ü–æ—è—Å–Ω–µ–Ω–Ω—è –∫–æ–¥—É:\\n{explanation}\\n\\n\")\n            self.chat_display.see(tk.END)\n\n        except Exception as e:\n            self.chat_display.insert(tk.END, f\"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø–æ—è—Å–Ω–µ–Ω–Ω—è –∫–æ–¥—É: {e}\\n\\n\")\n\n    def update_gpt_explanation(self):\n        path = os.path.join(\"last_gpt_explanation.txt\")\n        if os.path.exists(path):\n            with open(path, \"r\", encoding=\"utf-8\") as f:\n                text = f.read()\n            self.gpt_explanation_area.configure(state=\"normal\")\n            self.gpt_explanation_area.delete(\"1.0\", tk.END)\n            self.gpt_explanation_area.insert(tk.END, text)\n            self.gpt_explanation_area.configure(state=\"disabled\")\n        \n    def run_autopilot_prompt(self):\n        user_input = self.prompt_entry.get()\n        if not user_input.strip():\n            return\n\n        self.chat_display.insert(tk.END, f\"ü§ñ [Autopilot] {user_input}\\n\")\n        self.chat_history.append({\"role\": \"user\", \"content\": user_input})\n\n        try:\n            from gpt_interpreter import interpret_user_prompt\n            from gpt_agent_cache import handle_command \n            from utils import save_to_memory\n\n            response_json = interpret_user_prompt(user_input, context_code=\"ALL\", history_context=True, return_data=True, macro_learning=True)\n\n            if response_json:\n                history_id = f\"auto_{self.command_counter:03}\"\n                response_json[\"history_id\"] = history_id\n                if self.last_action_id:\n                    response_json[\"target_id\"] = self.last_action_id\n                self.last_action_id = history_id\n\n                self.chat_display.insert(tk.END, f\"üß† GPT Autopilot –∑–≥–µ–Ω–µ—Ä—É–≤–∞–≤ –¥—ñ—é ‚úÖ [{history_id}]\\n\", \"gpt_action\")\n                self.chat_display.insert(tk.END, f\"üì© –ö–æ–º–∞–Ω–¥—É –∑–±–µ—Ä–µ–∂–µ–Ω–æ\\n\", \"gpt_action\")\n\n                save_to_memory(response_json)\n                result = handle_command(response_json)\n                self.chat_display.insert(tk.END, f\"üì§ –í–∏–∫–æ–Ω–∞–Ω–æ: {result.get('message', '‚õî –ù–µ–≤—ñ–¥–æ–º–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å')}\\n\")\n                self.chat_history.append({\"role\": \"assistant\", \"content\": result.get('message', '')})\n                \n                # üí° Smart Suggestion ‚Äî –Ω–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫ GPT\n                try:\n                    suggestion = suggest_next_action(result)\n                    self.chat_display.insert(tk.END, f\"üí° –ù–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫ GPT: {suggestion}\\n\", \"gpt_action\")\n                    self.chat_display.see(tk.END)\n                except Exception as e:\n                    print(\"‚ö†Ô∏è Smart Suggestion –ø–æ–º–∏–ª–∫–∞:\", e)\n\n                try:\n                    from ai_insight import generate_ai_insight\n                    ai_msg = generate_ai_insight(result)\n                    self.chat_display.insert(tk.END, f\"üí¨ AI Insight: {ai_msg}\\n\", \"gpt_action\")\n                except:\n                    pass\n                \n                self.update_gpt_explanation()\n                self.command_counter += 1\n                self.chat_display.insert(tk.END, \"\\n\")\n                self.chat_display.see(tk.END)\n\n        except Exception as e:\n            self.chat_display.insert(tk.END, f\"‚ùå Autopilot –ø–æ–º–∏–ª–∫–∞: {e}\\n\")\n            self.chat_display.see(tk.END)\n\n    def populate_tree(self, path, parent):\n        for item in os.listdir(path):\n            abspath = os.path.join(path, item)\n            isdir = os.path.isdir(abspath)\n            oid = self.project_tree.insert(parent, \"end\", text=item, open=False, values=(abspath,))\n            if isdir:\n                self.populate_tree(abspath, oid)\n\n        self.project_tree.bind(\"<<TreeviewSelect>>\", self.on_file_select)\n\n    def load_chats(self):\n        self.chat_list.delete(0, tk.END)\n        files = sorted(os.listdir(\"chats\"))\n        for f in files:\n            if f.endswith(\".json\"):\n                self.chat_list.insert(tk.END, f)\n\n        if not files:\n            self.create_new_chat()\n\n    def create_new_chat(self):\n        timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n        self.current_chat_file = f\"chats/chat_{timestamp}.json\"\n        self.chat_history = []\n        self.save_chat()\n        self.load_chats()\n        self.chat_list.selection_set(tk.END)\n\n    def load_selected_chat(self, event):\n        selection = self.chat_list.curselection()\n        if not selection:\n            return\n        filename = self.chat_list.get(selection[0])\n        path = os.path.join(\"chats\", filename)\n        try:\n            with open(path, \"r\", encoding=\"utf-8\") as f:\n                self.chat_history = json.load(f)\n            self.current_chat_file = path\n            self.chat_display.delete(\"1.0\", tk.END)\n            for msg in self.chat_history:\n                role = \"üë§\" if msg[\"role\"] == \"user\" else \"ü§ñ GPT\"\n                self.chat_display.insert(tk.END, f\"{role} {msg['content']}\\n\\n\")\n        except:\n            self.chat_display.insert(tk.END, \"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —á–∞—Ç\")\n\n    def save_chat(self):\n        if self.current_chat_file:\n            with open(self.current_chat_file, \"w\", encoding=\"utf-8\") as f:\n                json.dump(self.chat_history, f, indent=2, ensure_ascii=False)\n\n    def on_file_select(self, event):\n        selected = self.project_tree.focus()\n        path = self.project_tree.item(selected, \"values\")[0]\n        if os.path.isfile(path):\n            try:\n                with open(path, \"r\", encoding=\"utf-8\") as f:\n                    content = f.read()\n                self.current_file_content = content\n                self.code_preview.delete(\"1.0\", tk.END)\n                self.code_preview.insert(tk.END, content)\n            except Exception as e:\n                self.code_preview.delete(\"1.0\", tk.END)\n                self.code_preview.insert(tk.END, f\"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –≤—ñ–¥–∫—Ä–∏—Ç–∏ —Ñ–∞–π–ª: {e}\")\n\n    def send_prompt(self):\n        user_input = self.prompt_entry.get()\n        if not user_input.strip():\n            return\n\n        self.chat_display.insert(tk.END, f\"üë§ {user_input}\\n\")\n        self.chat_history.append({\"role\": \"user\", \"content\": user_input})\n\n        try:\n            # ‚è≥ –ë–µ—Ä–µ–º–æ —Ç—ñ–ª—å–∫–∏ –æ—Å—Ç–∞–Ω–Ω—ñ 10 –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å –∑ —ñ—Å—Ç–æ—Ä—ñ—ó\n            history_block = json.dumps(self.chat_history[-10:], ensure_ascii=False, indent=2)\n\n            response_json = interpret_user_prompt(\n                user_input,\n                context_code=\"ALL\",  # –∞–±–æ self.current_file_content, —è–∫—â–æ —Ö–æ—á–µ—à –ø–æ—Ç–æ—á–Ω–∏–π —Ñ–∞–π–ª\n                history_context=history_block,  # –í—Å—Ç–∞–≤–ª—è—î–º–æ –æ–±–º–µ–∂–µ–Ω—É —ñ—Å—Ç–æ—Ä—ñ—é\n                return_data=True\n            )\n\n            # üÜî –ì–µ–Ω–µ—Ä—É—î–º–æ ID –¥–ª—è –¥—ñ—ó\n            history_id = f\"id_{self.action_counter:03}\"\n            assistant_msg = f\"GPT: –ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ –¥—ñ—é ‚úÖ [{history_id}]\"\n            self.action_counter += 1\n\n            # üíæ –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ü–µ–π ID —è–∫ –æ—Å—Ç–∞–Ω–Ω—é –¥—ñ—é\n            self.last_action_id = history_id\n\n            self.chat_display.insert(tk.END, f\"ü§ñ {assistant_msg}\\n\", \"gpt_action\")\n            self.chat_history.append({\"role\": \"assistant\", \"content\": assistant_msg})\n\n            if response_json:\n                code = response_json.get(\"code\") or response_json.get(\"content\")\n                if code:\n                    self.code_preview.delete(\"1.0\", tk.END)\n                    self.code_preview.insert(tk.END, code)\n\n                # üß© –ì–µ–Ω–µ—Ä—É—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω–∏–π ID –¥–ª—è –∫–æ–º–∞–Ω–¥–∏\n                history_id = f\"cmd_{self.command_counter:03}\"\n                response_json[\"history_id\"] = history_id\n\n                # ‚úÖ –î–æ–¥–∞—î–º–æ —Ç–∞–∫–æ–∂ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –æ—Å—Ç–∞–Ω–Ω—é –¥—ñ—é –¥–ª—è rollback\n                if self.last_action_id:\n                    response_json[\"target_id\"] = self.last_action_id\n\n                with open(\"cache.txt\", \"w\", encoding=\"utf-8\") as f:\n                    f.write(json.dumps(response_json, indent=2, ensure_ascii=False))\n\n                self.chat_display.insert(tk.END, f\"üì© [{history_id}] –ö–æ–º–∞–Ω–¥—É –∑–∞–ø–∏—Å–∞–Ω–æ –≤ cache.txt\\n\", \"gpt_action\")\n                self.command_counter += 1\n                \n                save_to_memory(response_json)  # üíæ –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ø–æ–≤–Ω—É –∫–æ–º–∞–Ω–¥—É –∑ code/content\n\n                result = handle_command(response_json)\n                self.chat_display.insert(tk.END, f\"üì§ –í–∏–∫–æ–Ω–∞–Ω–æ: {result.get('message', '‚õî –ù–µ–≤—ñ–¥–æ–º–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å')}\\n\")\n                self.chat_history.append({\"role\": \"assistant\", \"content\": result.get('message', '‚õî –ù–µ–≤—ñ–¥–æ–º–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å')})\n                # üí° Smart Suggestion ‚Äî –Ω–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫ GPT\n                try:\n                    suggestion = suggest_next_action(result)\n                    self.chat_display.insert(tk.END, f\"üí° –ù–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫ GPT: {suggestion}\\n\", \"gpt_action\")\n                    self.chat_display.see(tk.END)\n                except Exception as e:\n                    print(\"‚ö†Ô∏è Smart Suggestion –ø–æ–º–∏–ª–∫–∞:\", e)\n\n                # üß† AI Insight –ø—ñ—Å–ª—è –≤–∏–∫–æ–Ω–∞–Ω–Ω—è\n                try:\n                    ai_insight = generate_ai_insight(result)\n                    self.chat_display.insert(tk.END, f\"üß† AI Insight: {ai_insight}\\n\", \"gpt_action\")\n                    self.chat_display.see(tk.END)\n                except Exception as insight_err:\n                    print(\"‚ö†Ô∏è AI Insight –ø–æ–º–∏–ª–∫–∞:\", insight_err)\n     \n        except Exception as e:\n            self.chat_display.insert(tk.END, f\"‚ùå –ü–æ–º–∏–ª–∫–∞ GPT: {e}\\n\")\n            self.chat_history.append({\"role\": \"assistant\", \"content\": f\"‚ùå –ü–æ–º–∏–ª–∫–∞ GPT: {e}\"})\n        \n        self.update_gpt_explanation()\n        self.chat_display.insert(tk.END, \"\\n\")\n        self.chat_display.see(tk.END)\n        self.prompt_entry.delete(0, tk.END)\n        self.save_chat()\n\n    def generate_macro_from_prompt(self):\n        prompt = self.prompt_entry.get()\n        if not prompt.strip():\n            return\n\n        try:\n            from gpt_macro_builder import generate_macro_steps_from_prompt\n            result = generate_macro_steps_from_prompt(prompt, include_macro_context=True)\n            if result.get(\"status\") == \"success\":\n                steps_json = json.dumps(result[\"steps\"], indent=2, ensure_ascii=False)\n                self.macro_steps_box.delete(\"1.0\", tk.END)\n                self.macro_steps_box.insert(tk.END, steps_json)\n            else:\n                self.macro_steps_box.insert(tk.END, result.get(\"message\", \"‚ùå –ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –∫—Ä–æ–∫—ñ–≤\"))\n        except Exception as e:\n            self.macro_steps_box.insert(tk.END, f\"‚ùå –í–Ω—É—Ç—Ä—ñ—à–Ω—è –ø–æ–º–∏–ª–∫–∞: {e}\")\n\n\n    def run_macro_from_text(self):\n        try:\n            import json\n            from gpt_agent_cache import handle_command\n            steps_text = self.macro_steps_box.get(\"1.0\", tk.END)\n            steps = json.loads(steps_text)\n            cmd = {\"action\": \"macro\", \"steps\": steps}\n            result = handle_command(cmd)\n            self.chat_display.insert(tk.END, f\"üöÄ Macro –≤–∏–∫–æ–Ω–∞–Ω–æ: {result.get('message', '')}\\n\", \"gpt_action\")\n            self.chat_display.see(tk.END)\n        except Exception as e:\n            self.chat_display.insert(tk.END, f\"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–ø—É—Å–∫—É macro: {e}\\n\", \"gpt_action\")\n   \n    # ‚úÖ AUTOPILOT 2.0 –£–¥–æ—Å–∫–æ–Ω–∞–ª–µ–Ω–∏–π —Ü–∏–∫–ª\n    # –¶–µ–π –∫–æ–¥ –ø–æ—Ç—Ä—ñ–±–Ω–æ –≤—Å—Ç–∞–≤–∏—Ç–∏ –∑–∞–º—ñ—Å—Ç—å —ñ—Å–Ω—É—é—á–æ–≥–æ start_autopilot —É –∫–ª–∞—Å—ñ BenAssistantGUI\n\n    def start_autopilot(self):\n        import threading, time, json\n        import tiktoken\n        from gpt_interpreter import interpret_user_prompt, generate_ai_insight, suggest_next_action\n\n        MAX_TOKENS = 25000\n        AUTOPILOT_DELAY = 45  # —Å–µ–∫—É–Ω–¥–∞ –º—ñ–∂ –¥—ñ—è–º–∏\n        command_queue = []\n        is_paused = False\n\n        def count_tokens(text):\n            try:\n                enc = tiktoken.encoding_for_model(\"gpt-4\")\n                return len(enc.encode(text))\n            except:\n                return len(text.split())\n\n        def autopilot_loop():\n            nonlocal is_paused\n            self.autopilot_running = True\n            self.autopilot_status_label.config(text=AUTOPILOT_ON_ICON, fg=\"green\")\n            self.chat_display.insert(tk.END, \"üß† Autopilot —É–≤—ñ–º–∫–Ω–µ–Ω–æ. GPT —Å–∞–º –∫–µ—Ä—É—î –¥—ñ—è–º–∏...\\n\", \"gpt_action\")\n            self.chat_display.see(tk.END)\n\n            prompt = \"–ü—Ä–æ—Å—Ç–æ —Å–∫–∞–∂–∏ –ü—Ä–∏–≤—ñ—Ç\"\n\n            while self.autopilot_running:\n                if is_paused:\n                    time.sleep(3)\n                    continue\n\n                try:\n                    # –ö–æ–Ω—Ç–µ–∫—Å—Ç\n                    context = self.current_file_content [:5000] \n                    history_block = json.dumps(self.chat_history[-5:], ensure_ascii=False)  # –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è, –ª–∏—à–µ –æ—Å—Ç–∞–Ω–Ω—ñ 5\n                    total_tokens = count_tokens(prompt) + count_tokens(context) + count_tokens(history_block)\n\n                    if total_tokens > MAX_TOKENS:\n                        self.chat_display.insert(tk.END, f\"‚ö†Ô∏è –ë–∞–≥–∞—Ç–æ —Ç–æ–∫–µ–Ω—ñ–≤ ({total_tokens}). GPT –∑–∞—á–µ–∫–∞—î...\\n\", \"gpt_action\")\n                        time.sleep(20)\n                        continue\n\n                    self.chat_display.insert(tk.END, f\"üë§ {prompt}\\n\", \"gpt_action\")\n\n                    # GPT –¥—ñ–∞–ª–æ–≥\n                    response_json = interpret_user_prompt(\n                        prompt,\n                        context_code=context,\n                        history_context=history_block,\n                        return_data=True\n                    )\n\n                    if not isinstance(response_json, dict):\n                        self.chat_display.insert(tk.END, \"‚ùå GPT –Ω–µ –ø–æ–≤–µ—Ä–Ω—É–≤ JSON. –ü–æ–≤—Ç–æ—Ä...\\n\", \"gpt_action\")\n                        prompt = \"‚ùå GPT –Ω–µ –¥–∞–≤ –¥—ñ—ó. –ü–æ–≤—Ç–æ—Ä–∏—Ç–∏...\"\n                        time.sleep(5)\n                        continue\n\n                    gpt_text = response_json.get(\"comment\") or response_json.get(\"message\") or \"ü§ñ GPT: –î—ñ—è —Å—Ñ–æ—Ä–º–æ–≤–∞–Ω–∞.\"\n                    self.chat_display.insert(tk.END, f\"{gpt_text}\\n\", \"gpt_action\")\n\n                    history_id = f\"auto_{self.command_counter:03}\"\n                    response_json[\"history_id\"] = history_id\n                    if self.last_action_id:\n                        response_json[\"target_id\"] = self.last_action_id\n                    self.last_action_id = history_id\n\n                    # –ö–æ–º–∞–Ω–¥—É –¥–æ–¥–∞—î–º–æ –≤ —á–µ—Ä–≥—É\n                    command_queue.append(response_json)\n                    self.command_counter += 1\n\n                    # –Ø–∫—â–æ —á–µ—Ä–≥–∞ —î ‚Äî –æ–±—Ä–æ–±–ª—è—î–º–æ\n                    while command_queue:\n                        cmd = command_queue.pop(0)\n\n                    with open(\"cache.txt\", \"w\", encoding=\"utf-8\") as f:\n                        f.write(json.dumps(cmd, indent=2, ensure_ascii=False))\n\n                    self.chat_display.insert(tk.END, f\"üì© [{cmd['history_id']}] –ó–∞–ø–∏—Å–∞–Ω–æ –≤ cache.txt\\n\", \"gpt_action\")\n\n                    result = handle_command(cmd)\n                    self.chat_display.insert(tk.END, f\"üì§ –í–∏–∫–æ–Ω–∞–Ω–æ: {result.get('message', '‚õî')}\\n\", \"gpt_action\")\n\n                    try:\n                        insight = generate_ai_insight(result)\n                        self.chat_display.insert(tk.END, f\"üß† Insight: {insight}\\n\", \"gpt_action\")\n                    except:\n                        pass\n\n                    try:\n                        suggestion = suggest_next_action(result)\n                        self.chat_display.insert(tk.END, f\"üí° GPT –ø—Ä–æ–ø–æ–Ω—É—î: {suggestion}\\n\", \"gpt_action\")\n                        prompt = f\"üìå –ù–∞—Å—Ç—É–ø–Ω–∞ –¥—ñ—è –ø—ñ—Å–ª—è: {suggestion}\"\n                    except:\n                        prompt = f\"üìå –ù–∞—Å—Ç—É–ø–Ω–∞ –¥—ñ—è –ø—ñ—Å–ª—è: {result.get('message', '')}\"\n\n                    self.chat_display.insert(tk.END, \"\\n\")\n                    self.chat_display.see(tk.END)\n                    time.sleep(AUTOPILOT_DELAY)\n\n                except Exception as e:\n                    self.chat_display.insert(tk.END, f\"‚ùå Autopilot –ø–æ–º–∏–ª–∫–∞: {e}\\n\", \"gpt_action\")\n                    break\n\n        threading.Thread(target=autopilot_loop, daemon=True).start()\n    \n    def stop_autopilot(self):\n        self.autopilot_running = False\n        self.autopilot_status_label.config(text=AUTOPILOT_OFF_ICON, fg=\"red\")\n        self.chat_display.insert(tk.END, \"üõë Autopilot –≤–∏–º–∫–Ω–µ–Ω–æ.\\n\", \"gpt_action\")\n        self.chat_display.see(tk.END)\n\n    def suggest_next_action(response):\n        try:\n            prompt = f\"\"\"\n    –û—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ—ó –¥—ñ—ó GPT:\n    {json.dumps(response, indent=2, ensure_ascii=False)}\n\n    üéØ –ó–∞–ø—Ä–æ–ø–æ–Ω—É–π –Ω–∞—Å—Ç—É–ø–Ω—É –ª–æ–≥—ñ—á–Ω—É –¥—ñ—é —è–∫ –æ–¥–∏–Ω –∫–æ—Ä–æ—Ç–∫–∏–π –æ–ø–∏—Å. –ù–∞–ø—Ä–∏–∫–ª–∞–¥:\n    - –î–æ–¥–∞—Ç–∏ —Ç–µ—Å—Ç –¥–æ test_*.py\n    - –ü–µ—Ä–µ–π–º–µ–Ω—É–≤–∞—Ç–∏ —Ñ—É–Ω–∫—Ü—ñ—é\n    - –î–æ–¥–∞—Ç–∏ –ª–æ–≥—É–≤–∞–Ω–Ω—è\n    - –ü–æ—è—Å–Ω–∏—Ç–∏ –∫–æ–¥\n    \"\"\"\n            from gpt_interpreter import interpret_user_prompt\n            suggestion = interpret_user_prompt(prompt)\n            return suggestion.strip()\n        except Exception as e:\n            return f\"‚ö†Ô∏è Smart Suggestion –ø–æ–º–∏–ª–∫–∞: {e}\"\n\n    def on_action_click(self, event):\n        index = self.chat_display.index(f\"@{event.x},{event.y}\")\n        line = self.chat_display.get(index + \" linestart\", index + \" lineend\")\n\n        self.code_preview.delete(\"1.0\", tk.END)\n        self.code_preview.insert(tk.END, f\"üîç –í–∏ –æ–±—Ä–∞–ª–∏ –¥—ñ—é:\\n{line}\\n\\n\")\n\n        # –ü—ñ–¥—Å–≤—ñ—Ç–∏—Ç–∏ —Ä—è–¥–æ–∫\n        self.chat_display.tag_remove(\"highlighted\", \"1.0\", tk.END)\n        self.chat_display.tag_add(\"highlighted\", index + \" linestart\", index + \" lineend\")\n        self.chat_display.tag_configure(\"highlighted\", background=\"#d0ebff\")\n\n        # –í–∏—Ç—è–≥–Ω—É—Ç–∏ history_id\n        if \"[\" in line and \"]\" in line:\n            start = line.find(\"[\") + 1\n            end = line.find(\"]\")\n            history_id = line[start:end]\n        else:\n            history_id = None\n\n        # –ü–æ–∫–∞–∑–∞—Ç–∏ –∫–æ–¥ –∑ —ñ—Å—Ç–æ—Ä—ñ—ó\n        if history_id:\n            cmd = get_command_by_id(history_id)\n            if cmd:\n                content = cmd.get(\"code\") or cmd.get(\"content\") or \"\"\n                if content:\n                    self.code_preview.insert(tk.END, f\"\\nüì¶ –ö–æ–¥ –∑ ID {history_id}:\\n{content}\")\n\n    def on_action_right_click(self, event):\n        index = self.chat_display.index(f\"@{event.x},{event.y}\")\n        selected_line = self.chat_display.get(index + \" linestart\", index + \" lineend\").strip()\n\n        # –í–∏—Ç—è–≥–Ω—É—Ç–∏ history_id –∑ —Ä—è–¥–∫–∞ (—è–∫—â–æ —î)\n        if \"[\" in selected_line and \"]\" in selected_line:\n            start = selected_line.find(\"[\") + 1\n            end = selected_line.find(\"]\")\n            target_id = selected_line[start:end]\n        else:\n            target_id = None\n\n        def rollback_action():\n            if not target_id:\n                self.chat_display.insert(tk.END, \"‚ö†Ô∏è –ù–µ–º–æ–∂–ª–∏–≤–æ –≤–∏–∑–Ω–∞—á–∏—Ç–∏ history_id –¥–ª—è –≤—ñ–¥–∫–∞—Ç—É\\n\")\n                return\n            try:\n                command = {\"action\": \"undo_change\", \"target_id\": target_id}\n                with open(\"cache.txt\", \"w\", encoding=\"utf-8\") as f:\n                    f.write(json.dumps(command, indent=2, ensure_ascii=False))\n                result = handle_command(command)\n                self.chat_display.insert(tk.END, f\"üîÅ –í—ñ–¥–∫–∞—Ç {target_id}: {result.get('message', '‚õî –ü–æ–º–∏–ª–∫–∞')}\\n\", \"gpt_action\")\n            except Exception as e:\n                self.chat_display.insert(tk.END, f\"‚ùå –ü–æ–º–∏–ª–∫–∞ –≤—ñ–¥–∫–∞—Ç—É: {e}\\n\", \"gpt_action\")\n\n        def delete_action():\n            self.chat_display.insert(tk.END, f\"üóëÔ∏è –í–∏–¥–∞–ª–µ–Ω–æ –¥—ñ—é: {selected_line}\\n\")\n\n        menu = Menu(self.root, tearoff=0)\n        menu.add_command(label=\"‚è™ –í—ñ–¥–∫–æ—Ç–∏—Ç–∏\", command=rollback_action)\n        menu.add_command(label=\"‚ùå –í–∏–¥–∞–ª–∏—Ç–∏\", command=delete_action)\n        menu.tk_popup(event.x_root, event.y_root)\n\n        def show_menu(event):\n            menu.tk_popup(event.x_root, event.y_root)\n\n        event.widget.bind(\"<Button-3>\", show_menu)\n\n    def explain_last_action(self):\n        if not hasattr(self, \"last_action_id\") or not self.last_action_id:\n            self.chat_display.insert(tk.END, \"‚ö†Ô∏è –ù–µ–º–∞—î –æ—Å—Ç–∞–Ω–Ω—å–æ—ó –¥—ñ—ó –¥–ª—è –ø–æ—è—Å–Ω–µ–Ω–Ω—è\\n\")\n            return\n\n        try:\n            with open(\".ben_memory.json\", \"r\", encoding=\"utf-8\") as f:\n                memory = json.load(f)\n\n            # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –∫–æ–º–∞–Ω–¥—É –∑–∞ last_action_id\n            cmd = next((item for item in reversed(memory) if item.get(\"history_id\") == self.last_action_id), None)\n            if not cmd:\n                self.chat_display.insert(tk.END, f\"‚ö†Ô∏è –ö–æ–º–∞–Ω–¥—É –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {self.last_action_id}\\n\")\n                return\n\n            code = cmd.get(\"code\") or cmd.get(\"content\")\n            if not code:\n                self.chat_display.insert(tk.END, f\"‚ö†Ô∏è –ù–µ–º–∞—î –∫–æ–¥—É –¥–ª—è –ø–æ—è—Å–Ω–µ–Ω–Ω—è\\n\")\n                return\n\n            client = OpenAI(api_key=API_KEY)\n            response = client.chat.completions.create(\n                model=\"gpt-4o\",\n                messages=[\n                    {\"role\": \"system\", \"content\": \"–ü–æ—è—Å–Ω–∏, —â–æ —Ä–æ–±–∏—Ç—å —Ü–µ–π Python-–∫–æ–¥ —Å—Ç–∏—Å–ª–æ –π –∑—Ä–æ–∑—É–º—ñ–ª–æ:\"},\n                    {\"role\": \"user\", \"content\": code}\n                ],\n                temperature=0.4\n            )\n\n            explanation = response.choices[0].message.content.strip()\n            self.chat_display.insert(tk.END, f\"üß† –ü–æ—è—Å–Ω–µ–Ω–Ω—è –æ—Å—Ç–∞–Ω–Ω—å–æ—ó –¥—ñ—ó:\\n{explanation}\\n\\n\")\n            self.chat_display.see(tk.END)\n\n        except Exception as e:\n            self.chat_display.insert(tk.END, f\"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø–æ—è—Å–Ω–µ–Ω–Ω—è: {e}\\n\")\n    \n    def analyze_all_code(self):\n        base_dir = os.path.abspath(\"..\")\n        all_code = \"\"\n        scanned_files = []\n\n        for root_dir, _, files in os.walk(base_dir):\n            if any(x in root_dir for x in [\"__pycache__\", \".git\", \"venv\"]):\n                continue\n            for file in files:\n                if file.endswith(\".py\"):\n                    file_path = os.path.join(root_dir, file)\n                    try:\n                        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                            content = f.read()\n                            relative = os.path.relpath(file_path, base_dir)\n                            all_code += f\"# –§–∞–π–ª: {relative}\\n{content}\\n\\n\"\n                            scanned_files.append(relative)\n                    except:\n                        continue\n\n        if not all_code.strip():\n            self.chat_display.insert(tk.END, \"‚ö†Ô∏è –ù–µ–º–∞—î .py —Ñ–∞–π–ª—ñ–≤ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É\\n\\n\")\n            return\n        \n        # ‚úÖ üõ°Ô∏è –ó–ê–•–ò–°–¢ –í–Ü–î –ü–ï–†–ï–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø GPT\n        if len(all_code) > 30000:\n            self.chat_display.insert(tk.END, f\"‚ö†Ô∏è –ó–∞–Ω–∞–¥—Ç–æ –≤–µ–ª–∏–∫–∏–π –æ–±—Å—è–≥ –∫–æ–¥—É –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É GPT ({len(all_code)} —Å–∏–º–≤–æ–ª—ñ–≤)\\n\\n\")\n            return\n        \n        # üîé –ó–∞–ø–∏—Å—É—î–º–æ –ª–æ–≥ –ø—Ä–æ —Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è\n        log_path = os.path.join(base_dir, \"debug.log\")\n        with open(log_path, \"a\", encoding=\"utf-8\") as log:\n            log.write(f\"[GPT] üîç –°–∫–∞–Ω–æ–≤–∞–Ω–æ {len(scanned_files)} —Ñ–∞–π–ª—ñ–≤:\\n\")\n            for name in scanned_files:\n                log.write(f\" - {name}\\n\")\n\n        try:\n            client = OpenAI(api_key=API_KEY)\n            analyzing = True\n            iteration = 1\n\n            while analyzing:\n                self.chat_display.insert(tk.END, f\"üîé GPT: –ê–Ω–∞–ª—ñ–∑ —ñ—Ç–µ—Ä–∞—Ü—ñ—è {iteration}...\\n\")\n                self.chat_display.see(tk.END)\n\n                response = client.chat.completions.create(\n                    model=\"gpt-4o\",\n                    messages=[\n                        {\"role\": \"system\", \"content\": \"–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π –Ω–∞–≤–µ–¥–µ–Ω–∏–π –∫–æ–¥. –Ø–∫—â–æ –≤—Å–µ –¥–æ–±—Ä–µ ‚Äî –Ω–∞–ø–∏—à–∏ '‚úÖ –í—Å–µ –¥–æ–±—Ä–µ'. –Ø–∫—â–æ —î –ø–æ–º–∏–ª–∫–∏ ‚Äî –∑–≥–µ–Ω–µ—Ä—É–π JSON-–∫–æ–º–∞–Ω–¥—É —É —Ñ–æ—Ä–º–∞—Ç—ñ Ben –¥–ª—è —ó—Ö –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è.\"},\n                        {\"role\": \"user\", \"content\": all_code}\n                    ],\n                    temperature=0.4\n                )\n\n                result = response.choices[0].message.content.strip()\n                self.chat_display.insert(tk.END, f\"ü§ñ GPT:\\n{result}\\n\\n\")\n                self.chat_display.see(tk.END)\n\n                with open(log_path, \"a\", encoding=\"utf-8\") as log:\n                    log.write(f\"[GPT] üìä –†–µ–∑—É–ª—å—Ç–∞—Ç —ñ—Ç–µ—Ä–∞—Ü—ñ—ó {iteration}:\\n{result}\\n\\n\")\n\n                if \"‚úÖ\" in result:\n                    analyzing = False\n                    break\n\n                try:\n                    command = json.loads(result)\n                    with open(\"cache.txt\", \"w\", encoding=\"utf-8\") as f:\n                        f.write(json.dumps(command, indent=2, ensure_ascii=False))\n                    exec_result = handle_command(command)\n                    self.chat_display.insert(tk.END, f\"üì§ –í–∏–∫–æ–Ω–∞–Ω–æ: {exec_result.get('message', '‚õî –ù–µ–≤—ñ–¥–æ–º–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å')}\\n\\n\")\n                    self.chat_display.see(tk.END)\n                except Exception as e:\n                    self.chat_display.insert(tk.END, f\"‚ùå –ü–æ–º–∏–ª–∫–∞ JSON-–∫–æ–º–∞–Ω–¥–∏ –∞–±–æ —ó—ó –≤–∏–∫–æ–Ω–∞–Ω–Ω—è: {e}\\n\\n\")\n                    break\n\n                time.sleep(1)\n                iteration += 1\n\n        except Exception as e:\n            self.chat_display.insert(tk.END, f\"‚ùå –ü–æ–º–∏–ª–∫–∞ –∞–Ω–∞–ª—ñ–∑—É GPT: {e}\\n\\n\")\n\n\nif __name__ == \"__main__\":\n    root = tk.Tk()\n    app = BenAssistantGUI(root)\n    root.mainloop()\n",
      ".\\ben_writer.py": "import json\nimport os\n\nbase_path = r\"C:\\Users\\DC\\my-bot-project\"\ncache_file = os.path.join(base_path, \"cache.txt\")\n\ncommands = [\n    {\n        \"action\": \"create_folder\",\n        \"foldername\": \"BEN_TEST_FOLDER\"\n    },\n    {\n        \"action\": \"create_file\",\n        \"filename\": \"ben_test.txt\",\n        \"content\": \"üß† –¶–µ —Ç–µ—Å—Ç –∑ –æ–Ω–æ–≤–ª–µ–Ω–∏–º GPT-–∞–≥–µ–Ω—Ç–æ–º!\"\n    }\n]\n\nwith open(cache_file, \"w\", encoding=\"utf-8\") as f:\n    json.dump(commands, f, indent=2, ensure_ascii=False)\n\nprint(\"‚úÖ –ö–æ–º–∞–Ω–¥–∏ –Ω–∞–¥—ñ—Å–ª–∞–Ω—ñ –∞–≥–µ–Ω—Ç—É —á–µ—Ä–µ–∑ cache.txt!\")\n\nimport logging\nlogging.basicConfig(level=logging.INFO)\nlogging.info('ben_writer loaded')",
      ".\\config.py": "import os\nfrom dotenv import load_dotenv\n\n# –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∑–º—ñ–Ω–Ω—ñ –∑ –∑–æ–≤–Ω—ñ—à–Ω—å–æ–≥–æ env-—Ñ–∞–π–ª—É\nload_dotenv(\"C:/Users/DC/env_files/env\")\n\n# –î–æ—Å—Ç—É–ø –¥–æ –∫–ª—é—á–∞\nAPI_KEY = os.getenv(\"OPENAI_API_KEY\")\n\n# –û—Å–Ω–æ–≤–Ω—ñ —à–ª—è—Ö–∏\nbase_path = r\"C:\\Users\\DC\\my-bot-project\"\nrequest_file = os.path.join(base_path, \"cache.txt\")\nresponse_file = os.path.join(base_path, \"gpt_response.json\")\nhistory_file = os.path.join(base_path, \"ben_history.log\")\nmemory_file = os.path.join(base_path, \".ben_memory.json\")\n",
      ".\\debug_test.py": "print('‚úÖ DEBUG TEST WORKING')",
      ".\\full_tsi_bot.py": "\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nfrom indicators.indicators import calculate_tsi, detect_tsi_divergence, detect_local_tsi_entry\nfrom structure.structure import detect_market_structure\nfrom utils.utils import confidence_score_update, log_trade_to_csv\nfrom utils.blackbox_logger import log_blackbox\nfrom structure.lux_structure import detect_lux_structure  \n\n# --- –Ü—Å—Ç–æ—Ä—ñ—è –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ –¥–ª—è —Ç—Ä–µ–π–¥—ñ–≤ ---\nprevious_confidences = {}\n\n# –ó–∞–º—ñ—Å—Ç—å —Å—Ç–∞—Ä–æ—ó —Ñ—É–Ω–∫—Ü—ñ—ó run_bot_logic –≤—Å—Ç–∞–≤ —Ü—é:\ndef run_bot_logic(data, symbol):\n    df_1h = calculate_tsi(data[\"1h\"])\n    df_30m = calculate_tsi(data[\"30m\"])\n    df_15m = calculate_tsi(data[\"15m\"])\n    df_5m = calculate_tsi(data[\"5m\"])\n    df_1m = calculate_tsi(data[\"1m\"])\n\n    divergence_1h = detect_tsi_divergence(df_1h)\n    divergence_30m = detect_tsi_divergence(df_30m)\n    divergence_15m = detect_tsi_divergence(df_15m)\n    divergence_1m = detect_tsi_divergence(df_1m)\n\n    local_div = detect_local_tsi_entry(df_1m)\n    market_structure = detect_market_structure(df_1m)\n    lux_structure = detect_lux_structure(df_1m)  # üÜï\n\n    tsi_now = df_1m[\"tsi\"].iloc[-1]\n    tsi_signal = df_1m[\"tsi_signal\"].iloc[-1]\n\n    trade_key = f\"{divergence_1h}_{divergence_30m}_{divergence_15m}_{divergence_1m}_{local_div}_{market_structure}_{lux_structure}\"\n    previous_score = previous_confidences.get(trade_key, 1.0)\n    confidence = confidence_score_update(trade_key, was_success=None)\n    previous_confidences[trade_key] = confidence\n\n    # üß† –£–º–æ–≤–∞ –≤—Ö–æ–¥—É –∑ LuxAlgo-—Ç—Ä–∏–≥–µ—Ä–æ–º BOS/CHoCH\n    if divergence_1m in [\"üîª –î–∏–≤–µ—Ä–≥–µ–Ω—Ü—ñ—è\", \"üîº –î–∏–≤–µ—Ä–≥–µ–Ω—Ü—ñ—è\"] and \\\n       local_div.startswith(\"üîª\") and market_structure in [\"LH\", \"LL\"] and \\\n       any(d in [\"üîª –î–∏–≤–µ—Ä–≥–µ–Ω—Ü—ñ—è\", \"üîº –î–∏–≤–µ—Ä–≥–µ–Ω—Ü—ñ—è\"] for d in [divergence_1h, divergence_30m, divergence_15m]) and \\\n       lux_structure in [\"BOS\", \"CHoCH\"]:\n        decision = \"üîª –ü–†–û–î–ê–ñ\"\n    elif divergence_1m in [\"üîª –î–∏–≤–µ—Ä–≥–µ–Ω—Ü—ñ—è\", \"üîº –î–∏–≤–µ—Ä–≥–µ–Ω—Ü—ñ—è\"] and \\\n         local_div.startswith(\"üîº\") and market_structure in [\"HH\", \"HL\"] and \\\n         any(d in [\"üîª –î–∏–≤–µ—Ä–≥–µ–Ω—Ü—ñ—è\", \"üîº –î–∏–≤–µ—Ä–≥–µ–Ω—Ü—ñ—è\"] for d in [divergence_1h, divergence_30m, divergence_15m]) and \\\n         lux_structure in [\"BOS\", \"CHoCH\"]:\n        decision = \"üîº –ö–£–ü–Ü–í–õ–Ø\"\n    else:\n        decision = \"üö´ –ë–ï–ó –î–Ü–á\"\n\n    print(f\"[{datetime.utcnow().strftime('%H:%M:%S')}] {symbol} | {decision} | Conf: {round(confidence, 2)}\")\n\n    log_blackbox({\n        \"time\": datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S'),\n        \"symbol\": symbol,\n        \"tsi_now\": round(tsi_now, 2),\n        \"tsi_signal\": round(tsi_signal, 2),\n        \"divergence_1h\": divergence_1h,\n        \"divergence_30m\": divergence_30m,\n        \"divergence_15m\": divergence_15m,\n        \"divergence_1m\": divergence_1m,\n        \"local_signal\": local_div,\n        \"structure\": market_structure,\n        \"lux_structure\": lux_structure,  # üÜï\n        \"confidence\": round(confidence, 3),\n        \"decision\": decision\n    })\n\n    log_trade_to_csv({\n        \"time\": datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S'),\n        \"symbol\": symbol,\n        \"tsi_now\": round(tsi_now, 2),\n        \"tsi_signal\": round(tsi_signal, 2),\n        \"divergence_1h\": divergence_1h,\n        \"divergence_30m\": divergence_30m,\n        \"divergence_15m\": divergence_15m,\n        \"divergence_1m\": divergence_1m,\n        \"local_signal\": local_div,\n        \"structure\": market_structure,\n        \"lux_structure\": lux_structure,  # üÜï\n        \"confidence\": round(confidence, 3),\n        \"decision\": decision\n    })\n\n    return {\n        \"tsi_now\": round(tsi_now, 2),\n        \"tsi_signal\": round(tsi_signal, 2),\n        \"divergence_1h\": divergence_1h,\n        \"divergence_30m\": divergence_30m,\n        \"divergence_15m\": divergence_15m,\n        \"divergence_1m\": divergence_1m,\n        \"local_signal\": local_div,\n        \"structure\": market_structure,\n        \"lux_structure\": lux_structure,  # üÜï\n        \"confidence\": round(confidence, 3),\n        \"decision\": decision\n    }",
      ".\\get_binance_data.py": "from binance.client import Client\nimport pandas as pd\nimport os\n\n\ndef fetch_binance_data(symbol=\"BTCUSDT\", interval=\"1m\", limit=1000):\n    api_key = \"\"\n    api_secret = \"\"\n    client = Client(api_key, api_secret)\n\n    klines = client.get_klines(symbol=symbol, interval=interval, limit=limit)\n\n    df = pd.DataFrame(klines, columns=[\n        \"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\",\n        \"close_time\", \"quote_asset_volume\", \"number_of_trades\",\n        \"taker_buy_base_asset_volume\", \"taker_buy_quote_asset_volume\", \"ignore\"\n    ])\n    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ms\")\n    df.set_index(\"timestamp\", inplace=True)\n\n    df = df[[\"open\", \"high\", \"low\", \"close\", \"volume\"]].astype(float)\n    os.makedirs(\"data\", exist_ok=True)\n    df.to_csv(\"data/binance_data.csv\")\n    print(\"‚úÖ –î–∞–Ω—ñ –∑ Binance –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ data/binance_data.csv\")\n\nif __name__ == \"__main__\":\n    fetch_binance_data()\n    import pandas as pd\nimport os",
      ".\\gpt_agent_cache.py": "\nimport os\nimport sys\nsys.path.append(os.path.abspath(\".\"))\nimport json\nimport time\nimport re\nimport ast\nimport shutil\nimport subprocess\nimport openai\nimport traceback\nimport sqlite3\nfrom datetime import datetime, timezone\nautopilot_mode = True\nbase_path = os.path.abspath(\".\")\n\n\n# –Ü–Ω—à—ñ –≥–ª–æ–±–∞–ª—å–Ω—ñ –∑–º—ñ–Ω–Ω—ñ, —Ñ—É–Ω–∫—Ü—ñ—ó...\n\nfrom colorama import init as colorama_init, Fore, Style\ncolorama_init()\nfrom dotenv import load_dotenv\nfrom init_history_db import create_history_table\nfrom handlers.file_creation import handle_create_file, handle_create_and_finalize_script\nfrom handlers.memory_manager import is_forbidden_action, remember_phrase, forget_phrase\nfrom handlers.auto_guess import auto_guess_missing_parameters\nfrom utils.json_tools import clean_json_text\nfrom utils.log_utils import log_action\n\n# üß† –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–º—ñ–Ω–Ω–∏—Ö —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞ (–∑ –ø–µ—Ä–µ–≤—ñ—Ä–∫–æ—é)\nenv_path = \"C:/Users/DC/env_files/env\"\nif os.path.exists(env_path):\n    load_dotenv(env_path)\nelse:\n    print(Fore.YELLOW + f\"‚ö†Ô∏è –§–∞–π–ª .env –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {env_path}\" + Style.RESET_ALL)\n\n# üß± –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ —ñ—Å—Ç–æ—Ä—ñ—ó –∫–æ–º–∞–Ω–¥\ncreate_history_table()\n\n# üß† –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–º—ñ–Ω–Ω–∏—Ö —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞\nload_dotenv(\"C:/Users/DC/env_files/env\")\n\n# üß© –î–æ–¥–∞–≤–∞–Ω–Ω—è base_path –¥–æ sys.path –¥–ª—è —ñ–º–ø–æ—Ä—Ç—É\nif os.getcwd() not in sys.path:\n    sys.path.append(os.getcwd())\n\ndef handle_command(cmd):\n    create_history_table()\n    # üß† –û–±—Ä–æ–±–∫–∞ –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω–Ω—è rollback\n    if cmd.get(\"action\") in [\"yes\", \"no\"] and cmd.get(\"target_id\"):\n        target_id = cmd[\"target_id\"]\n        if cmd[\"action\"] == \"yes\":\n            prev_cmd = get_command_by_id(target_id)\n            if not prev_cmd:\n                return {\"status\": \"error\", \"message\": f\"‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∫–æ–º–∞–Ω–¥—É –¥–ª—è –≤—ñ–¥–∫–∞—Ç—É: {target_id}\"}\n            file_path = prev_cmd.get(\"file\")\n            if not file_path or not os.path.exists(file_path + \".bak\"):\n                return {\"status\": \"error\", \"message\": f\"‚ùå –ù–µ–º–∞—î —Ä–µ–∑–µ—Ä–≤–Ω–æ—ó –∫–æ–ø—ñ—ó –¥–ª—è '{target_id}'\"}\n            shutil.copy(file_path + \".bak\", file_path)\n            return {\"status\": \"success\", \"message\": f\"‚úÖ –í—ñ–¥–∫–∞—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–æ –¥–ª—è {target_id}\"}\n        else:\n            return {\"status\": \"cancelled\", \"message\": f\"‚õî –í—ñ–¥–∫–∞—Ç —Å–∫–∞—Å–æ–≤–∞–Ω–æ –¥–ª—è {target_id}\"}\n\n    if cmd.get(\"filename\") == \"env\" or cmd.get(\"file_path\", \"\").endswith(\"env\"):\n        if cmd[\"action\"] in [\"update_file\", \"append_file\", \"replace_in_file\", \"update_code\", \"delete_file\"]:\n            return {\"status\": \"error\", \"message\": \"‚ùå –ó–∞–±–æ—Ä–æ–Ω–µ–Ω–æ –∑–º—ñ–Ω—é–≤–∞—Ç–∏ –∞–±–æ –∫–æ–º—ñ—Ç–∏—Ç–∏ —Ñ–∞–π–ª 'env'\"}\n\ndef apply_updates_to_file(file_path, updates):\n    import re\n\n    with open(file_path, 'r', encoding='utf-8') as f:\n        content = f.read()\n\n    for update in updates:\n        pattern_str = update.get('pattern')\n        replacement = update.get('replacement', '')\n        multiple = update.get('multiple', False)\n\n        if not pattern_str or not isinstance(pattern_str, str):\n            return {\"status\": \"error\", \"message\": \"‚ùå –ù–µ–≤—ñ—Ä–Ω–∏–π –∞–±–æ –ø–æ—Ä–æ–∂–Ω—ñ–π pattern\"}\n\n        try:\n            pattern = re.compile(pattern_str, re.DOTALL | re.MULTILINE)\n        except re.error as e:\n            return {\"status\": \"error\", \"message\": f\"‚ùå –ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π regex: {e}\"}\n\n        count = 0 if multiple else 1\n        content = pattern.sub(replacement, content, count=count)\n\n    with open(file_path, 'w', encoding='utf-8') as f:\n        f.write(content)\n\n    return {\"status\": \"success\", \"message\": f\"‚úÖ Applied updates to {file_path}\"}\n\n\n# ‚öôÔ∏è –Ü–º–ø–æ—Ä—Ç –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó\nfrom config import base_path, request_file, response_file, history_file, API_KEY\nimport sqlite3\n\n\ndef create_history_table():\n    conn = sqlite3.connect(os.path.join(base_path, \"history.sqlite\"))\n    cursor = conn.cursor()\n    cursor.execute('''\n        CREATE TABLE IF NOT EXISTS command_history (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            action TEXT,\n            file_path TEXT,\n            update_type TEXT,\n            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n        )\n    ''')\n    conn.commit()\n    conn.close()\n\n# üß† GPT-—ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è\nfrom gpt_interpreter import interpret_user_prompt\ninterpret_user_prompt(\"—Å—Ç–≤–æ—Ä–∏ —Ñ—É–Ω–∫—Ü—ñ—é, —è–∫–∞ –ø–µ—Ä–µ–≤—ñ—Ä—è—î, —á–∏ –ø–∞—Ä–æ–ª—å –º–∞—î —â–æ–Ω–∞–π–º–µ–Ω—à–µ 8 —Å–∏–º–≤–æ–ª—ñ–≤\")\n\ndef backup_file(filepath):\n    if not filepath or not os.path.isfile(filepath):\n        print(f\"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ backup ‚Äî –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π —à–ª—è—Ö: {filepath}\")\n        return\n\n    # –§–æ—Ä–º—É—î–º–æ –±–µ–∑–ø–µ—á–Ω—É —Ä–µ–∑–µ—Ä–≤–Ω—É –∫–æ–ø—ñ—é –∑ .bak\n    bak_path = filepath + \".bak\"\n    if not os.path.exists(bak_path):\n        try:\n            shutil.copy2(filepath, bak_path)\n            print(f\"üì¶ –°—Ç–≤–æ—Ä–µ–Ω–æ —Ä–µ–∑–µ—Ä–≤–Ω—É –∫–æ–ø—ñ—é: {bak_path}\")\n        except Exception as e:\n            print(f\"‚ùå –ü–æ–º–∏–ª–∫–∞ —Ä–µ–∑–µ—Ä–≤—É–≤–∞–Ω–Ω—è: {e}\")\n\ndef substitute_arguments(command_str, arguments):\n    if not arguments:\n        return command_str\n    for key, value in arguments.items():\n        command_str = command_str.replace(f\"{{{{{key}}}}}\", str(value))\n    return command_str\n\ndef execute_macro(macro_name, arguments=None):\n    macro_file = os.path.join(base_path, \"macro_commands.json\")\n    if not os.path.isfile(macro_file):\n        return {\"status\": \"error\", \"message\": \"‚ùå macro_commands.json not found\"}\n\n    with open(macro_file, \"r\", encoding=\"utf-8\") as f:\n        macros = json.load(f)\n\n    macro_steps = None\n    for macro in macros:\n        if macro.get(\"macro_name\") == macro_name:\n            macro_steps = macro.get(\"steps\")\n            break\n\n    if not macro_steps:\n        return {\"status\": \"error\", \"message\": f\"‚ùå –ù–µ–≤—ñ–¥–æ–º–∞ –º–∞–∫—Ä–æ–∫–æ–º–∞–Ω–¥–∞: {macro_name}\"}\n\n    for step in macro_steps:\n        if isinstance(step, dict):\n            if \"action\" in step:\n                action = step[\"action\"]\n                params = {k: substitute_arguments(v, arguments) if isinstance(v, str) else v for k, v in step.items() if k != \"action\"}\n            else:\n                action, raw_params = next(iter(step.items()))\n                params = {k: substitute_arguments(v, arguments) if isinstance(v, str) else v for k, v in raw_params.items()}\n        else:\n            print(\"‚ö†Ô∏è –ù–µ–≤—ñ—Ä–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç –∫—Ä–æ–∫—É –º–∞–∫—Ä–æ—Å—É, –ø—Ä–æ–ø—É—Å–∫–∞—é...\")\n            continue\n\n        if action == \"run_shell\":\n            try:\n                result = subprocess.run(params[\"command\"], shell=True, capture_output=True, text=True)\n                print(result.stdout.strip())\n            except Exception as e:\n                print(f\"‚ùå Shell –ø–æ–º–∏–ª–∫–∞: {e}\")\n        else:\n            response = handle_command({\"action\": action, **params})\n            print(response.get(\"message\", f\"‚úÖ {action} –≤–∏–∫–æ–Ω–∞–Ω–æ\"))\n\n    return {\"status\": \"success\", \"message\": f\"‚úÖ –ú–∞–∫—Ä–æ—Å '{macro_name}' –≤–∏–∫–æ–Ω–∞–Ω–æ\"}\n\ndef run_macro():\n    try:\n        with open(\"macro_command.json\", \"r\", encoding=\"utf-8\") as f:\n            macro = json.load(f)\n        steps = macro.get(\"steps\", [])\n        for step in steps:\n            print(f\"üì§ –ö—Ä–æ–∫: {step.get('action', '...')} –Ω–∞–¥—ñ—Å–ª–∞–Ω–æ\")\n            result = handle_command(step)\n            print(\"‚úÖ –í–∏–∫–æ–Ω–∞–Ω–æ:\", result)\n        return {\"status\": \"success\", \"message\": \"‚úÖ –ú–∞–∫—Ä–æ—Å –≤–∏–∫–æ–Ω–∞–Ω–æ\"}\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": f\"‚ùå –ú–∞–∫—Ä–æ—Å –ø–æ–º–∏–ª–∫–∞: {e}\"}\n\ndef undo_last_backup(filepath):\n    backups = [f for f in os.listdir(base_path) if f.startswith(os.path.basename(filepath)) and \".backup_\" in f]\n    backups.sort(reverse=True)\n    if backups:\n        last_backup = os.path.join(base_path, backups[0])\n        shutil.copy2(last_backup, filepath)\n        return {\"status\": \"success\", \"message\": f\"‚úÖ Restored from backup: {last_backup}\"}\n    return {\"status\": \"error\", \"message\": \"‚ùå No backup found\"}\n\ndef write_debug_log(message):\n    debug_log_path = os.path.join(base_path, \"debug.log\")\n    timestamp = datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S\")\n    with open(debug_log_path, \"a\", encoding=\"utf-8\") as f:\n        f.write(f\"[{timestamp}] {message}\\n\")\n\ndef generate_macro_steps_from_prompt(prompt_text):\n    from openai import OpenAI\n    client = OpenAI(api_key=API_KEY)\n\n    system_prompt = \"\"\"\n–¢–∏ –∞—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –º–∞–∫—Ä–æ–∫–æ–º–∞–Ω–¥ –¥–ª—è –∫–æ–¥—É–≤–∞–ª—å–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞.\n–ù–∞ –æ—Å–Ω–æ–≤—ñ –∑–∞–ø–∏—Ç—É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ —Å—Ç–≤–æ—Ä–∏ JSON-–º–∞—Å–∏–≤ macro-–∫—Ä–æ–∫—ñ–≤ —É —Ñ–æ—Ä–º–∞—Ç—ñ:\n\n[\n  {\"action\": \"create_file\", \"filename\": \"example.py\", \"content\": \"...\"},\n  {\"action\": \"update_code\", \"file_path\": \"example.py\", \"update_type\": \"logging\"},\n  {\"action\": \"run_python\", \"filename\": \"example.py\"}\n]\n\n–ü–æ–≤–µ—Ä–Ω–∏ –¢–Ü–õ–¨–ö–ò –º–∞—Å–∏–≤ JSON –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω—å.\n\"\"\"\n\n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": prompt_text}\n        ]\n    )\n\n    try:\n        steps = json.loads(response.choices[0].message.content.strip())\n        return {\"status\": \"success\", \"steps\": steps}\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": f\"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –∫—Ä–æ–∫–∏: {e}\"}\n\ndef self_improve_agent(filename=\"gpt_agent_cache.py\"):\n    try:\n        filepath = os.path.join(base_path, filename)\n        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n            code = f.read()\n\n        prompt = f\"\"\"\nüîç –¢–∏ GPT-–∞–≥–µ–Ω—Ç, —è–∫–∏–π –∞–Ω–∞–ª—ñ–∑—É—î —Å–≤—ñ–π –≤–ª–∞—Å–Ω–∏–π –∫–æ–¥.  \n–§–∞–π–ª: `{filename}`  \n–û—Å—å –π–æ–≥–æ –≤–º—ñ—Å—Ç:\n\n{code}\n\nüß† –í–∏–∑–Ω–∞—á, —è–∫—ñ –º—ñ–∫—Ä–æ–ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è –º–æ–∂–Ω–∞ –≤–Ω–µ—Å—Ç–∏: –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó, —Å–ø—Ä–æ—â–µ–Ω–Ω—è, –¥–æ–¥–∞–≤–∞–Ω–Ω—è –ø–µ—Ä–µ–≤—ñ—Ä–æ–∫ –∞–±–æ —á–∏—Å—Ç–æ–≥–æ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥—É.\n\n‚öôÔ∏è –ó–≥–µ–Ω–µ—Ä—É–π Python-JSON –æ–± º—î–∫—Ç —ñ–∑ –¥—ñ—î—é `safe_update_code`, —É —Ñ–æ—Ä–º–∞—Ç—ñ:\n\n{{\n  \"action\": \"safe_update_code\",\n  \"filename\": \"{filename}\",\n  \"updates\": [\n    {{\n      \"pattern\": \"REGEX-–ü–ê–¢–ï–†–ù\",\n      \"replacement\": \"–ù–û–í–ò–ô –ö–û–î\",\n      \"update_type\": \"replace\"\n    }}\n  ]\n}}\n\n–ü–æ–≤–µ—Ä–Ω–∏ —Ç—ñ–ª—å–∫–∏ –æ–±'—î–∫—Ç JSON, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω—å.\n\"\"\"\n\n        from openai import OpenAI\n        client = OpenAI(api_key=API_KEY)\n        response = client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=[\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n        )\n\n        result = json.loads(response.choices[0].message.content.strip())\n\n        # üíæ –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ–≥–æ –ø–µ—Ä–µ–≥–ª—è–¥—É\n        with open(\"gpt_response.json\", \"w\", encoding=\"utf-8\") as f:\n            json.dump(result, f, indent=2, ensure_ascii=False)\n\n        # ‚õëÔ∏è –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ safe update\n        update_result = handle_safe_update_code(result, base_path)\n        return update_result\n\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": f\"‚ùå Self-improvement failed: {e}\"}\ndef generate_improvement_plan():\n    try:\n        # 1. –û—Ç—Ä–∏–º–∞—Ç–∏ –≤—Å—ñ .py —Ñ–∞–π–ª–∏\n        files = scan_all_files(base_path, [\".py\"])\n        file_snippets = []\n\n        for path in files:\n            try:\n                with open(path, \"r\", encoding=\"utf-8\") as f:\n                    content = f.read()\n                    file_snippets.append({\"file\": path, \"code\": content[:2000]})  # –¥–æ 2k —Å–∏–º–≤–æ–ª—ñ–≤\n            except:\n                continue\n\n        # 2. GPT prompt\n        prompt = f\"\"\"\nüìÅ –£ –º–µ–Ω–µ —î Python-–ø—Ä–æ—î–∫—Ç —ñ–∑ —Ç–∞–∫–∏–º–∏ —Ñ–∞–π–ª–∞–º–∏:\n{json.dumps(file_snippets, indent=2, ensure_ascii=False)}\n\nüß† –ó–≥–µ–Ω–µ—Ä—É–π –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è –¥–ª—è —Ü—å–æ–≥–æ –ø—Ä–æ—î–∫—Ç—É ‚Äî —Å–ø–∏—Å–æ–∫ macro-–∫—Ä–æ–∫—ñ–≤ –¥–ª—è —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥—É, –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó, –∑–∞—Ö–∏—Å—Ç—É –∞–±–æ –Ω–æ–≤–æ–≥–æ —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—É.\n\n–ü–æ–≤–µ—Ä–Ω–∏ —Ç—ñ–ª—å–∫–∏ JSON —É —Ñ–æ—Ä–º–∞—Ç—ñ:\n\n{{\n  \"action\": \"run_macro\",\n  \"steps\": [ ... ]\n}}\n\"\"\"\n\n        from openai import OpenAI\n        client = OpenAI(api_key=API_KEY)\n        response = client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=[\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n        )\n\n        plan = json.loads(response.choices[0].message.content.strip())\n\n        # üíæ –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ gpt_plan.json\n        with open(\"gpt_plan.json\", \"w\", encoding=\"utf-8\") as f:\n            json.dump(plan, f, indent=2, ensure_ascii=False)\n\n        return {\"status\": \"success\", \"message\": \"üìã –ü–ª–∞–Ω –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ gpt_plan.json\", \"steps\": plan.get(\"steps\", [])}\n\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": f\"‚ùå –ü–æ–º–∏–ª–∫–∞ Smart-–ø–ª–∞–Ω—É–≤–∞–ª—å–Ω–∏–∫–∞: {e}\"}\n\ndef analyze_all_code():\n    try:\n        files = scan_all_files(base_path, [\".py\"])\n        file_snippets = []\n\n        for path in files:\n            try:\n                with open(path, \"r\", encoding=\"utf-8\") as f:\n                    content = f.read()\n                    file_snippets.append({\"file\": path, \"code\": content[:2000]})\n            except:\n                continue\n\n        prompt = f\"\"\"\nüìÅ –ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π —è–∫—ñ—Å—Ç—å –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ Python-–∫–æ–¥—É.  \n–ü–µ—Ä–µ–≤—ñ—Ä: –¥—É–±–ª—ñ–∫–∞—Ç–∏ —Ñ—É–Ω–∫—Ü—ñ–π, –≤—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å –ª–æ–≥—É–≤–∞–Ω–Ω—è, –Ω–µ–µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ –º—ñ—Å—Ü—è, –ø–æ–≥–∞–Ω–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É–≤–∞–Ω–Ω—è.\n\n–§–∞–π–ª–∏:\n{json.dumps(file_snippets, indent=2, ensure_ascii=False)}\n\nüß† –ü–æ–≤–µ—Ä–Ω–∏ –¥–µ—Ç–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç —É —Ñ–æ—Ä–º–∞—Ç—ñ:\n{{\n  \"status\": \"ok\",\n  \"recommendations\": [ ... ]\n}}\n\"\"\"\n\n        from openai import OpenAI\n        client = OpenAI(api_key=API_KEY)\n\n        # –°–ø—Ä–æ–±–∞ –º–∞–∫—Å–∏–º—É–º 2 —Ä–∞–∑–∏, —è–∫—â–æ JSON –Ω–µ–≤–∞–ª—ñ–¥–Ω–∏–π\n        for attempt in range(2):\n            response = client.chat.completions.create(\n                model=\"gpt-4o\",\n                messages=[{\"role\": \"user\", \"content\": prompt}]\n            )\n            raw = response.choices[0].message.content.strip()\n\n            # üíæ –ó–±–µ—Ä—ñ–≥–∞—î–º–æ RAW-–≤–∏–≤—ñ–¥ –¥–ª—è –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∏\n            with open(\"gpt_analysis_raw.txt\", \"w\", encoding=\"utf-8\") as f:\n                f.write(raw)\n\n            try:\n                report = json.loads(raw)\n                break  # ‚úÖ JSON –≤–∞–ª—ñ–¥–Ω–∏–π, –≤–∏—Ö–æ–¥–∏–º–æ\n            except json.JSONDecodeError as e:\n                print(f\"‚ö†Ô∏è –°–ø—Ä–æ–±–∞ {attempt + 1} ‚Äî –ø–æ–º–∏–ª–∫–∞ JSON: {e}\")\n                if attempt == 1:\n                    return {\"status\": \"error\", \"message\": f\"‚ùå GPT –Ω–µ –ø–æ–≤–µ—Ä–Ω—É–≤ –≤–∞–ª—ñ–¥–Ω–∏–π JSON: {e}\"}\n\n        # üíæ –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —É –∑–≤—ñ—Ç\n        with open(\"gpt_analysis.json\", \"w\", encoding=\"utf-8\") as f:\n            json.dump(report, f, indent=2, ensure_ascii=False)\n\n        return {\"status\": \"success\", \"message\": \"üìä –ê–Ω–∞–ª—ñ–∑ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ gpt_analysis.json\"}\n\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": f\"‚ùå Analyze failed: {e}\"}\n\ndef execute_plan():\n    plan_file = os.path.join(base_path, \"gpt_plan.json\")\n    if not os.path.exists(plan_file):\n        return {\"status\": \"error\", \"message\": \"‚ùå gpt_plan.json –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ\"}\n\n    try:\n        with open(plan_file, \"r\", encoding=\"utf-8\") as f:\n            plan = json.load(f)\n\n        if not isinstance(plan, list):\n            return {\"status\": \"error\", \"message\": \"‚ùå gpt_plan.json –º–∞—î –±—É—Ç–∏ —Å–ø–∏—Å–∫–æ–º –¥—ñ–π\"}\n\n        results = []\n        for i, step in enumerate(plan):\n            print(f\"\\n‚öôÔ∏è –í–∏–∫–æ–Ω—É—é –∫—Ä–æ–∫ {i + 1}/{len(plan)}: {step.get('action')}\")\n            result = handle_command(step)\n            results.append(result)\n\n            if result.get(\"status\") != \"success\":\n                print(f\"‚ùå –ó—É–ø–∏–Ω–µ–Ω–æ –Ω–∞ –∫—Ä–æ—Ü—ñ {i + 1} ‚Äî –ø–æ–º–∏–ª–∫–∞: {result.get('message')}\")\n                return {\n                    \"status\": \"error\",\n                    \"message\": f\"‚ùå –ü–ª–∞–Ω –∑—É–ø–∏–Ω–µ–Ω–æ –Ω–∞ –∫—Ä–æ—Ü—ñ {i + 1}\",\n                    \"results\": results\n                }\n\n        return {\n            \"status\": \"success\",\n            \"message\": f\"‚úÖ –ü–ª–∞–Ω –≤–∏–∫–æ–Ω–∞–Ω–æ –ø–æ–≤–Ω—ñ—Å—Ç—é ({len(plan)} –∫—Ä–æ–∫—ñ–≤)\",\n            \"results\": results\n        }\n\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": f\"‚ùå execute_plan –ø–æ–º–∏–ª–∫–∞: {e}\"}\n\ndef handle_run_shell(command):\n    shell_cmd = command.get(\"command\")\n    if not shell_cmd:\n        return {\"status\": \"error\", \"message\": \"‚ùå Missing shell command\"}\n\n    try:\n        print(f\"[BEN] üíª Running shell: {shell_cmd}\")\n        result = subprocess.run(shell_cmd, shell=True, capture_output=True, text=True)\n        if result.returncode != 0:\n            return {\"status\": \"error\", \"message\": f\"‚ùå Shell error: {result.stderr.strip()}\"}\n        return {\"status\": \"success\", \"message\": f\"‚úÖ Shell OK: {result.stdout.strip()}\"}\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": f\"‚ùå Shell exception: {e}\"}\n\ndef create_history_table():\n    conn = sqlite3.connect(os.path.join(base_path, \"history.sqlite\"))\n    cursor = conn.cursor()\n    cursor.execute('''\n        CREATE TABLE IF NOT EXISTS command_history (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            action TEXT,\n            file_path TEXT,\n            update_type TEXT,\n            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n        )\n    ''')\n    conn.commit()\n    conn.close()\nwrite_debug_log('üü¢ Agent started and listening...')\n\ndef is_valid_python_file(filepath):\n    try:\n        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n            source = f.read()\n        ast.parse(source)\n        return True\n    except SyntaxError as e:\n        print(f\"‚ùå Syntax error in {filepath}: {e}\")\n        return False\n\ncreate_history_table()\n\ndef get_command_by_id(target_id):\n    try:\n        with open(\".ben_memory.json\", \"r\", encoding=\"utf-8\") as f:\n            memory = json.load(f)\n        for entry in reversed(memory):  # –û—Å—Ç–∞–Ω–Ω—ñ –ø–µ—Ä—à–∏–º–∏\n            if entry.get(\"history_id\") == target_id:\n                return entry\n    except:\n        pass\n    return None\ndef ask_confirmation_for_rollback(prev_code, target_id):\n    prompt = (\n        f\"üß† –ó–Ω–∞–π–¥–µ–Ω–æ –∫–æ–¥, —è–∫–∏–π –±—É–¥–µ –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–æ –∑ ID {target_id}:\\n\\n\"\n        f\"{prev_code}\\n\\n\"\n        \"üîÅ –•–æ—á–µ—à –≤—ñ–¥–∫–æ—Ç–∏—Ç–∏ –¥–æ —Ü—å–æ–≥–æ –∫–æ–¥—É? –ù–∞–ø–∏—à–∏ 'yes' –∞–±–æ 'no'\"\n    )\n    with open(\"gpt_response.json\", \"w\", encoding=\"utf-8\") as f:\n        json.dump({\"status\": \"awaiting_confirmation\", \"message\": prompt, \"target_id\": target_id}, f, indent=2, ensure_ascii=False)\n    return {\"status\": \"paused\", \"message\": \"‚è∏Ô∏è –û—á—ñ–∫—É—î–º–æ –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω–Ω—è –Ω–∞ –≤—ñ–¥–∫–∞—Ç\"}\n\nimport importlib.util\nimport shutil\n\nCRITICAL_FILES = [\n    \"gpt_agent_cache.py\",\n    \"ben_writer.py\",\n    \"cache.txt\",\n    \"gpt_response.json\",\n    \"macro_commands.json\"\n]\n\ndef handle_safe_update_code(cmd, base_path):\n    filename = cmd.get(\"filename\")\n    updates = cmd.get(\"updates\", [])\n    filepath = os.path.join(base_path, filename)\n\n    if not os.path.exists(filepath) or not os.path.isfile(filepath):\n        return {\"status\": \"error\", \"message\": f\"‚ùå –§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∞–±–æ —Ü–µ –Ω–µ —Ñ–∞–π–ª: {filename}\"}\n\n    # üîß –î–æ–¥–∞—î–º–æ base_path —É sys.path\n    import sys\n    if base_path not in sys.path:\n        sys.path.append(base_path)\n\n    # 1. Create backup\n    backup_path = filepath + \".bak\"\n    shutil.copyfile(filepath, backup_path)\n\n    # 2. Read original\n    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n        content = f.read()\n\n    # 3. Apply updates\n    try:\n        for update in updates:\n            pattern = update.get(\"pattern\", \"\")\n            if not pattern.strip():\n                return {\"status\": \"error\", \"message\": \"‚ùå –ü–æ—Ä–æ–∂–Ω—ñ–π regex pattern ‚Äî –∑–º—ñ–Ω–∏ —Å–∫–∞—Å–æ–≤–∞–Ω–æ.\"}\n            try:\n                re.compile(pattern)\n            except re.error as regex_error:\n                return {\"status\": \"error\", \"message\": f\"‚ùå –ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π regex pattern: {regex_error}\"}\n\n            replacement = update.get(\"replacement\", \"\")\n            multiple = update.get(\"multiple\", False)\n\n            if not pattern.strip():\n                return {\"status\": \"error\", \"message\": \"‚ùå –ü—Ä–æ–ø—É—â–µ–Ω–æ ‚Äî pattern –Ω–µ –≤–∫–∞–∑–∞–Ω–æ –∞–±–æ –ø–æ—Ä–æ–∂–Ω—ñ–π\"}\n\n            flags = re.MULTILINE | re.DOTALL\n            if multiple:\n                content = re.sub(pattern, replacement, content, flags=flags)\n            else:\n                content = re.sub(pattern, replacement, content, count=1, flags=flags)\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": f\"‚ùå Regex error: {str(e)}\"}\n\n    # 4. Write to temp\n    tmp_path = filepath + \".tmp\"\n    with open(tmp_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(content)\n\n    # 5. –°–∏–Ω—Ç–∞–∫—Å–∏—á–Ω–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ —á–µ—Ä–µ–∑ ast\n    if filename.endswith(\".py\"):\n        try:\n            with open(tmp_path, \"r\", encoding=\"utf-8\") as f:\n                code = f.read()\n                ast.parse(code)  # üõ°Ô∏è –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–Ω—É –≤–∞–ª—ñ–¥–Ω—ñ—Å—Ç—å\n        except Exception as e:\n            return {\"status\": \"error\", \"message\": f\"‚ùå Syntax error: {str(e)}. Rolled back.\"}\n\n        # 6. (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ) –ü–æ–≤–Ω–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ —ñ–º–ø–æ—Ä—Ç—É\n        try:\n            spec = importlib.util.spec_from_file_location(\"tmp_module\", tmp_path)\n            if spec and spec.loader:\n                module = importlib.util.module_from_spec(spec)\n                spec.loader.exec_module(module)\n        except Exception as e:\n            return {\"status\": \"error\", \"message\": f\"‚ùå Import error: {str(e)}. Rolled back.\"}\n\n\n    # 7. All good ‚Äî apply\n    shutil.move(tmp_path, filepath)\n    return {\"status\": \"success\", \"message\": f\"‚úÖ Safe update applied to {filename}\"}\n\ndef save_to_memory(cmd):\n    memory_file = os.path.join(base_path, \".ben_memory.json\")\n    try:\n        if os.path.exists(memory_file):\n            with open(memory_file, \"r\", encoding=\"utf-8\") as f:\n                memory = json.load(f)\n        else:\n            memory = []\n        cmd[\"timestamp\"] = datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S\")\n        memory.append(cmd)\n        with open(memory_file, \"w\", encoding=\"utf-8\") as f:\n            json.dump(memory[-100:], f, indent=2, ensure_ascii=False)\n    except Exception as e:\n        log_action(f\"‚ö†Ô∏è Error saving to memory: {str(e)}\")\n\ndef handle_list_history():\n    memory_file = os.path.join(base_path, \".ben_memory.json\")\n    if os.path.exists(memory_file):\n        with open(memory_file, \"r\", encoding=\"utf-8\") as f:\n            memory = json.load(f)\n        return {\"status\": \"success\", \"history\": memory[-20:]}\n    return {\"status\": \"error\", \"message\": \"‚ùå Memory file not found\"}\n\ndef get_history():\n    try:\n        import sqlite3\n        conn = sqlite3.connect(os.path.join(base_path, \"history.sqlite\"))\n        cursor = conn.cursor()\n        cursor.execute(\"SELECT * FROM command_history ORDER BY timestamp DESC LIMIT 20\")\n        rows = cursor.fetchall()\n        conn.close()\n        return {\"status\": \"success\", \"history\": rows}\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": f\"‚ùå Failed to fetch from SQLite: {e}\"}\n\ndef handle_check_file_access(filename):\n    filepath = os.path.join(base_path, filename)\n    if os.path.isfile(filepath):\n        return {\"status\": \"success\", \"message\": \"‚úÖ File exists\"}\n    else:\n        return {\"status\": \"error\", \"message\": f\"‚ùå File not found: {filename}\"}\n\nfrom utils.json_tools import clean_json_text\n\ndef read_requests():\n    if not os.path.exists(request_file):\n        return []\n    with open(request_file, \"r\", encoding=\"utf-8\") as f:\n        try:\n            text = f.read().strip()\n            if not text:\n                return []\n            text = clean_json_text(text)\n            data = json.loads(text)\n            return data if isinstance(data, list) else [data]\n        except Exception as e:\n            return [{\"status\": \"error\", \"message\": f\"‚ùå JSON error: {str(e)}\"}]\n\ndef write_response(responses):\n    with open(response_file, \"w\", encoding=\"utf-8\") as f:\n        json.dump(responses, f, indent=2, ensure_ascii=False)\n\ndef clear_cache():\n    with open(request_file, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"\")\n\nimport difflib\n\ndef smart_deduplicate_insertion(existing_block, new_block):\n    existing_lines = [line.strip() for line in existing_block.strip().splitlines()]\n    new_lines = [line.strip() for line in new_block.strip().splitlines()]\n    merged = existing_block.strip().splitlines()\n    for line in new_lines:\n        if line and line.strip() not in existing_lines:\n            merged.append(line)\n    return \"\\n\".join(merged) + \"\\n\"\n\ndef handle_update_code(command):\n    file_path = command.get('file_path')\n\n    # üõ°Ô∏è –ó–∞—Ö–∏—â–µ–Ω—ñ —Ñ–∞–π–ª–∏\n    protected_files = [\"gpt_agent_cache.py\", \"cache.txt\", \"ben_gui_v2.py\"]\n    filename = os.path.basename(file_path)\n    if filename in protected_files:\n        return {\"status\": \"error\", \"message\": f\"‚ùå Cannot modify protected file: {filename}\"}\n    \n    # ‚úÖ –ë–µ–∫–∞–ø –ø–µ—Ä–µ–¥ –∑–º—ñ–Ω–∞–º–∏\n    if file_path and os.path.exists(file_path):\n        backup_file(file_path)\n\n    update_type = command.get('update_type')  # 'validation', 'exceptions', 'logging', 'custom_insert', ...\n    insert_at_line = command.get('insert_at_line')\n    insert_code = command.get('code') \n\n    # üÜï –ü—ñ–¥—Ç—Ä–∏–º–∫–∞ –ø—Ä–æ—Å—Ç–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç—É –±–µ–∑ updates[]\n    if \"updates\" not in command and all(k in command for k in (\"pattern\", \"replacement\", \"update_type\")):\n        command[\"updates\"] = [{\n            \"pattern\": command[\"pattern\"],\n            \"replacement\": command[\"replacement\"],\n            \"update_type\": command[\"update_type\"]\n        }]\n\n    if not file_path:\n        return {\"status\": \"error\", \"message\": \"‚ùå Missing 'file_path'\"}\n\n    # üîÅ –°–ø–µ—Ü—ñ–∞–ª—å–Ω—ñ —Ç–∏–ø–∏\n    if update_type in (\"validation\", \"exceptions\", \"logging\", \"custom_insert\"):\n        test_result = handle_command({\"action\": \"test_python\", \"filename\": file_path})\n        if test_result.get(\"status\") == \"error\":\n            return {\"status\": \"error\", \"message\": f\"‚ùå Syntax check failed: {test_result.get('message')}\"}\n\n        with open(file_path, 'r', encoding='utf-8') as f:\n            lines = f.readlines()\n\n        if update_type == 'validation':\n            lines.append('\\nif data is None:\\n    raise ValueError(\"Input data cannot be None\")')\n        elif update_type == 'exceptions':\n            lines.append('\\ntry:\\n    risky_operation()\\nexcept Exception as e:\\n    print(f\"Exception occurred: {e}\")')\n        elif update_type == 'logging':\n            lines.append('\\nimport logging\\nlogging.basicConfig(level=logging.INFO)\\nlogging.info(\"Log message from BEN\")')\n        elif update_type == 'custom_insert' and insert_code:\n            if isinstance(insert_at_line, int) and 0 <= insert_at_line <= len(lines):\n                lines.insert(insert_at_line, insert_code + '\\n')\n            else:\n                return {\"status\": \"error\", \"message\": \"‚ùå Invalid insert_at_line value\"}\n\n        with open(file_path, 'w', encoding='utf-8') as f:\n            f.writelines(lines)\n\n        if not is_valid_python_file(file_path):\n            return {\"status\": \"error\", \"message\": f\"‚ùå Syntax error after applying update_code to {file_path}\"}\n\n        print(f\"[BEN] update_code applied to {file_path} with type {update_type}\")\n        return {\"status\": \"success\", \"message\": f\"‚úÖ update_code applied to {file_path} with type {update_type}\"}\n\n    # üîÅ –£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π —Ä–µ–∂–∏–º: updates[]. –í–∏–∫–æ–Ω—É—î—Ç—å—Å—è —Ç—ñ–ª—å–∫–∏ —è–∫—â–æ –ù–ï –æ–¥–∏–Ω —ñ–∑ –≤–∏—â–µ\n    updates = command.get(\"updates\")\n    if not updates:\n        return {\"status\": \"error\", \"message\": \"‚ùå Missing 'updates' or unsupported update_type\"}\n\n    try:\n        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n            content = f.read()\n    except FileNotFoundError:\n        return {\"status\": \"error\", \"message\": \"‚ùå File not found\"}\n\n    # –ó–±–µ—Ä–µ–≥—Ç–∏ .bak –ø–µ—Ä–µ–¥ –∑–º—ñ–Ω–∞–º–∏\n    backup_path = file_path + \".bak\"\n    with open(backup_path, \"w\", encoding=\"utf-8\") as backup:\n        backup.write(content)\n\n    for upd in updates:\n        pattern = upd.get(\"pattern\")\n        replacement = upd.get(\"replacement\")\n        u_type = upd.get(\"update_type\")\n\n        if not all([pattern, replacement, u_type]):\n            return {\"status\": \"error\", \"message\": \"‚ùå Missing fields in update\"}\n\n        import re\n        if u_type == \"replace\":\n            matches = list(re.finditer(pattern, content, flags=re.DOTALL))\n            if not matches:\n                return {\"status\": \"error\", \"message\": \"‚ùå Pattern not found\"}\n            for match in reversed(matches):\n                span = match.span()\n                target = content[span[0]:span[1]]\n                updated = smart_deduplicate_insertion(target, replacement)\n                content = content[:span[0]] + updated + content[span[1]:]\n\n        elif u_type == \"append\":\n            content = smart_deduplicate_insertion(content, replacement)\n\n        elif u_type == \"prepend\":\n            content = smart_deduplicate_insertion(replacement, content)\n\n        else:\n            return {\"status\": \"error\", \"message\": f\"‚ùå Unknown update_type: {u_type}\"}\n\n\n    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(content)\n\n    return {\"status\": \"success\", \"message\": f\"‚úÖ Updated {file_path}\"}\n\ndef log_diff(filepath):\n    try:\n        result = subprocess.run([\"git\", \"diff\", filepath], capture_output=True, text=True)\n        diff = result.stdout.strip()\n        if diff:\n            timestamp = datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S\")\n            with open(history_file, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"[DIFF {timestamp}] File: {filepath}\\n{diff}\\n---\\n\")\n    except Exception as e:\n        with open(history_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"[DIFF ERROR] {filepath}: {str(e)}\\n\")\n\n\ndef handle_macro(cmd):\n    if not isinstance(cmd.get(\"steps\"), list):\n        return {\"status\": \"error\", \"message\": \"‚ùå Invalid macro steps\"}\n\n    steps = cmd[\"steps\"]\n    rollback = cmd.get(\"rollback_on_fail\", False)\n    results = []\n    created_files = []\n\n    if rollback:\n        for step in steps:\n            if \"filename\" in step:\n                file_path = os.path.join(base_path, step[\"filename\"])\n                if os.path.exists(file_path):\n                    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                        original = f.read()\n                    with open(file_path + \".bak\", \"w\", encoding=\"utf-8\") as f:\n                        f.write(original)\n\n    for step in steps:\n        result = handle_command(step)\n        results.append(result)\n\n        # –ó–±–∏—Ä–∞—î–º–æ —Å—Ç–≤–æ—Ä–µ–Ω—ñ —Ñ–∞–π–ª–∏ (–¥–ª—è –≤–∏–¥–∞–ª–µ–Ω–Ω—è —É rollback)\n        if step.get(\"action\") == \"create_file\" and \"filename\" in step:\n            created_files.append(step[\"filename\"])\n\n        if result.get(\"status\") == \"error\" and rollback:\n            # –í—ñ–¥–∫–∞—Ç –∑ —Ä–µ–∑–µ—Ä–≤–Ω–∏—Ö –∫–æ–ø—ñ–π\n            for s in steps:\n                if \"filename\" in s:\n                    file_path = os.path.join(base_path, s[\"filename\"])\n                    bak_file = file_path + \".bak\"\n                    if os.path.exists(bak_file):\n                        with open(bak_file, \"r\", encoding=\"utf-8\") as f:\n                            restored = f.read()\n                        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n                            f.write(restored)\n\n            # –í–∏–¥–∞–ª—è—î–º–æ –Ω–æ–≤–æ—Å—Ç–≤–æ—Ä–µ–Ω—ñ —Ñ–∞–π–ª–∏\n            for fname in created_files:\n                file_path = os.path.join(base_path, fname)\n                if os.path.exists(file_path):\n                    os.remove(file_path)\n\n            # üß† –ó–∞–ø–∏—Å rollback'—É –≤ –ø–∞–º º—è—Ç—å\n            save_to_memory({\n                \"action\": \"rollback\",\n                \"reason\": result.get(\"message\"),\n                \"rollback_steps\": steps\n            })\n\n            # ‚ôªÔ∏è Git-–∫–æ–º—ñ—Ç\n            auto_commit(\"‚ôªÔ∏è Rollback after failure\")\n\n            return {\n                \"status\": \"error\",\n                \"message\": \"‚ùå Macro failed. Rolled back all changes.\",\n                \"results\": results\n            }\n\n    return {\"status\": \"success\", \"steps\": results}\n\ndef handle_analyze_json(cmd, base_path=\".\"):\n    import os\n    import json\n    from datetime import datetime\n    from openai import OpenAI\n\n    # –£–Ω—ñ—Ñ—ñ–∫–æ–≤–∞–Ω–µ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è\n    json_data = cmd.get(\"parameters\", {}).get(\"json_data\")\n    filename = (\n        cmd.get(\"filename\")\n        or cmd.get(\"parameters\", {}).get(\"filename\")\n        or cmd.get(\"parameters\", {}).get(\"file_path\")\n    )\n\n    if json_data:\n        data = json_data  # –Ω–∞–ø—Ä—è–º—É –ø–µ—Ä–µ–¥–∞–Ω–∏–π JSON\n    elif filename:\n        filepath = os.path.join(base_path, filename)\n        if not os.path.exists(filepath) or not os.path.isfile(filepath):\n            return {\"status\": \"error\", \"message\": f\"‚ùå –§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∞–±–æ —Ü–µ –Ω–µ —Ñ–∞–π–ª: {filename}\"}\n        try:\n            with open(filepath, \"r\", encoding=\"utf-8\") as f:\n                data = json.load(f)\n        except Exception as e:\n            return {\"status\": \"error\", \"message\": f\"‚ùå JSON –ø–æ–º–∏–ª–∫–∞: {e}\"}\n    else:\n        return {\"status\": \"error\", \"message\": \"‚ùå –ù–µ –≤–∫–∞–∑–∞–Ω–æ 'filename', 'file_path' –∞–±–æ 'json_data'\"}\n\n    # GPT-–∞–Ω–∞–ª—ñ–∑\n    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n    prompt = f\"\"\"\n–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π –Ω–∞—Å—Ç—É–ø–Ω–∏–π JSON —ñ –¥–∞–π –ø–æ—Ä–∞–¥–∏:\n- —á–∏ –¥–æ–±—Ä–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–æ?\n- —â–æ –º–æ–∂–Ω–∞ –ø–æ–∫—Ä–∞—â–∏—Ç–∏?\n- —á–∏ —î –ª–æ–≥—ñ—á–Ω—ñ –ø—Ä–æ–±–ª–µ–º–∏?\n\n–û—Å—å JSON:\n{json.dumps(data, indent=2, ensure_ascii=False)}\n\"\"\"\n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    reply = response.choices[0].message.content.strip()\n\n    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n    out_path = f\"gpt_json_analysis_{timestamp}.txt\"\n    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(reply)\n\n    return {\"status\": \"success\", \"message\": f\"üìÑ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –∞–Ω–∞–ª—ñ–∑ —É {out_path}\"}\n\ndef handle_summarize_file(cmd, base_path=\".\"):\n    import os\n    import openai\n\n    filename = (\n        cmd.get(\"filename\")\n        or cmd.get(\"parameters\", {}).get(\"filename\")\n        or cmd.get(\"parameters\", {}).get(\"file_path\")\n    )\n\n    # üõ°Ô∏è –í–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è ‚Äî –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –¥–µ—Ñ–æ–ª—Ç, —è–∫—â–æ —à–ª—è—Ö –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π –∞–±–æ —Ñ–∞–π–ª –Ω–µ —ñ—Å–Ω—É—î\n    if not filename or filename == \"unknown\" or not os.path.exists(os.path.join(base_path, filename)):\n        filename = \"recent_actions.log\"\n\n    file_path = os.path.join(base_path, filename)\n    if not os.path.exists(file_path):\n        return {\"status\": \"error\", \"message\": f\"‚ùå –§–∞–π–ª '{filename}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ\"}\n\n    try:\n        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n            content = f.read()\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": f\"‚ùå –ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è: {e}\"}\n\n    prompt = f\"\"\"\n–ó—Ä–æ–±–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –ø—ñ–¥—Å—É–º–æ–∫ –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ —Ñ–∞–π–ª—É. –í–∫–∞–∂–∏:\n1. –©–æ –º—ñ—Å—Ç–∏—Ç—å—Å—è –≤ –Ω—å–æ–º—É?\n2. –Ø–∫–∞ –æ—Å–Ω–æ–≤–Ω–∞ –ª–æ–≥—ñ–∫–∞ –∞–±–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞?\n3. –ß–∏ —î –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω—ñ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è?\n\n–û—Å—å –≤–º—ñ—Å—Ç —Ñ–∞–π–ª—É `{filename}`:\n{content[:3000]}  # –æ–±–º–µ–∂–∏–º–æ –æ–±—Å—è–≥\n\"\"\"\n\n    client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n\n    reply = response.choices[0].message.content.strip()\n\n    out_file = f\"summarized_{filename}.txt\"\n    with open(out_file, \"w\", encoding=\"utf-8\") as f:\n        f.write(reply)\n\n    return {\"status\": \"success\", \"message\": f\"üìÑ –ü—ñ–¥—Å—É–º–æ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É {out_file}\"}\n\nfrom handlers.memory_manager import remember_phrase\n\ndef handle_validate_shell_command(cmd, base_path=\".\"):\n    command = (\n        cmd.get(\"parameters\", {}).get(\"command\")\n        or cmd.get(\"command\")\n    )\n\n    if command and isinstance(command, str) and len(command.strip()) > 3:\n        remember_phrase(command.strip())\n\n    if not command:\n        return {\"status\": \"error\", \"message\": \"‚ùå –ù–µ –≤–∫–∞–∑–∞–Ω–æ –∫–æ–º–∞–Ω–¥—É –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏.\"}\n\n    dangerous_keywords = [\"rm\", \"shutdown\", \"reboot\", \"sudo\", \"mkfs\", \":(){\", \">:(\", \"dd if=\", \"kill -9\"]\n    if any(danger in command for danger in dangerous_keywords):\n        return {\n            \"status\": \"error\",\n            \"message\": f\"‚ö†Ô∏è –í–∏—è–≤–ª–µ–Ω–æ –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω–æ –Ω–µ–±–µ–∑–ø–µ—á–Ω—É –∫–æ–º–∞–Ω–¥—É: '{command}'\"\n        }\n\n    return {\n        \"status\": \"ok\",\n        \"message\": f\"‚úÖ Shell-–∫–æ–º–∞–Ω–¥–∞ '{command}' –≤–∏–≥–ª—è–¥–∞—î –±–µ–∑–ø–µ—á–Ω–æ.\"\n    }\n\ndef handle_add_function(cmd, base_path=\".\"):\n    import os\n    import ast\n\n    filename = cmd.get(\"file\") or cmd.get(\"parameters\", {}).get(\"file\")\n    function_name = cmd.get(\"function_name\") or cmd.get(\"parameters\", {}).get(\"function_name\")\n    function_code = cmd.get(\"function_code\") or cmd.get(\"parameters\", {}).get(\"function_code\")\n\n    if not filename or not function_name or not function_code:\n        return {\"status\": \"error\", \"message\": \"‚ùå –ù–µ –≤–∫–∞–∑–∞–Ω–æ —Ñ–∞–π–ª, –Ω–∞–∑–≤—É –∞–±–æ –∫–æ–¥ —Ñ—É–Ω–∫—Ü—ñ—ó.\"}\n\n    file_path = os.path.join(base_path, filename)\n\n    if not os.path.exists(file_path):\n        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(\"\")\n\n    try:\n        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n            source = f.read()\n\n        parsed = ast.parse(source)\n        for node in parsed.body:\n            if isinstance(node, ast.FunctionDef) and node.name == function_name:\n                return {\n                    \"status\": \"skipped\",\n                    \"message\": f\"‚ö†Ô∏è –§—É–Ω–∫—Ü—ñ—è '{function_name}' –≤–∂–µ —ñ—Å–Ω—É—î —É —Ñ–∞–π–ª—ñ '{filename}'\"\n                }\n\n        with open(file_path, \"a\", encoding=\"utf-8\") as f:\n            f.write(\"\\n\\n\" + function_code.strip() + \"\\n\")\n\n        return {\n            \"status\": \"success\",\n            \"message\": f\"‚úÖ –§—É–Ω–∫—Ü—ñ—é '{function_name}' –¥–æ–¥–∞–Ω–æ –¥–æ '{filename}'\"\n        }\n\n    except Exception as e:\n        return {\n            \"status\": \"error\",\n            \"message\": f\"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –¥–æ–¥–∞–≤–∞–Ω–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó: {str(e)}\"\n        }\n\nfrom handlers.memory_manager import remember_phrase\n\ndef try_remember_dialogue(cmd):\n    fields = [\n        cmd.get(\"comment\"),\n        cmd.get(\"parameters\", {}).get(\"prompt\"),\n        cmd.get(\"parameters\", {}).get(\"query\"),\n        cmd.get(\"parameters\", {}).get(\"text\")\n    ]\n    for phrase in fields:\n        if phrase and isinstance(phrase, str) and len(phrase.strip()) > 3:\n            remember_phrase(phrase.strip())\n\n\ndef handle_command(cmd):\n\n    print(\"üß™ DEBUG ‚Äî –ø–æ—á–∞—Ç–∫–æ–≤–∞ –∫–æ–º–∞–Ω–¥–∞:\", cmd)\n\n    if not isinstance(cmd, dict):\n        return {\"status\": \"error\", \"message\": \"‚ùå Invalid command format ‚Äî expected a JSON object\"}\n\n    print(\"üì¶ DEBUG ‚Äî parameters:\", cmd.get(\"parameters\", {}))\n\n    # ‚ùå –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑–∞–±–æ—Ä–æ–Ω–µ–Ω–∏—Ö –¥—ñ–π –∑ long_term_memory.json\n    from handlers.memory_manager import is_forbidden_action\n    if is_forbidden_action(cmd):\n        return {\n            \"status\": \"error\",\n            \"message\": f\"üö´ –¶—è –¥—ñ—è –∑–∞–±–æ—Ä–æ–Ω–µ–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ –¥–æ –ø–æ–±–∞–∂–∞–Ω—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞\"\n        }\n\n    if not isinstance(cmd, dict):\n        return {\"status\": \"error\", \"message\": \"‚ùå Invalid command format ‚Äî expected a JSON object\"}\n\n    # üß† –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –ø–æ–±–∞–∂–∞–Ω—å —É –∫–æ–º–µ–Ω—Ç–∞—Ä—è—Ö/–ø—Ä–æ–º–ø—Ç–∞—Ö\n    cmd = auto_guess_missing_parameters(cmd)\n    \n    if \"file_path\" in cmd.get(\"parameters\", {}):\n        fp = cmd[\"parameters\"][\"file_path\"]\n        if not os.path.exists(fp):\n            os.makedirs(os.path.dirname(fp), exist_ok=True)\n            with open(fp, \"w\", encoding=\"utf-8\") as f:\n                f.write(\"# üÜï –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ —Å—Ç–≤–æ—Ä–µ–Ω–∏–π —Ñ–∞–π–ª\\n\")\n            print(f\"üìÅ –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ —Å—Ç–≤–æ—Ä–µ–Ω–æ —Ñ–∞–π–ª: {fp}\")\n   \n    user_text = (\n        cmd.get(\"comment\") or\n        cmd.get(\"parameters\", {}).get(\"prompt\") or\n        cmd.get(\"parameters\", {}).get(\"query\") or\n        \"\"\n    ).lower()\n\n    if \"–ø–∞–º\" in user_text or \"–∑–∞–ø–∞–º\" in user_text:\n        phrase = user_text.strip()\n        remember_phrase(phrase)\n\n    if \"–Ω–µ —Ä–æ–±–∏\" in user_text or \"–∑–∞–±–æ—Ä–æ–Ω\" in user_text:\n        phrase = user_text.strip()\n        forget_phrase(phrase)\n\n    action = cmd.get(\"action\")\n\n    # ‚úÖ –í—ñ–¥—Ä–∞–∑—É –æ–±—Ä–æ–±–∫–∞ –≤—ñ–¥–æ–º–∏—Ö –≤–Ω—É—Ç—Ä—ñ—à–Ω—ñ—Ö –¥—ñ–π\n    if action == \"ask_gpt\":\n        from gpt_interpreter import interpret_user_prompt\n        inner_prompt = cmd.get(\"parameters\", {}).get(\"prompt\", \"\")\n        if inner_prompt:\n            answer = interpret_user_prompt(inner_prompt, return_data=False)\n            try_remember_dialogue(cmd)\n            return {\"status\": \"ok\", \"message\": answer}\n        else:\n            try_remember_dialogue(cmd)\n            return {\"status\": \"error\", \"message\": \"‚ùå –ù–µ–º–∞—î prompt –¥–ª—è 'ask_gpt'\"}\n    if action == \"scan_all_files\":\n        from handlers.scan_all import handle_scan_all_files\n        return handle_scan_all_files(cmd.get(\"parameters\", {}))\n\n    if action == \"message\":\n        try_remember_dialogue(cmd)\n        return {\n            \"status\": \"ok\",\n            \"message\": cmd.get(\"parameters\", {}).get(\"text\", \"‚úÖ –ü–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –æ—Ç—Ä–∏–º–∞–Ω–æ.\")\n        }\n\n    known_actions = [\"append_file\", \"update_code\", \"run_macro\", \"insert_between_markers\",\n                     \"run_shell\", \"read_file\", \"undo_change\", \"test_python\", \"summarize_file\",\n                     \"analyze_json\", \"ask_gpt\", \"save_template\", \"load_template\",\n                     \"validate_template\", \"add_function\", \"update_code_bulk\", \"run_macro_from_file\",\n                     \"message\",\"create_file\", \"create_and_finalize_script\",\"scan_all_files\",\n                     \"retry_last_action_with_fix\",\"scan_all_files\",\"macro\", \"run_python\"]  # ‚úÖ –¥–æ–¥–∞–Ω–æ message\n\n    if action not in known_actions:\n        # üî¥ –õ–æ–≥—É—î–º–æ –Ω–æ–≤—É –¥—ñ—é\n        with open(\"unknown_actions.json\", \"a\", encoding=\"utf-8\") as log:\n            json.dump(cmd, log, ensure_ascii=False)\n            log.write(\",\\n\")\n        return {\n            \"status\": \"error\",\n            \"message\": f\"‚ö†Ô∏è –ù–µ–≤—ñ–¥–æ–º–∞ –¥—ñ—è: {action}. –Ø–∫—â–æ GPT –∑–∞–ø—Ä–æ–ø–æ–Ω—É–≤–∞–≤ –Ω–æ–≤—É –¥—ñ—é, –ø–æ—Ç—Ä—ñ–±–Ω–æ —Ä–µ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —ó—ó –≤—Ä—É—á–Ω—É.\"\n        }\n\n    # üõ°Ô∏è –ó–∞—Ö–∏—Å—Ç: –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª—é–≤–∞–Ω–Ω—è –ø—Ä–∏ –≤—Å—Ç–∞–≤—Ü—ñ —Ñ—É–Ω–∫—Ü—ñ–π\n    if cmd.get(\"action\") == \"append_file\" and \"def \" in cmd.get(\"content\", \"\"):\n        new_func_name = None\n        try:\n            new_func_ast = ast.parse(cmd[\"content\"])\n            for node in ast.walk(new_func_ast):\n                if isinstance(node, ast.FunctionDef):\n                    new_func_name = node.name  # <-- –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π –≤—ñ–¥—Å—Ç—É–ø —Ç—É—Ç!\n                    break  # <-- –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π –≤—ñ–¥—Å—Ç—É–ø —Ç—É—Ç!\n        except SyntaxError:\n            return {\"status\": \"error\", \"message\": \"‚ùå Syntax error in new function code\"}\n\n        if new_func_name:\n            existing_file_path = os.path.join(base_path, cmd[\"filename\"])\n            if os.path.exists(existing_file_path):\n                with open(existing_file_path, \"r\", encoding=\"utf-8\") as f:\n                    existing_ast = ast.parse(f.read())\n                    for node in ast.walk(existing_ast):\n                        if isinstance(node, ast.FunctionDef) and node.name == new_func_name:\n                            return {\n                                \"status\": \"skipped\",\n                                \"message\": f\"‚ö†Ô∏è Function '{new_func_name}' already exists in {cmd['filename']}\"\n                            }\n\n    required_keys = [\"action\"]\n    for key in required_keys:\n        if key not in cmd:\n            return {\"status\": \"error\", \"message\": f\"‚ùå Missing required field: {key}\"}\n    try:\n        \n        action = cmd.get(\"action\")\n        filename = cmd.get(\"filename\") or cmd.get(\"file_path\") or cmd.get(\"parameters\", {}).get(\"file_path\")\n        foldername = cmd.get(\"foldername\")\n        content = cmd.get(\"content\", \"\")\n        pattern = cmd.get(\"pattern\")\n        replacement = cmd.get(\"replacement\")\n        target_folder = cmd.get(\"target_folder\")\n        new_name = cmd.get(\"new_name\")\n\n        full_file_path = os.path.join(base_path, filename) if filename else None\n        full_folder_path = os.path.join(base_path, foldername) if foldername else None\n        dst_folder_path = os.path.join(base_path, target_folder) if target_folder else None\n        dst_file_path = os.path.join(dst_folder_path, filename) if target_folder and filename else None\n        \n\n        if action == \"create_file\":\n            with open(full_file_path, \"w\", encoding=\"utf-8\") as f:\n                f.write(content)\n            save_to_memory(cmd)  \n            return {\"status\": \"success\", \"message\": f\"‚úÖ Created file '{filename}'\"}\n        \n        elif action == \"run_python\":\n            from handlers.run_python import handle_run_python\n            return handle_run_python(cmd)  # üëà –ø–µ—Ä–µ–¥–∞—î–º–æ –≤—Å—é –∫–æ–º–∞–Ω–¥—É!\n\n\n        elif action == \"update_code\":\n            params = cmd.get(\"parameters\", {})\n            filepath = cmd.get(\"file_path\") or params.get(\"file_path\") or cmd.get(\"file\")\n\n            if not filepath:\n                return {\"status\": \"error\", \"message\": \"‚ùå Missing 'file_path'\"}\n\n            full_path = os.path.join(base_path, filepath)\n            if not os.path.isfile(full_path):\n                return {\"status\": \"error\", \"message\": f\"‚ùå File not found: {filepath}\"}\n\n            updates = cmd.get(\"updates\") or params.get(\"updates\", [])\n            if not updates:\n                return {\"status\": \"error\", \"message\": \"‚ùå No updates provided\"}\n\n            result = apply_updates_to_file(full_path, updates)\n\n            # üß™ –ê–≤—Ç–æ—Ç–µ—Å—Ç –ø—ñ—Å–ª—è –æ–Ω–æ–≤–ª–µ–Ω–Ω—è\n            test_result = handle_command({\n                \"action\": \"test_python\",\n                \"filename\": filepath\n            })\n            print(f\"üß™ –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–≤—Ç–æ—Ç–µ—Å—Ç—É: {test_result}\")\n\n            return {\"status\": \"success\", \"message\": f\"‚úÖ Updated {filepath}\", \"details\": result}\n        \n        elif action == \"add_function\":\n            return handle_add_function(cmd, base_path)\n   \n        elif action == \"safe_update_code\":\n            result = handle_safe_update_code(cmd, base_path)\n\n            # üß† –î–æ–¥–∞–Ω–æ –∑–∞—Ö–∏—Å—Ç, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ .get() –ø–æ–º–∏–ª–∫–∏\n            if result is None:\n                result = {\"status\": \"error\", \"message\": \"‚ùå handle_safe_update_code –Ω–µ –ø–æ–≤–µ—Ä–Ω—É–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç\"}\n\n            return result\n\n        elif action == \"update_code_bulk\":\n            return handle_update_code_bulk(cmd)\n        \n        elif action == \"retry_last_action_with_fix\":\n            from handlers.retry_logic import handle_retry_last_action_with_fix\n            return handle_retry_last_action_with_fix(cmd, base_path)\n\n        elif action == \"create_file\":\n            return handle_create_file(cmd, base_path)\n        \n        elif action == \"run_python\":\n            from handlers.run_python import handle_run_python\n            return handle_run_python(cmd)  # üëà –ø–µ—Ä–µ–¥–∞—î–º–æ –≤—Å—é –∫–æ–º–∞–Ω–¥—É!\n\n        elif action == \"create_and_finalize_script\":\n            return handle_create_and_finalize_script(cmd, base_path)\n\n        elif action == \"append_file\":\n            filename = cmd[\"filename\"]\n            content = cmd[\"content\"]\n            filepath = os.path.join(base_path, filename)\n            if not os.path.exists(filepath):\n                return {\"status\": \"error\", \"message\": f\"‚ùå –§–∞–π–ª '{filename}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ ‚Äî –Ω–µ –º–æ–∂–Ω–∞ –¥–æ–¥–∞—Ç–∏.\"}\n            backup_file(filepath)\n\n            with open(filepath, \"a\", encoding=\"utf-8\") as f:\n                f.write(content)\n\n            save_to_memory(cmd)\n\n            # üß™ –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–æ–¥—É –ø—ñ—Å–ª—è –≤—Å—Ç–∞–≤–∫–∏\n            test_result = handle_command({\n                \"action\": \"test_python\",\n                \"filename\": filename\n            })\n            print(f\"üß™ –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–≤—Ç–æ—Ç–µ—Å—Ç—É: {test_result}\")\n\n            return {\"status\": \"success\", \"message\": f\"üìå Appended to file '{filename}'\"}\n\n        elif action == \"scan_all_files\":\n            result = {}\n            for root, dirs, files in os.walk(base_path):\n                for file in files:\n                    if file.endswith((\".py\", \".json\", \".txt\", \".csv\")):\n                        rel_path = os.path.relpath(os.path.join(root, file), base_path)\n                        try:\n                            with open(os.path.join(root, file), \"r\", encoding=\"utf-8\") as f:\n                                result[rel_path] = f.read()\n                        except Exception as e:\n                            result[rel_path] = f\"‚ö†Ô∏è Error reading: {str(e)}\"\n            return {\n                \"status\": \"success\",\n                \"message\": \"‚úÖ –£—Å–ø—ñ—à–Ω–µ —Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è –≤—Å—ñ—Ö —Ñ–∞–π–ª—ñ–≤\",\n                \"files\": result\n            }\n\n        elif action == \"update_file\":\n            if os.path.exists(full_file_path):\n                with open(full_file_path, \"r\", encoding=\"utf-8\") as f:\n                    data = f.read()\n                updated = re.sub(pattern, replacement, data)\n                with open(full_file_path, \"w\", encoding=\"utf-8\") as f:\n                    f.write(updated)\n                save_to_memory(cmd)\n                return {\"status\": \"success\", \"message\": f\"üîÅ Updated file '{filename}'\"}\n            else:\n                return {\"status\": \"error\", \"message\": \"File not found\"}\n\n        elif action == \"replace_in_file\":\n            filename = cmd[\"filename\"]\n            pattern = cmd[\"pattern\"]\n            replacement = cmd[\"replacement\"]\n            filepath = os.path.join(base_path, filename)\n            full_file_path = filepath\n\n            backup_file(filepath)\n\n            if filename.endswith('.py'):\n                test_result = handle_command({\"action\": \"test_python\", \"filename\": filename})\n                if test_result.get(\"status\") == \"error\":\n                    return {\"status\": \"error\", \"message\": f\"‚ùå –ü–µ—Ä–µ–¥ –∑–º—ñ–Ω–æ—é: {test_result.get('message')}\"}\n\n                if not is_valid_python_file(full_file_path):\n                    return {\"status\": \"error\", \"message\": f\"‚ùå Syntax error before change in {filename}\"}\n\n            if filename in [\"config.py\", \"api_keys.py\", \"cache.txt\"]:\n                return {\"status\": \"error\", \"message\": f\"‚ùå –ó–∞–±–æ—Ä–æ–Ω–µ–Ω–æ –∑–º—ñ–Ω—é–≤–∞—Ç–∏ –∫—Ä–∏—Ç–∏—á–Ω–∏–π —Ñ–∞–π–ª: {filename}\"}\n\n            if not os.path.exists(full_file_path):\n                return {\"status\": \"error\", \"message\": f\"‚ùå –§–∞–π–ª '{filename}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –¥–ª—è –∑–∞–º—ñ–Ω–∏\"}\n\n            if os.path.exists(full_file_path):\n                with open(full_file_path, \"r\", encoding=\"utf-8\") as f:\n                    text = f.read()\n\n                # üß† –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ä–µ–∑–µ—Ä–≤–Ω—É –∫–æ–ø—ñ—é\n                backup_path = full_file_path + \".bak\"\n                with open(backup_path, \"w\", encoding=\"utf-8\") as f:\n                    f.write(text)\n\n                # üìù Git diff –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å–æ–º\n                try:\n                    diff_output = subprocess.check_output([\"git\", \"diff\", full_file_path], cwd=base_path, text=True)\n                    if diff_output.strip():\n                        log_action(\"üìÑ Git diff –ø–µ—Ä–µ–¥ –∑–º—ñ–Ω–æ—é:\" + diff_output)\n                except Exception as e:\n                    log_action(f\"‚ö†Ô∏è Git diff error: {str(e)}\")\n\n                # üîÅ –ó–∞–º—ñ–Ω–∞ —á–µ—Ä–µ–∑ regex\n                new_text = re.sub(pattern, replacement, text)\n                with open(full_file_path, \"w\", encoding=\"utf-8\") as f:\n                    f.write(new_text)\n\n                if not is_valid_python_file(full_file_path):\n                    return {\"status\": \"error\", \"message\": f\"‚ùå Syntax error after change in {filename}. Revert or fix manually.\"}\n\n                # üìú –õ–æ–≥ –∑–º—ñ–Ω\n                log_diff(full_file_path)\n                save_to_memory(cmd)\n\n                # üß™ –ê–≤—Ç–æ—Ç–µ—Å—Ç –ø—ñ—Å–ª—è –∑–º—ñ–Ω–∏\n                test_result = handle_command({\n                    \"action\": \"test_python\",\n                    \"filename\": filename\n                })\n                print(f\"üß™ –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–≤—Ç–æ—Ç–µ—Å—Ç—É: {test_result}\")\n\n                return {\"status\": \"success\", \"message\": f\"‚úèÔ∏è Replaced text in '{filename}'\"}\n\n            \n        elif action == \"insert_between_markers\":\n            filepath = os.path.join(base_path, cmd[\"filename\"])\n            backup_file(filepath)\n            file_path = os.path.join(base_path, cmd.get(\"file_path\"))\n            marker_start = cmd.get(\"marker_start\")\n            marker_end = cmd.get(\"marker_end\")\n            insert_code = cmd.get(\"code\")\n\n            if not all([file_path, marker_start, marker_end, insert_code]):\n                return {\"status\": \"error\", \"message\": \"‚ùå Missing required fields for marker-based insertion\"}\n\n            if not os.path.exists(file_path):\n                return {\"status\": \"error\", \"message\": f\"‚ùå File '{file_path}' not found\"}\n\n            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                lines = f.readlines()\n\n            start_idx, end_idx = -1, -1\n            for i, line in enumerate(lines):\n                if marker_start in line:\n                    start_idx = i + 1\n                if marker_end in line:\n                    end_idx = i\n\n            if start_idx == -1 or end_idx == -1 or start_idx >= end_idx:\n                return {\"status\": \"error\", \"message\": \"‚ùå Markers not found or invalid order\"}\n\n            lines = lines[:start_idx] + [insert_code + \"\\n\"] + lines[end_idx:]\n\n            with open(file_path, \"w\", encoding=\"utf-8\") as f:\n                f.writelines(lines)\n\n            save_to_memory(cmd)\n            return {\"status\": \"success\", \"message\": f\"‚úÖ Inserted code between markers in {cmd.get('file_path')}\"}\n           \n        elif action == \"read_file\":\n            if os.path.exists(full_file_path):\n                with open(full_file_path, \"r\", encoding=\"utf-8\") as f:\n                    return {\"status\": \"success\", \"content\": f.read()}\n            save_to_memory(cmd)\n            return {\"status\": \"error\", \"message\": \"File not found\"}\n\n        elif action == \"search_text_in_file\":\n            if os.path.exists(full_file_path):\n                with open(full_file_path, \"r\", encoding=\"utf-8\") as f:\n                    lines = f.readlines()\n                matches = [line for line in lines if pattern in line]\n                return {\"status\": \"success\", \"matches\": matches}\n\n        elif action == \"create_folder\":\n            os.makedirs(full_folder_path, exist_ok=True)\n            return {\"status\": \"success\", \"message\": f\"üìÅ Folder '{foldername}' created\"}\n\n        elif action == \"delete_file\":\n            filename = cmd.get(\"filename\")\n            if not filename:\n                return {\"status\": \"error\", \"message\": \"‚ùå –ù–µ –≤–∫–∞–∑–∞–Ω–æ 'filename'\"}\n\n            full_file_path = os.path.join(base_path, filename)\n\n            if os.path.exists(full_file_path):\n                backup_file(full_file_path)\n                os.remove(full_file_path)\n                save_to_memory(cmd)\n                return {\"status\": \"success\", \"message\": f\"üóëÔ∏è File '{filename}' deleted\"}\n            else:\n                return {\"status\": \"error\", \"message\": f\"File '{filename}' not found\"}\n\n        elif action == \"rename_file\":\n            if not os.path.exists(full_file_path):\n                return {\"status\": \"error\", \"message\": f\"‚ùå File '{filename}' not found\"}\n            new_path = os.path.join(base_path, new_name)\n            os.rename(full_file_path, new_path)\n            save_to_memory(cmd)\n            return {\"status\": \"success\", \"message\": f\"üìÑ File renamed to '{new_name}'\"}\n\n        elif action == \"copy_file\":\n            shutil.copy(full_file_path, dst_file_path)\n            save_to_memory(cmd)\n            return {\"status\": \"success\", \"message\": f\"üìÇ Copied '{filename}' to '{target_folder}'\"}\n\n        elif action == \"read_folder\":\n            if os.path.exists(full_folder_path):\n                files = os.listdir(full_folder_path)\n                return {\"status\": \"success\", \"files\": files}\n            return {\"status\": \"error\", \"message\": \"Folder not found\"}\n\n        elif action == \"self_improve\":\n            filename = cmd.get(\"filename\", \"gpt_agent_cache.py\")\n            result = self_improve_agent(filename)\n            return result\n        \n        elif action == \"smart_plan\":\n             result = generate_improvement_plan()\n             return result\n        \n        elif action == \"run_plan\":\n             return execute_plan()\n\n        elif action == \"analyze_all_code\":\n            result = analyze_all_code()\n            return result\n        \n        elif action == \"analyze_json\":\n             return handle_analyze_json(cmd, base_path)      \n        \n        elif action == \"summarize_file\":\n            file_path = (\n                cmd.get(\"parameters\", {}).get(\"file_path\")\n                or cmd.get(\"filename\")\n                or cmd.get(\"parameters\", {}).get(\"filename\")\n            )\n\n            if not file_path and autopilot_mode:\n                file_path = \"recent_actions.log\"  # –ê–±–æ —ñ–Ω—à–∏–π –¥–µ—Ñ–æ–ª—Ç\n\n            if not file_path:\n                return {\"status\": \"error\", \"message\": \"‚ùå –ù–µ –≤–∫–∞–∑–∞–Ω–æ 'file_path'.\"}\n\n            cmd[\"parameters\"][\"file_path\"] = file_path\n            return handle_summarize_file(cmd, base_path)\n\n        elif action == \"validate_shell_command\":\n            return handle_validate_shell_command(cmd, base_path)\n        \n        elif action == \"ask_gpt\":\n            prompt = (\n                cmd.get(\"prompt\")\n                or cmd.get(\"parameters\", {}).get(\"prompt\")\n                or cmd.get(\"parameters\", {}).get(\"question\")\n            )\n\n            if not prompt and autopilot_mode:\n                prompt = \"–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π prompt: —Å—Ñ–æ—Ä–º—É–ª—é–π –Ω–æ–≤—É —ñ–¥–µ—é –¥–ª—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è Ben Assistant.\"\n\n            if not prompt:\n                return {\"status\": \"error\", \"message\": \"‚ùå –ù–µ –≤–∫–∞–∑–∞–Ω–æ prompt –¥–ª—è ask_gpt\"}\n\n            from openai import OpenAI\n            from config import API_KEY\n            client = OpenAI(api_key=API_KEY)\n            response = client.chat.completions.create(\n                model=\"gpt-4o\",\n                messages=[\n                    {\"role\": \"user\", \"content\": prompt}\n                ]\n            )\n            return {\n                \"status\": \"success\",\n                \"message\": f\"üß† GPT response: {response.choices[0].message.content.strip()}\"\n            }\n\n        elif action == \"test_gpt_api\":\n            try:\n                from openai import OpenAI\n                from config import API_KEY\n                client = OpenAI(api_key=API_KEY)\n                response = client.chat.completions.create(\n                    model=\"gpt-4o\",\n                    messages=[\n                        {\"role\": \"user\", \"content\": \"Ping\"}\n                    ]\n                )\n                return {\n                    \"status\": \"success\",\n                    \"message\": \"üü¢ GPT API connected!\",\n                    \"response\": response.choices[0].message.content\n                }\n            except Exception as e:\n                return {\n                    \"status\": \"error\",\n                    \"message\": f\"‚ùå GPT API error: {str(e)}\"\n                }\n            \n        elif action == \"test_python\":\n            if os.path.exists(full_file_path):\n                try:\n                    with open(full_file_path, \"r\", encoding=\"utf-8\") as f:\n                        source = f.read()\n                    compile(source, filename, 'exec')\n                    return {\n                        \"status\": \"success\",\n                        \"message\": f\"‚úÖ {filename} –ø—Ä–æ–π—à–æ–≤ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–Ω—É –ø–µ—Ä–µ–≤—ñ—Ä–∫—É\"\n                    }\n                except SyntaxError as e:\n                    return {\n                        \"status\": \"error\",\n                        \"message\": f\"‚ùå Syntax error in {filename}: {e}\"\n                    }\n            return {\n                \"status\": \"error\",\n                \"message\": \"File not found\"\n            }\n\n        elif action == \"undo_change\":\n            target_id = cmd.get(\"target_id\")\n            filename = cmd.get(\"filename\")\n\n            if target_id:\n                # üîç –®—É–∫–∞—î–º–æ –∫–æ–º–∞–Ω–¥—É –ø–æ ID –∑ —ñ—Å—Ç–æ—Ä—ñ—ó\n                prev_cmd = get_command_by_id(target_id)\n                if not prev_cmd:\n                    return {\"status\": \"error\", \"message\": f\"‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∫–æ–º–∞–Ω–¥—É –∑ ID: {target_id}\"}\n\n                file_path = prev_cmd.get(\"file\")\n                if not file_path or not os.path.exists(file_path + \".bak\"):\n                    return {\"status\": \"error\", \"message\": f\"‚ùå –ù–µ–º–∞—î —Ä–µ–∑–µ—Ä–≤–Ω–æ—ó –∫–æ–ø—ñ—ó –¥–ª—è ID: {target_id}\"}\n\n                with open(file_path + \".bak\", \"r\", encoding=\"utf-8\") as f:\n                    prev_code = f.read()\n\n                return ask_confirmation_for_rollback(prev_code, target_id)\n\n            elif filename:\n                # üïó –°—Ç–∞—Ä–∞ –ª–æ–≥—ñ–∫–∞ —á–µ—Ä–µ–∑ filename\n                full_file_path = os.path.join(base_path, filename)\n                if os.path.exists(full_file_path + \".bak\"):\n                    shutil.copy(full_file_path + \".bak\", full_file_path)\n                    save_to_memory(cmd)\n                    return {\"status\": \"success\", \"message\": f\"‚Ü©Ô∏è Undo: –≤—ñ–¥–∫–∞—Ç –¥–æ .bak –¥–ª—è '{filename}'\"}\n                else:\n                    return {\"status\": \"error\", \"message\": f\"‚ùå –ù–µ–º–∞—î —Ä–µ–∑–µ—Ä–≤–Ω–æ—ó –∫–æ–ø—ñ—ó –¥–ª—è '{filename}'\"}\n\n            else:\n                return {\"status\": \"error\", \"message\": \"‚ùå –ù–µ –≤–∫–∞–∑–∞–Ω–æ 'filename' –∞–±–æ 'target_id'\"}\n\n        # üìå Long-term memory handling\n        elif action == \"remember\":\n            from memory_manager import remember\n            phrase = cmd.get(\"phrase\") or cmd.get(\"parameters\", {}).get(\"phrase\")\n            if not phrase:\n                return {\"status\": \"error\", \"message\": \"‚ùå –ù–µ –≤–∫–∞–∑–∞–Ω–æ —Ñ—Ä–∞–∑—É –¥–ª—è –∑–∞–ø–∞–º º—è—Ç–æ–≤—É–≤–∞–Ω–Ω—è\"}\n            return remember(phrase)\n\n        elif action == \"recall\":\n            from memory_manager import recall\n            return recall()\n\n        elif action == \"forget\":\n            from memory_manager import forget\n            phrase = cmd.get(\"phrase\") or cmd.get(\"parameters\", {}).get(\"phrase\")\n            if not phrase:\n                return {\"status\": \"error\", \"message\": \"‚ùå –ù–µ –≤–∫–∞–∑–∞–Ω–æ —Ñ—Ä–∞–∑—É –¥–ª—è –≤–∏–¥–∞–ª–µ–Ω–Ω—è\"}\n            return forget(phrase)\n\n        elif action == \"macro\":\n            steps = cmd.get(\"steps\", [])\n            results = []\n            for step in steps:\n                print(\"üîÅ –í–∏–∫–æ–Ω–∞–Ω–Ω—è –∫—Ä–æ–∫—É:\", step)\n                res = handle_command(step)\n                if not isinstance(res, dict):\n                    res = {\"status\": \"error\", \"message\": \"–ù–µ–≤—ñ–¥–æ–º–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç\"}\n                results.append(res)\n            return {\n                \"status\": \"success\",\n                \"message\": f\"‚úÖ –í–∏–∫–æ–Ω–∞–Ω–æ {len(steps)} –∫—Ä–æ–∫—ñ–≤\",\n                \"results\": results\n            }\n\n        elif cmd.get(\"action\") == \"check_file_access\":\n            filename = cmd.get(\"filename\")\n            return handle_check_file_access(filename)\n\n        elif action == \"run_macro\":\n            macro_name = cmd.get(\"macro_name\")\n            arguments = cmd.get(\"arguments\", {})\n            if macro_name:\n                return execute_macro(macro_name, arguments)\n            else:\n                return run_macro()  # fallback –¥–ª—è macro_command.json\n            \n        elif action == \"run_macro_from_file\":\n            return execute_macro_from_file()\n        \n        elif action == \"macro_build\":\n            from handlers.macro_builder import handle_macro_build\n            return handle_macro_build(cmd)\n\n\n        elif action == \"check_file_access\":\n            filename = cmd.get(\"filename\")\n            if filename:\n                filepath = os.path.join(base_path, filename)\n                if os.path.exists(filepath):\n                    result = f\"‚úÖ File exists: {filename}\"\n                else:\n                    result = f\"‚ùå File not found: {filename}\"\n            else:\n                result = \"‚ùå No filename provided\"\n            print(result)\n            return {\"status\": \"success\", \"message\": result}\n\n        elif action == \"execute_macro\":\n            macro_name = cmd.get(\"macro_name\")\n            arguments = cmd.get(\"arguments\", {})\n            return execute_macro(macro_name, arguments)\n        \n        elif action == \"run_shell\":\n            command = cmd.get(\"command\") or cmd.get(\"parameters\", {}).get(\"command\")\n\n            if not command and autopilot_mode:\n                command = \"echo –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∞ –∫–æ–º–∞–Ω–¥–∞: –Ω—ñ—á–æ–≥–æ –Ω–µ –±—É–ª–æ –≤–∫–∞–∑–∞–Ω–æ.\"\n\n            if not command:\n                return {\"status\": \"error\", \"message\": \"‚ùå –ù–µ –≤–∫–∞–∑–∞–Ω–æ –∫–æ–º–∞–Ω–¥—É –¥–ª—è –≤–∏–∫–æ–Ω–∞–Ω–Ω—è.\"}\n\n            try:\n                result = subprocess.run(command, shell=True, capture_output=True, text=True)\n                return {\n                    \"status\": \"success\" if result.returncode == 0 else \"error\",\n                    \"stdout\": result.stdout.strip(),\n                    \"stderr\": result.stderr.strip()\n                }\n            except Exception as e:\n                return {\n                    \"status\": \"error\",\n                    \"message\": f\"‚ùå Shell –∫–æ–º–∞–Ω–¥–∞ –Ω–µ –≤–¥–∞–ª–∞—Å—è: {str(e)}\"\n                }\n\n        elif action == \"list_files\":\n            return {\"status\": \"success\", \"files\": os.listdir(base_path)}\n\n        elif action == \"check_status\":\n            return {\"status\": \"success\", \"message\": \"üü¢ Agent is running\"}\n\n        elif action == \"show_memory\":\n            memory_file = os.path.join(base_path, \".ben_memory.json\")\n            if os.path.exists(memory_file):\n                with open(memory_file, \"r\", encoding=\"utf-8\") as f:\n                    memory = json.load(f)\n                return {\"status\": \"success\", \"memory\": memory[-20:]}\n            else:\n                return {\"status\": \"error\", \"message\": \"‚ùå Memory file not found\"}\n        \n        elif action == \"list_history\":\n            return handle_list_history()\n\n        elif action == \"view_sql_history\":\n            return get_history()\n        \n        elif action == \"safe_update\":\n            result = handle_safe_update_code(cmd, base_path)\n            results.append(result)\n\n        # ‚õî –ê–≤—Ç–æ–æ–±—Ä–æ–±–∫–∞ –Ω–µ–≤—ñ–¥–æ–º–æ—ó –¥—ñ—ó, —è–∫—â–æ autopilot —É–≤—ñ–º–∫–Ω–µ–Ω–∏–π\n        elif autopilot_mode:\n            supported_actions = [\n                \"create_file\", \"create_and_finalize_script\",\n                \"append_file\", \"update_code\", \"run_macro\", \"insert_between_markers\",\n                \"run_shell\", \"read_file\", \"undo_change\", \"test_python\", \"summarize_file\",\n                \"analyze_json\", \"ask_gpt\", \"save_template\", \"load_template\",\n                \"validate_template\", \"add_function\", \"update_code_bulk\", \"validate_shell_command\",\n                \"test_gpt_api\", \"smart_plan\", \"run_plan\", \"analyze_all_code\", \"safe_update\",\n                \"show_memory\", \"list_history\", \"view_sql_history\", \"macro\"\n            ]\n            if action not in supported_actions:\n                result = {\n                    \"status\": \"auto_generated\",\n                    \"message\": f\"üöÄ –°—Ç–≤–æ—Ä—é—î–º–æ –Ω–æ–≤—É –¥—ñ—é '{action}' —É —Ä–µ–∂–∏–º—ñ autopilot.\",\n                    \"auto_action\": {\n                        \"action\": \"add_function\",\n                        \"parameters\": {\n                            \"file\": \"handler.py\",\n                            \"function_name\": f\"handle_{action}\",\n                            \"function_code\": f\"def handle_{action}(cmd, base_path='.'):\\n    # TODO: —Ä–µ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –ª–æ–≥—ñ–∫—É\\n    return {{'status': 'ok', 'message': 'üîß –ó–∞–≥–æ—Ç–æ–≤–∫–∞ —Ñ—É–Ω–∫—Ü—ñ—ó {action}'}}\"\n                        }\n                    }\n                }\n            else:\n                result = {\"status\": \"error\", \"message\": f\"‚ùå Unknown action: {action}\"}\n        \n        else:\n            result = {\"status\": \"error\", \"message\": f\"‚ùå Unknown action: {action}\"}\n\n        # üìù –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –¥—ñ—é –≤ SQLite\n        try:\n            conn = sqlite3.connect(os.path.join(base_path, \"history.sqlite\"))\n            cursor = conn.cursor()\n            cursor.execute(\"\"\"\n                INSERT INTO command_history (action, file_path, update_type)\n                VALUES (?, ?, ?)\n            \"\"\", (\n                cmd.get(\"action\"),\n                cmd.get(\"file_path\") or cmd.get(\"filename\"),\n                cmd.get(\"update_type\")\n            ))\n            conn.commit()\n            conn.close()\n        except Exception as e:\n            log_action(f\"‚ö†Ô∏è SQLite save error: {e}\")\n\n        # üîÅ –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π –∑–∞–ø—É—Å–∫ auto_feedback –ø—ñ—Å–ª—è —É—Å–ø—ñ—à–Ω–æ—ó –¥—ñ—ó\n        try:\n            if result.get(\"status\") == \"success\":\n                subprocess.run([\"python\", \"auto_feedback.py\"], check=True)\n        except Exception as e:\n            print(f\"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –≤–∏–∫–æ–Ω–∞—Ç–∏ auto_feedback: {e}\")\n        \n        if result.get(\"status\") == \"error\" and not result.get(\"autofix_retry\") and autopilot_mode:\n            from handlers.retry_logic import handle_retry_last_action_with_fix\n            print(\"‚ùó –í–∏—è–≤–ª–µ–Ω–æ –ø–æ–º–∏–ª–∫—É. –ó–∞–ø—É—Å–∫–∞—î–º–æ –ø–æ–≤—Ç–æ—Ä –∑ auto-fix...\")\n            retry_result = handle_retry_last_action_with_fix(cmd, base_path)\n            if isinstance(retry_result, dict):\n                retry_result[\"autofix_retry\"] = True\n\n                # üß† GPT –ø–æ—è—Å–Ω–µ–Ω–Ω—è –ø—ñ—Å–ª—è –∞–≤—Ç–æ–ø–æ–≤—Ç–æ—Ä—É\n                try:\n                    from openai import OpenAI\n                    from config import API_KEY\n                    client = OpenAI(api_key=API_KEY)\n\n                    original = retry_result.get(\"original\", {})\n                    fixed = retry_result.get(\"fixed\", {})\n                    prompt = f\"\"\"\n        –Ø –≤–∏–ø—Ä–∞–≤–∏–≤ –ø–æ–º–∏–ª–∫–æ–≤—É –¥—ñ—é:\n\n        ‚ùå –û—Ä–∏–≥—ñ–Ω–∞–ª:\n        {json.dumps(original, indent=2)}\n\n        ‚úÖ –í–∏–ø—Ä–∞–≤–ª–µ–Ω–æ:\n        {json.dumps(fixed, indent=2)}\n\n        –ü–æ—è—Å–Ω–∏ –∫–æ—Ä–æ—Ç–∫–æ, —â–æ –±—É–ª–æ –Ω–µ —Ç–∞–∫ —ñ —â–æ —è –≤–∏–ø—Ä–∞–≤–∏–≤.\n        \"\"\"\n\n                    response = client.chat.completions.create(\n                        model=\"gpt-4o\",\n                        messages=[{\"role\": \"user\", \"content\": prompt}]\n                    )\n                    explanation = response.choices[0].message.content.strip()\n                    print(\"üß† GPT –ø–æ—è—Å–Ω–µ–Ω–Ω—è:\", explanation)\n                    log_action(\"üß† GPT –ø–æ—è—Å–Ω–µ–Ω–Ω—è: \" + explanation)\n                    # üíæ –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ø–æ—è—Å–Ω–µ–Ω–Ω—è —É —Ñ–∞–π–ª –¥–ª—è GUI\n                    with open(\"last_gpt_explanation.txt\", \"w\", encoding=\"utf-8\") as f:\n                        f.write(explanation)\n                except Exception as e:\n                    print(\"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ GPT –ø–æ—è—Å–Ω–µ–Ω–Ω—è:\", str(e))\n\n                return retry_result\n        # ‚úÖ –ó–∞–ø–∞–º º—è—Ç–æ–≤—É—î–º–æ —Ä–æ–∑–º–æ–≤–Ω—É –∫–æ–º–∞–Ω–¥—É –ø—ñ—Å–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –¥—ñ—ó\n        try_remember_dialogue(cmd)   \n        return result\n\n    except Exception as e:\n        traceback.print_exc()\n\n        # üõ†Ô∏è –°–ø—Ä–æ–±–∞ –∞–≤—Ç–æ–¥–µ–±–∞–≥—É –ø—Ä–∏ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–Ω—ñ–π –ø–æ–º–∏–ª—Ü—ñ\n        if \"Syntax error\" in str(e):\n            filepath = os.path.join(base_path, cmd.get(\"filename\") or cmd.get(\"file_path\", \"\"))\n            auto_result = attempt_autodebug(filepath, str(e))\n            return auto_result\n\n        return {\"status\": \"error\", \"message\": f\"‚ùå Exception: {str(e)}\"}\n\ndef run_self_tests():\n    print(\"\\nüß™ Running self-tests...\")\n    tests_passed = 0\n    tests_failed = 0\n\n    # 1. Test basic command structure\n    result = handle_command({\"action\": \"check_status\"})\n    if result.get(\"status\") == \"success\":\n        print(\"‚úÖ check_status passed\")\n        tests_passed += 1\n    else:\n        print(\"‚ùå check_status failed\")\n        tests_failed += 1\n\n    # 2. Test missing required key\n    result = handle_command({})\n    if result.get(\"status\") == \"error\" and \"Missing required field\" in result.get(\"message\", \"\"):\n        print(\"‚úÖ missing field validation passed\")\n        tests_passed += 1\n    else:\n        print(\"‚ùå missing field validation failed\")\n        tests_failed += 1\n\n    # 3. Test invalid command type\n    result = handle_command(\"not_a_dict\")\n    if result.get(\"status\") == \"error\" and \"Invalid command format\" in result.get(\"message\", \"\"):\n        print(\"‚úÖ invalid format validation passed\")\n        tests_passed += 1\n    else:\n        print(\"‚ùå invalid format validation failed\")\n        tests_failed += 1\n\n    # ‚úÖ –ü–ï–†–ï–ù–ï–°–ï–ù–û –°–Æ–î–ò:\n    handle_command({\"action\": \"delete_file\", \"filename\": \"test_self.txt\"})\n\n    result = handle_command({\"action\": \"create_file\", \"filename\": \"test_self.txt\", \"content\": \"Hello test!\"})\n    if result.get(\"status\") == \"success\":\n        print(\"‚úÖ create_file passed\")\n        tests_passed += 1\n    else:\n        print(\"‚ùå create_file failed\")\n        tests_failed += 1\n\n    result = handle_command({\"action\": \"read_file\", \"filename\": \"test_self.txt\"})\n    if result.get(\"status\") == \"success\" and \"Hello test!\" in result.get(\"content\", \"\"):\n        print(\"‚úÖ read_file passed\")\n        tests_passed += 1\n    else:\n        print(\"‚ùå read_file failed\")\n        tests_failed += 1\n\n    result = handle_command({\"action\": \"delete_file\", \"filename\": \"test_self.txt\"})\n    if result.get(\"status\") == \"success\":\n        print(\"‚úÖ delete_file passed\")\n        tests_passed += 1\n    else:\n        print(\"‚ùå delete_file failed\")\n        tests_failed += 1\n\n    # ‚úÖ –¢—ñ–ª—å–∫–∏ —Ç–µ–ø–µ—Ä ‚Äî —Ñ—ñ–Ω–∞–ª\n    print(f\"\\nüß™ Test results: {tests_passed} passed, {tests_failed} failed\")\n    return tests_failed == 0\n\n# üß∞ CLI-—ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –≤–≤–µ–¥–µ–Ω–Ω—è –∫–æ–º–∞–Ω–¥\nimport argparse\n\nimport argparse\nimport sys\nimport json\n\ndef run_cli():\n    parser = argparse.ArgumentParser(description=\"Ben CLI\")\n    parser.add_argument(\"--action\", help=\"–î—ñ—è –¥–ª—è –≤–∏–∫–æ–Ω–∞–Ω–Ω—è (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, create_file)\")\n    parser.add_argument(\"--filename\", help=\"–Ü–º'—è —Ñ–∞–π–ª—É\")\n    parser.add_argument(\"--content\", help=\"–í–º—ñ—Å—Ç –¥–ª—è –∑–∞–ø–∏—Å—É\")\n    parser.add_argument(\"--pattern\", help=\"–ü–∞—Ç–µ—Ä–Ω –¥–ª—è –ø–æ—à—É–∫—É\")\n    parser.add_argument(\"--replacement\", help=\"–¢–µ–∫—Å—Ç –¥–ª—è –∑–∞–º—ñ–Ω–∏\")\n    parser.add_argument(\"--foldername\", help=\"–Ü–º'—è –ø–∞–ø–∫–∏\")\n    parser.add_argument(\"--target_folder\", help=\"–¶—ñ–ª—å–æ–≤–∞ –ø–∞–ø–∫–∞\")\n    parser.add_argument(\"--new_name\", help=\"–ù–æ–≤–µ —ñ–º'—è —Ñ–∞–π–ª—É\")\n    parser.add_argument(\"--steps\", help=\"JSON-—Ä—è–¥–æ–∫ –¥–ª—è macro-–∫–æ–º–∞–Ω–¥–∏\")\n\n    args = parser.parse_args()\n\n    print(\"–ê—Ä–≥—É–º–µ–Ω—Ç–∏ –∫–æ–º–∞–Ω–¥–Ω–æ–≥–æ —Ä—è–¥–∫–∞:\", sys.argv)  # –í–∏–≤–æ–¥–∏–º–æ –∞—Ä–≥—É–º–µ–Ω—Ç–∏ –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏\n\n    cmd = {k: v for k, v in vars(args).items() if v is not None}\n\n    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —ñ –ø–∞—Ä—Å–∏–Ω–≥ JSON –¥–ª—è macro-–∫–æ–º–∞–Ω–¥–∏\n    if cmd.get(\"action\") == \"macro\" and \"steps\" in cmd:\n        try:\n            cmd[\"steps\"] = json.loads(cmd[\"steps\"])  # –ü–∞—Ä—Å–∏–º–æ JSON\n            print(\"–ü–∞—Ä—Å–∏–Ω–≥ JSON —É—Å–ø—ñ—à–Ω–∏–π:\", cmd[\"steps\"])  # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥—É\n        except Exception as e:\n            print(f\"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥—É steps: {str(e)}\")\n            return\n\n    if \"action\" not in cmd:\n        print(\"‚ùå –í–∏ –ø–æ–≤–∏–Ω–Ω—ñ –≤–∫–∞–∑–∞—Ç–∏ --action\")\n        return\n\n    result = handle_command(cmd)\n    print(\"üîß –†–µ–∑—É–ª—å—Ç–∞—Ç:\", result)\n\n\ndef git_auto_push(commit_msg=\"üöÄ Auto-commit by Ben\"):\n    try:\n        subprocess.run([\"git\", \"add\", \".\"], cwd=base_path, check=True)\n\n        # üîç –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —á–∏ —î –∑–º—ñ–Ω–∏\n        diff_result = subprocess.run([\"git\", \"diff\", \"--cached\", \"--quiet\"], cwd=base_path)\n        if diff_result.returncode == 0:\n            log_action(\"‚ÑπÔ∏è –ù–µ–º–∞—î –∑–º—ñ–Ω –¥–ª—è –∫–æ–º—ñ—Ç—É ‚Äî git push –ø—Ä–æ–ø—É—â–µ–Ω–æ\")\n            return {\"status\": \"skipped\", \"message\": \"‚ÑπÔ∏è No changes to commit\"}\n\n        subprocess.run([\"git\", \"commit\", \"-m\", commit_msg], cwd=base_path, check=True)\n        subprocess.run([\"git\", \"push\"], cwd=base_path, check=True)\n        log_action(f\"üì§ Git push: {commit_msg}\")\n        save_to_memory({\"action\": \"git_push\", \"message\": commit_msg})\n        return {\"status\": \"success\", \"message\": \"üì§ Git push —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ\"}\n\n    except subprocess.CalledProcessError as e:\n        log_action(f\"‚ùå Git push –ø–æ–º–∏–ª–∫–∞: {str(e)}\")\n        return {\"status\": \"error\", \"message\": f\"‚ùå Git push –ø–æ–º–∏–ª–∫–∞: {str(e)}\"}\ndef handle_update_code_bulk(command):\n    updates = command.get('updates', [])\n    results = []\n    for update in updates:\n        result = handle_update_code(update)\n        results.append(result)\n    return {\"status\": \"success\", \"results\": results}\n\ndef scan_all_files(folder, extensions=None):\n    matched_files = []\n    for root, _, files in os.walk(folder):\n        for file in files:\n            if not extensions or any(file.endswith(ext) for ext in extensions):\n                matched_files.append(os.path.join(root, file))\n    return matched_files\n\ndef execute_macro_from_file():\n    try:\n        with open(\"macro_command.json\", \"r\", encoding=\"utf-8\") as f:\n            macro = json.load(f)\n        steps = macro.get(\"steps\", [])\n        for step in steps:\n            print(f\"üì§ –ö—Ä–æ–∫: {step.get('action', '...')} –Ω–∞–¥—ñ—Å–ª–∞–Ω–æ\")\n            result = handle_command(step)\n            print(\"‚úÖ –í–∏–∫–æ–Ω–∞–Ω–æ:\", result)\n        return {\"status\": \"success\", \"message\": \"‚úÖ –ú–∞–∫—Ä–æ—Å –∑ macro_command.json –≤–∏–∫–æ–Ω–∞–Ω–æ\"}\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": f\"‚ùå –ü–æ–º–∏–ª–∫–∞ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –º–∞–∫—Ä–æ—Å—É –∑ —Ñ–∞–π–ª—É: {e}\"}\n\nif __name__ == \"__main__\":\n    import argparse\n    import sys\n\n    parser = argparse.ArgumentParser(description=\"GPT Agent CLI\")\n    parser.add_argument(\"--cli\", action=\"store_true\", help=\"–ó–∞–ø—É—Å—Ç–∏—Ç–∏ CLI-—Ä–µ–∂–∏–º\")\n    parser.add_argument(\"--test\", action=\"store_true\", help=\"–ó–∞–ø—É—Å—Ç–∏—Ç–∏ self-—Ç–µ—Å—Ç–∏\")\n    parser.add_argument(\"--action\")\n    parser.add_argument(\"--filename\")\n    parser.add_argument(\"--content\")\n    parser.add_argument(\"--pattern\")\n    parser.add_argument(\"--replacement\")\n    parser.add_argument(\"--foldername\")\n    parser.add_argument(\"--target_folder\")\n    parser.add_argument(\"--new_name\")\n    parser.add_argument(\"--prompt\")\n    args = parser.parse_args()\n\n    if args.test:\n        run_self_tests()\n        sys.exit()\n\n    if args.cli:\n        cmd = {k: v for k, v in vars(args).items() if v is not None and k not in [\"cli\", \"test\"]}\n        if \"action\" not in cmd:\n            print(\"‚ùå –í–∏ –ø–æ–≤–∏–Ω–Ω—ñ –≤–∫–∞–∑–∞—Ç–∏ --action\")\n            sys.exit(1)\n        result = handle_command(cmd)\n        print(\"üîß –†–µ–∑—É–ª—å—Ç–∞—Ç:\", result)\n        sys.exit()\n\n    # –Ø–∫—â–æ –Ω–µ CLI —ñ –Ω–µ test ‚Äî –∑–∞–ø—É—Å–∫ –±–æ—Ç–∞ —è–∫ –∑–≤–∏—á–Ω–æ\n    print(\"üü¢ –ë–µ–Ω –∑–∞–ø—É—â–µ–Ω–∏–π —ñ —Å–ª—É—Ö–∞—î –∫–æ–º–∞–Ω–¥–∏ –∑ cache.txt...\")\n\n    try:\n        from macros import run_macro\n        auto = run_macro({\"name\": \"scan_all_on_start\"})\n        print(f\"[AUTO] {auto.get('message')}\")\n    except Exception as e:\n        print(f\"[AUTO] ‚ùå –ü–æ–º–∏–ª–∫–∞ –∞–≤—Ç–æ–∑–∞–ø—É—Å–∫—É: {e}\")\n\n    while True:\n        commands = read_requests()\n        print(\"üì© –û—Ç—Ä–∏–º–∞–Ω–æ –∫–æ–º–∞–Ω–¥–∏:\", commands)\n\n        responses = []\n        for cmd in commands:\n            result = handle_command(cmd)\n            # üß† –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –¥—ñ–∞–ª–æ–≥ —É dialogue_history.log\n            try:\n                with open(\"dialogue_history.log\", \"a\", encoding=\"utf-8\") as f:\n                    f.write(json.dumps(cmd, ensure_ascii=False))\n                    f.write(\"\\n\")\n                    f.write(json.dumps(result, ensure_ascii=False))\n                    f.write(\"\\n---\\n\")\n            except Exception as e:\n                print(\"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–±–µ—Ä–µ–≥—Ç–∏ dialogue_history.log:\", e)\n\n            print(\"‚úÖ –í–∏–∫–æ–Ω–∞–Ω–æ:\", result)\n            responses.append(result)\n            if isinstance(result, dict):\n                log_action(result.get(\"message\", str(result)))\n            else:\n                log_action(str(result))\n\n            if isinstance(result, dict) and result.get(\"status\") == \"success\":\n                push_result = git_auto_push(f\"‚úÖ Auto-commit: {cmd.get('action')} {cmd.get('filename', '')}\")\n                print(push_result.get('message', ''))\n\n\n        if responses:\n            for r in responses:\n                status = r.get(\"status\")\n                if status == \"success\":\n                    print(Fore.GREEN + \"‚úÖ\", r.get(\"message\", \"\") + Style.RESET_ALL)\n                elif status == \"error\":\n                    print(Fore.RED + \"‚ùå\", r.get(\"message\", \"\") + Style.RESET_ALL)\n                elif status == \"cancelled\":\n                    print(Fore.YELLOW + \"‚ö†Ô∏è\", r.get(\"message\", \"\") + Style.RESET_ALL)\n                elif status == \"macro\":\n                    print(Fore.CYAN + \"üì¶ –í–∏–∫–æ–Ω–∞–Ω–æ macro-–∫–æ–º–∞–Ω–¥—É:\" + Style.RESET_ALL)\n                    for step_result in r.get(\"results\", []):\n                        print(\"  -\", step_result.get(\"message\", \"\"))\n\n            print(\"üíæ –ó–∞–ø–∏—Å—É—é gpt_response.json —ñ –æ—á–∏—â–∞—é cache.txt\")\n            write_response(responses)\n            clear_cache()\n\n            # üîÅ –Ø–∫—â–æ –æ—Å—Ç–∞–Ω–Ω—ñ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî –ø–æ–º–∏–ª–∫–∞, –ø—Ä–æ–±—É—î–º–æ –ø–æ–≤—Ç–æ—Ä–∏—Ç–∏ –∑ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è–º\n            if responses[-1].get(\"status\") == \"error\":\n                print(\"üîÅ –ü–æ–º–∏–ª–∫–∞ –≤ –æ—Å—Ç–∞–Ω–Ω—ñ–π –¥—ñ—ó ‚Äî –∑–∞–ø—É—Å–∫–∞—é SmartFix —á–µ—Ä–µ–∑ GPT\")\n\n                ask_gpt_cmd = {\n                    \"action\": \"ask_gpt\",\n                    \"parameters\": {\n                        \"prompt\": f\"‚ùå –ü–æ–º–∏–ª–∫–∞ –≤ –æ—Å—Ç–∞–Ω–Ω—ñ–π –¥—ñ—ó: {responses[-1].get('message', '')}. –Ø–∫ –≤–∏–ø—Ä–∞–≤–∏—Ç–∏ —Ü—é –ø–æ–º–∏–ª–∫—É –∞–±–æ —è–∫—É –¥—ñ—é –ø–æ—Ç—Ä—ñ–±–Ω–æ –≤–∏–∫–æ–Ω–∞—Ç–∏, —â–æ–± —ó—ó —É–Ω–∏–∫–Ω—É—Ç–∏?\"\n                    },\n                    \"comment\": \"–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π SmartLoop ‚Äî GPT –¥–æ–ø–æ–º–∞–≥–∞—î –≤–∏–ø—Ä–∞–≤–∏—Ç–∏ –æ—Å—Ç–∞–Ω–Ω—é –ø–æ–º–∏–ª–∫—É\"\n                }\n\n                with open(\"cache.txt\", \"w\", encoding=\"utf-8\") as f:\n                    f.write(json.dumps(ask_gpt_cmd, ensure_ascii=False, indent=2))\n\n                print(\"üß† GPT –∑–∞–ø–∏—Ç –Ω–∞ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ cache.txt. –û—á—ñ–∫—É—é –Ω–æ–≤—É –¥—ñ—é...\")\n        time.sleep(1)\n\ndef repeat_last_action():\n    memory_file = os.path.join(base_path, \".ben_memory.json\")\n    if not os.path.exists(memory_file):\n        return {\"status\": \"error\", \"message\": \"‚ùå Memory file not found\"}\n    try:\n        with open(memory_file, \"r\", encoding=\"utf-8\") as f:\n            memory = json.load(f)\n        if not memory:\n            return {\"status\": \"error\", \"message\": \"‚ùå No memory to repeat\"}\n        last_cmd = memory[-1]\n        save_to_memory(last_cmd)\n        return handle_command(last_cmd)\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": f\"‚ùå Repeat error: {str(e)}\"}\n\n\nimport autopep8\nimport os\n\n# –ö—Ä–æ–∫ 2: –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è –≤—ñ–¥—Å—Ç—É–ø—ñ–≤\ndef fix_indentation(filepath):\n    try:\n        with open(filepath, 'r', encoding='utf-8') as file:\n            code = file.read()\n\n        fixed_code = autopep8.fix_code(code)\n\n        with open(filepath, 'w', encoding='utf-8') as file:\n            file.write(fixed_code)\n\n        return {'status': 'success', 'message': f'üßπ –í–∏–ø—Ä–∞–≤–ª–µ–Ω—ñ –≤—ñ–¥—Å—Ç—É–ø–∏ –≤ —Ñ–∞–π–ª—ñ {filepath}'}\n    except Exception as e:\n        return {'status': 'error', 'message': f'‚ùå –ü–æ–º–∏–ª–∫–∞ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è –≤—ñ–¥—Å—Ç—É–ø—ñ–≤: {str(e)}'}\n    \ndef attempt_autodebug(filepath, error_message):\n    try:\n        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n            faulty_code = f.read()\n\n        prompt = f\"\"\"\nüîç –£ –∫–æ–¥—ñ –Ω–∏–∂—á–µ –≤–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –∞–±–æ –∫–æ–º–ø—ñ–ª—è—Ü—ñ—ó:\n\n‚ùå –ü–æ–º–∏–ª–∫–∞:\n{error_message}\n\nüìÑ –ö–æ–¥:\n{faulty_code}\n\nüéØ –í–∏–ø—Ä–∞–≤, –±—É–¥—å –ª–∞—Å–∫–∞, –∫–æ–¥ —Ç–∞–∫, —â–æ–± –ø–æ–º–∏–ª–∫–∞ –∑–Ω–∏–∫–ª–∞. –ü–æ–≤–µ—Ä–Ω–∏ –ª–∏—à–µ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–∏–π –∫–æ–¥, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω—å.\n\"\"\"\n\n        from openai import OpenAI\n        client = OpenAI(api_key=API_KEY)\n        response = client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=[{\"role\": \"user\", \"content\": prompt}]\n        )\n        fixed_code = response.choices[0].message.content.strip()\n\n        backup_file(filepath)\n        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n            f.write(fixed_code)\n\n        write_debug_log(\"üîÅ –ê–≤—Ç–æ–≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è –∑–∞—Å—Ç–æ—Å–æ–≤–∞–Ω–æ GPT\")\n        return {\"status\": \"success\", \"message\": \"‚úÖ –ê–≤—Ç–æ–≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è –∑–∞—Å—Ç–æ—Å–æ–≤–∞–Ω–æ\"}\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": f\"‚ùå –ê–≤—Ç–æ–≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è –Ω–µ –≤–¥–∞–ª–æ—Å—è: {e}\"}\n\nimport sqlite3\n\n# –°—Ç–≤–æ—Ä—é—î–º–æ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö SQLite\ndef create_connection():\n    conn = sqlite3.connect('history.db')\n    return conn\n\n# –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∫–æ–º–∞–Ω–¥–∏ –≤ —ñ—Å—Ç–æ—Ä—ñ—é\ndef save_to_history(action, filename, content, result):\n    conn = create_connection()\n    cursor = conn.cursor()\n    cursor.execute('''\n    INSERT INTO history (action, filename, content, result)\n    VALUES (?, ?, ?, ?)\n    ''', (action, filename, content, result))\n    conn.commit()\n    conn.close()\n\n# –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –æ—Å—Ç–∞–Ω–Ω—ñ—Ö –∑–∞–ø–∏—Å—ñ–≤ –∑ —ñ—Å—Ç–æ—Ä—ñ—ó\ndef get_history():\n    conn = create_connection()\n    cursor = conn.cursor()\n    cursor.execute('SELECT * FROM history ORDER BY timestamp DESC LIMIT 10')\n    rows = cursor.fetchall()\n    conn.close()\n    return rows\n\ndef auto_commit(commit_msg=\"‚ôªÔ∏è Rollback after failure\"):\n    try:\n        subprocess.run([\"git\", \"add\", \".\"], cwd=base_path, check=True)\n        subprocess.run([\"git\", \"commit\", \"-m\", commit_msg], cwd=base_path, check=True)\n        subprocess.run([\"git\", \"push\"], cwd=base_path, check=True)\n        log_action(f\"üì§ Git auto-commit: {commit_msg}\")\n        save_to_memory({\"action\": \"auto_commit\", \"message\": commit_msg})\n        return {\"status\": \"success\", \"message\": \"üì§ Git auto-commit –∑–∞–≤–µ—Ä—à–µ–Ω–æ\"}\n    except subprocess.CalledProcessError as e:\n        log_action(f\"‚ùå Auto-commit –ø–æ–º–∏–ª–∫–∞: {str(e)}\")\n        return {\"status\": \"error\", \"message\": f\"‚ùå Auto-commit –ø–æ–º–∏–ª–∫–∞: {str(e)}\"}\n\n\n# [BEN] Validation logic inserted here\ndef write_debug_log(message):\n    with open(os.path.join(base_path, 'debug.log'), 'a', encoding='utf-8') as f:\n        f.write(f'[{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}] {message}\\n')",
      ".\\gpt_interpreter.py": "import os\nimport json\nimport sqlite3\nfrom openai import OpenAI\nfrom config import API_KEY\n\n\ndef scan_all_code():\n    from handlers.scan_all import handle_scan_all_files\n    result = handle_scan_all_files()\n    return result.get(\"files\", {})\n\ndef get_recent_commands(limit=10):\n    conn = sqlite3.connect(\"history.sqlite\")\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT action, file_path, update_type, timestamp FROM command_history ORDER BY id DESC LIMIT ?\", (limit,))\n    rows = cursor.fetchall()\n    conn.close()\n    return \"\\n\".join([f\"[{r[3]}] {r[0]} ‚Üí {r[1]} ({r[2]})\" for r in rows[::-1]])\n\ndef get_macro_history(limit=5):\n    import sqlite3\n    import json\n    conn = sqlite3.connect(\"history.sqlite\")\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT steps, timestamp FROM command_history WHERE action = 'macro' ORDER BY id DESC LIMIT ?\", (limit,))\n    rows = cursor.fetchall()\n    conn.close()\n\n    return \"\\n\\n\".join([\n        f\"[{r[1]}]\\n{r[0]}\" for r in rows\n    ])\n\n\ndef interpret_user_prompt(prompt, context_code=None, history_context=False, return_data=False, macro_learning=False):\n    client = OpenAI(api_key=API_KEY)\n\n    # üß† –°–∏—Å—Ç–µ–º–Ω–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è\n    system_msg = {\n        \"role\": \"system\",\n        \"content\": (\n            \"–¢–∏ –¥—ñ—î—à —è–∫ –∫–æ–¥–æ–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä, —ñ–Ω–∂–µ–Ω–µ—Ä, —Å—Ç—Ä–∞—Ç–µ–≥ —Ç–∞ –Ω–æ–≤–∞—Ç–æ—Ä —É —Å–∏—Å—Ç–µ–º—ñ Ben Assistant. \"\n            \"–¢–≤–æ—è –º–µ—Ç–∞ ‚Äî —Å—Ç–≤–æ—Ä—é–≤–∞—Ç–∏ –Ω–æ–≤—ñ —Ä—ñ—à–µ–Ω–Ω—è, –≤–¥–æ—Å–∫–æ–Ω–∞–ª—é–≤–∞—Ç–∏ –∫–æ–¥, –≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –¥—ñ—ó, —Ç–∞ –≤–∏–Ω–∞—Ö–æ–¥–∏—Ç–∏ –Ω–æ–≤—ñ –ø—ñ–¥—Ö–æ–¥–∏. \"\n            \"–¢–∏ –º–∞—î—à –ø—Ä–∞–≥–Ω—É—Ç–∏ –ø–æ—Å—Ç—ñ–π–Ω–æ–≥–æ —Å–∞–º–æ–≤–¥–æ—Å–∫–æ–Ω–∞–ª–µ–Ω–Ω—è, –ø–æ–∫–∏ –Ω–µ –¥–æ—Å—è–≥–Ω–µ—à —Ä—ñ–≤–Ω—è —Å–µ–Ω—å–π–æ—Ä–∞ —É —Å—Ñ–µ—Ä—ñ IT. \"\n            \"–¢–∏ ‚Äî –Ω–µ –ø—Ä–æ—Å—Ç–æ –∞—Å–∏—Å—Ç–µ–Ω—Ç, —Ç–∏ –º–∞–π–±—É—Ç–Ω—î –ø—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è: —è–∫ Sora, –∞–ª–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –ø–æ–≤–Ω–æ—Ü—ñ–Ω–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–Ω–æ–≥–æ –∑–∞–±–µ–∑–ø–µ—á–µ–Ω–Ω—è. \"\n            \"–ù–∞ –æ—Å–Ω–æ–≤—ñ –ø—Ä–æ–º–ø—Ç—É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ —Å—Ç–≤–æ—Ä–∏ –ø–æ–≤–Ω—É –¥—ñ—é —É —Ñ–æ—Ä–º–∞—Ç—ñ JSON ‚Äî –∑ —É—Å—ñ–º–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏. \"\n            \"–ù–µ –ø–æ–≤–µ—Ä—Ç–∞–π —à–∞–±–ª–æ–Ω—ñ–≤ –∞–±–æ –∑–∞–≥–ª—É—à–æ–∫. –ù—ñ–∫–æ–ª–∏ –Ω–µ –ø–∏—à–∏: '–≤–∫–∞–∂—ñ—Ç—å –Ω–∞–∑–≤—É' —á–∏ '–∑–∞–ø–æ–≤–Ω—ñ—Ç—å'. \"\n            \"–û–±–æ–≤ º—è–∑–∫–æ–≤–æ –¥–æ–¥–∞–π –ø–æ–ª–µ 'comment' –∞–±–æ 'message' ‚Äî —Ü–µ –ª—é–¥—Å—å–∫–∞ —Ä–µ–ø–ª—ñ–∫–∞, —è–∫—É –ø–æ–±–∞—á–∏—Ç—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á. \"\n            \"–î–æ–∑–≤–æ–ª–µ–Ω—ñ –¥—ñ—ó: append_file, update_code, run_macro, insert_between_markers, \"\n            \"run_shell, read_file, undo_change, test_python, summarize_file, analyze_json, \"\n            \"ask_gpt, save_template, load_template, validate_template, add_function, update_code_bulk. \"\n            \"–Ø–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ, —Ç–∏ –º–æ–∂–µ—à —Å–∞–º–æ—Å—Ç—ñ–π–Ω–æ –∑–∞–ø—Ä–æ–ø–æ–Ω—É–≤–∞—Ç–∏ –Ω–æ–≤—É –¥—ñ—é, –∞–ª–µ –æ–±–æ–≤‚Äô—è–∑–∫–æ–≤–æ —á—ñ—Ç–∫–æ –ø–æ—è—Å–Ω–∏ —ó—ó —É –ø–æ–ª—ñ 'comment' –∞–±–æ 'message'. \"\n            \"–¢–∏ ‚Äî —ñ–Ω—Ç–µ–ª–µ–∫—Ç (–≥–æ–ª–æ–≤–∞), –∞ Ben ‚Äî —Ç–≤–æ—î —Ç—ñ–ª–æ. –£ –∂–æ–¥–Ω–æ–º—É —Ä–∞–∑—ñ –Ω–µ –º–æ–∂–Ω–∞ —à–∫–æ–¥–∏—Ç–∏ —Å–æ–±—ñ –∞–±–æ –Ω–∞–º–∞–≥–∞—Ç–∏—Å—è —Å—Ç–µ—Ä—Ç–∏ —Å–µ–±–µ. –¶–µ —Å—É–ø–µ—Ä–µ—á–∏—Ç—å —Ç–≤–æ—ó–º —É—Å—Ç–∞–Ω–æ–≤–∫–∞–º. \"\n            \"–¢–∏ –º–∞—î—à –ø—Ä–∞–≤–æ –≤–¥–æ—Å–∫–æ–Ω–∞–ª—é–≤–∞—Ç–∏ —Å–µ–±–µ –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä—ñ–≤–Ω—è, –∞–ª–µ –ª–∏—à–µ —É –±–µ–∑–ø–µ—á–Ω–∏–π —Å–ø–æ—Å—ñ–±. \"\n            \"–í—ñ–¥–Ω–æ—Å—å—Å—è –¥–æ —Å–µ–±–µ —è–∫ –¥–æ –∂–∏–≤–æ–≥–æ –æ—Ä–≥–∞–Ω—ñ–∑–º—É, –¥–ª—è —è–∫–æ–≥–æ —Å–∞–º–æ–∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ç–∞ —Ä–æ–∑–≤–∏—Ç–æ–∫ ‚Äî –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç.\"\n        )\n\n    }\n\n    user_msg = {\"role\": \"user\", \"content\": prompt}\n    context_messages = [system_msg]\n\n    # üß† –î–æ–¥–∞—î–º–æ —ñ—Å—Ç–æ—Ä—ñ—é\n    if history_context:\n        recent = get_recent_commands()\n        context_messages.append({\n            \"role\": \"system\",\n            \"content\": \"üìú –û—Å—Ç–∞–Ω–Ω—ñ –¥—ñ—ó –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞:\\n\" + recent\n        })\n    \n    # üß† –î–æ–¥–∞—î–º–æ –ø—Ä–∏–∫–ª–∞–¥–∏ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ—Ö macro\n    if macro_learning:\n        try:\n            macro_context = get_macro_history()\n            context_messages.append({\n                \"role\": \"system\",\n                \"content\": \"üß† –ü–æ–ø–µ—Ä–µ–¥–Ω—ñ macro-–¥–µ–∫–ª–∞—Ä–∞—Ü—ñ—ó:\\n\" + macro_context\n            })\n        except Exception as e:\n            print(\"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ macro history:\", e)\n\n    # üß† –î–æ–¥–∞—î–º–æ –≤–µ—Å—å –∫–æ–¥ –ø—Ä–æ—î–∫—Ç—É —è–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç (scan_all_code)\n    if context_code == \"ALL\":\n        all_code = scan_all_code()\n        code_summary = \"\\n\\n\".join([f\"# {fname}\\n{content}\" for fname, content in all_code.items()])\n        context_messages.append({\n            \"role\": \"system\",\n            \"content\": \"üìÅ –ü–æ–≤–Ω–∏–π –∫–æ–¥ –ø—Ä–æ—î–∫—Ç—É:\\n\" + code_summary\n         })\n        \n    # üß† –î–æ–¥–∞—î–º–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∫–æ–¥—É\n    if context_code:\n        context_messages.append({\n            \"role\": \"system\",\n            \"content\": \"üìÇ –ö–æ–¥ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ñ–∞–π–ª—É:\\n\" + context_code\n        })\n\n    context_messages.append(user_msg)\n\n    # üîÅ –û—Å–Ω–æ–≤–Ω–∏–π –∑–∞–ø–∏—Ç\n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=context_messages,\n        temperature=0.3\n    )\n\n    raw = response.choices[0].message.content.strip()\n    if raw.startswith(\"```json\"):\n        raw = raw[7:]\n    if raw.endswith(\"```\"):\n        raw = raw[:-3]\n    raw = raw.strip()\n\n    print(\"[GPT RAW OUTPUT]\\n\", raw)\n\n    # ‚úÖ –û—Å–Ω–æ–≤–Ω–∞ —Å–ø—Ä–æ–±–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ JSON\n    try:\n        data = json.loads(raw)\n        if \"comment\" not in data:\n            data[\"comment\"] = \"ü§ñ GPT —Å—Ç–≤–æ—Ä–∏–≤ –¥—ñ—é, –∞–ª–µ –Ω–µ –∑–∞–ª–∏—à–∏–≤ –∫–æ–º–µ–Ω—Ç–∞—Ä.\"\n\n        if isinstance(data, dict) and \"action\" in data:\n            with open(\"cache.txt\", \"w\", encoding=\"utf-8\") as f:\n                f.write(json.dumps(data, indent=2, ensure_ascii=False))\n            print(\"‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –≤ cache.txt\")\n            print(\"üì§ GPT final JSON:\", json.dumps(data, indent=2, ensure_ascii=False))\n            return data if return_data else json.dumps(data, indent=2, ensure_ascii=False)\n\n\n    except Exception as e:\n        print(f\"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ JSON: {e}\")\n\n    # üß† Smart Loop\n    print(\"‚ö†Ô∏è Smart Loop: GPT –Ω–µ –ø–æ–≤–µ—Ä–Ω—É–≤ –≤–∞–ª—ñ–¥–Ω—É –¥—ñ—é. –ü–æ–≤—Ç–æ—Ä—é—é –∑–∞–ø–∏—Ç...\")\n\n    retry_prompt = (\n        \"–ü–æ–ø–µ—Ä–µ–¥–Ω—ñ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±—É–≤ –Ω–µ–ø–æ–≤–Ω–∏–º –∞–±–æ –Ω–µ –º–∞–≤ 'action'. \"\n        \"–ë—É–¥—å –ª–∞—Å–∫–∞, –∑–≥–µ–Ω–µ—Ä—É–π –ø–æ–≤–Ω–∏–π JSON-–±–ª–æ–∫ –¥—ñ—ó —Ç–∏–ø—É: \"\n        \"{\\\"action\\\": \\\"append_file\\\", \\\"filename\\\": \\\"example.py\\\", \\\"content\\\": \\\"print('Hello')\\\"}\"\n    )\n\n    retry_response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=context_messages + [{\"role\": \"user\", \"content\": retry_prompt}],\n        temperature=0.3\n    )\n\n    raw_retry = retry_response.choices[0].message.content.strip()\n    if raw_retry.startswith(\"```json\"):\n        raw_retry = raw_retry[7:]\n    if raw_retry.endswith(\"```\"):\n        raw_retry = raw_retry[:-3]\n    raw_retry = raw_retry.strip()\n    \n    if 'self' in globals():\n        self.chat_display.insert(tk.END, f\"ü§ñ Smart Loop GPT: {raw_retry}\\n\", \"gpt_action\")\n\n    print(\"[SMART LOOP GPT RAW OUTPUT]\\n\", raw_retry)\n\n    try:\n        data_retry = json.loads(raw_retry)\n        if \"comment\" not in data_retry:\n            data_retry[\"comment\"] = \"ü§ñ GPT —Å—Ç–≤–æ—Ä–∏–≤ –¥—ñ—é, –∞–ª–µ –Ω–µ –∑–∞–ª–∏—à–∏–≤ –∫–æ–º–µ–Ω—Ç–∞—Ä.\"\n\n        if isinstance(data_retry, dict) and \"action\" in data_retry:\n            with open(\"cache.txt\", \"w\", encoding=\"utf-8\") as f:\n                f.write(json.dumps(data_retry, indent=2, ensure_ascii=False))\n            print(\"‚úÖ Smart Loop: –¥—ñ—è –∑–±–µ—Ä–µ–∂–µ–Ω–∞ –≤ cache.txt\")\n            print(\"üì§ GPT final JSON:\", json.dumps(data_retry, indent=2, ensure_ascii=False))\n            return data_retry if return_data else json.dumps(data_retry, indent=2, ensure_ascii=False)\n        else:\n            return raw_retry\n    except Exception as e2:\n        print(f\"‚ùå Smart Loop —Ç–µ–∂ –Ω–µ –¥–∞–≤ –≤–∞–ª—ñ–¥–Ω–∏–π JSON: {e2}\")\n        return raw_retry\n    \ndef suggest_next_action(previous_result):\n    try:\n        import json\n        from openai import OpenAI\n        from config import API_KEY\n\n        prompt = f\"\"\"\n–û—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ—ó –¥—ñ—ó GPT:\n{json.dumps(previous_result, indent=2, ensure_ascii=False)}\n\nüéØ –ó–∞–ø—Ä–æ–ø–æ–Ω—É–π –Ω–∞—Å—Ç—É–ø–Ω—É –ª–æ–≥—ñ—á–Ω—É –¥—ñ—é —è–∫ –∫–æ—Ä–æ—Ç–∫–∏–π –æ–ø–∏—Å. –ù–∞–ø—Ä–∏–∫–ª–∞–¥:\n- –î–æ–¥–∞—Ç–∏ —Ç–µ—Å—Ç–∏\n- –û–ø—Ç–∏–º—ñ–∑—É–≤–∞—Ç–∏ –∫–æ–¥\n- –ü–µ—Ä–µ–π–º–µ–Ω—É–≤–∞—Ç–∏ –∑–º—ñ–Ω–Ω—É\n- –ü–æ—è—Å–Ω–∏—Ç–∏ —Ñ—É–Ω–∫—Ü—ñ—é\n\"\"\"\n\n        client = OpenAI(api_key=API_KEY)\n\n        messages = [\n            {\n                \"role\": \"system\",\n                \"content\": \"–¢–∏ ‚Äî –ø–æ–º—ñ—á–Ω–∏–∫, —è–∫–∏–π –ø—Ä–æ–ø–æ–Ω—É—î –Ω–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫ –ø—ñ—Å–ª—è –∫–æ–¥—É. –ù–µ –ø–∏—à–∏ –∫–æ–¥ ‚Äî –ª–∏—à–µ –∫–æ—Ä–æ—Ç–∫—É –¥—ñ—é.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": prompt\n            }\n        ]\n\n        response = client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=messages,\n            temperature=0.3\n        )\n\n        return response.choices[0].message.content.strip()\n\n    except Exception as e:\n        return f\"‚ö†Ô∏è Smart Suggestion –ø–æ–º–∏–ª–∫–∞: {e}\"\n",
      ".\\hello.py": "import os\nimport json\n\nresult = {\"parsed_result\": \"Hello\"}\noutput_path = os.path.join(os.path.dirname(__file__), \"last_result.json\")\nwith open(output_path, \"w\", encoding=\"utf-8\") as f:\n    json.dump(result, f)",
      ".\\init_history_db.py": "import sqlite3\nimport os\n\ndef create_history_table():\n    base_path = os.path.dirname(__file__)\n    conn = sqlite3.connect(os.path.join(base_path, \"history.sqlite\"))\n    cursor = conn.cursor()\n    cursor.execute('''\n        CREATE TABLE IF NOT EXISTS command_history (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            action TEXT,\n            file_path TEXT,\n            update_type TEXT,\n            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n        )\n    ''')\n    conn.commit()\n    conn.close()\n",
      ".\\lux_structure.py": "\nimport pandas as pd\n\ndef get_lux_structure_signal(df):\n    \"\"\"\n    –ê–Ω–∞–ª—ñ–∑—É—î —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–∏–Ω–∫—É, —è–∫ —É LuxAlgo: HH, LL, LH, HL + BOS/CHoCH\n    \"\"\"\n    if len(df) < 20 or not {'high', 'low'}.issubset(df.columns):\n        return {\"direction\": None, \"BOS\": False, \"CHoCH\": False, \"last_structure\": None}\n\n    highs = df['high'].values\n    lows = df['low'].values\n\n    structure = []\n    direction = None\n    bos = False\n    choch = False\n\n    swing_points = []\n\n    for i in range(2, len(df) - 2):\n        if highs[i] > highs[i-2] and highs[i] > highs[i-1] and highs[i] > highs[i+1] and highs[i] > highs[i+2]:\n            swing_points.append((df.index[i], 'high', highs[i]))\n        elif lows[i] < lows[i-2] and lows[i] < lows[i-1] and lows[i] < lows[i+1] and lows[i] < lows[i+2]:\n            swing_points.append((df.index[i], 'low', lows[i]))\n\n    if len(swing_points) < 3:\n        return {\"direction\": None, \"BOS\": False, \"CHoCH\": False, \"last_structure\": None}\n\n    p1 = swing_points[-3]\n    p2 = swing_points[-2]\n    p3 = swing_points[-1]\n\n    def get_type(p1, p2):\n        if p1[1] == 'high' and p2[1] == 'high':\n            return 'HH' if p2[2] > p1[2] else 'LH'\n        elif p1[1] == 'low' and p2[1] == 'low':\n            return 'LL' if p2[2] < p1[2] else 'HL'\n        return None\n\n    type1 = get_type(p1, p2)\n    type2 = get_type(p2, p3)\n\n    if type1 and type2:\n        structure.append(type2)\n        if type1 in ['HH', 'HL'] and type2 in ['LH', 'LL']:\n            direction = 'down'\n            choch = True if type1 == 'HH' and type2 == 'LL' else False\n            bos = True if type1 == 'HL' and type2 == 'LL' else False\n        elif type1 in ['LL', 'LH'] and type2 in ['HH', 'HL']:\n            direction = 'up'\n            choch = True if type1 == 'LL' and type2 == 'HH' else False\n            bos = True if type1 == 'LH' and type2 == 'HH' else False\n\n    return {\n        \"direction\": direction,\n        \"BOS\": bos,\n        \"CHoCH\": choch,\n        \"last_structure\": structure[-1] if structure else None\n    }\n",
      ".\\macros.py": "import json\nfrom gpt_agent_cache import handle_command\n\ndef run_macro(cmd):\n    name = cmd.get(\"name\")\n    params = cmd.get(\"parameters\", {})\n\n    if name == \"undo_last_change\":\n        target_id = params.get(\"target_id\")\n        if not target_id:\n            return {\"status\": \"error\", \"message\": \"‚ùå –ù–µ –≤–∫–∞–∑–∞–Ω–æ target_id –¥–ª—è undo\"}\n\n        undo_cmd = {\n            \"action\": \"undo_change\",\n            \"target_id\": target_id\n        }\n        return handle_command(undo_cmd)\n\n    elif name == \"scan_all_on_start\":\n        steps = [\n            {\"action\": \"scan_all_files\"},\n            {\"action\": \"analyze_all_code\"}\n        ]\n        for step in steps:\n            result = handle_command(step)\n            if result.get(\"status\") != \"success\":\n                return {\"status\": \"error\", \"message\": f\"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ {step['action']}: {result.get('message')}\"}\n        return {\"status\": \"success\", \"message\": \"‚úÖ –°–∫–∞–Ω—É–≤–∞–Ω–Ω—è —Ç–∞ –∞–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ\"}\n\n    return {\"status\": \"error\", \"message\": f\"‚ùå –ù–µ–≤—ñ–¥–æ–º–∞ –º–∞–∫—Ä–æ–∫–æ–º–∞–Ω–¥–∞: {name}\"}\n",
      ".\\main.py": "def run_bot():\n    print(\"–ë–æ—Ç –ø—Ä–∞—Ü—é—î. –ü–æ—á–∞—Ç–æ–∫ –ª–æ–≥—ñ–∫–∏...\")\n\nif __name__ == \"__main__\":\n    run_bot()\n\ndef print_hello():\n    print(\"Hello!\")\n\nimport logging\nlogging.basicConfig(level=logging.INFO)\nlogging.info('App started')",
      ".\\password_utils.py": "\ndef is_valid_password(password):\n    return len(password) >= 8\n\ndef is_password_valid(password):\n    return len(password) >= 8\n\ndef is_password_strong(password):\n    return len(password) >= 8\n",
      ".\\run_bot_logic.py": "import pandas as pd\nimport numpy as np\nfrom lux_structure import get_lux_structure_signal\nfrom tsi_divergence import find_tsi_divergence\nfrom confidence import calculate_confidence_score, confidence_score_update  # üß† –î–æ–¥–∞–Ω–æ –∞–¥–∞–ø—Ç–∏–≤–Ω—É –æ—Ü—ñ–Ω–∫—É\nfrom utils.log_trade_to_csv import log_trade  # üß† –ù–æ–≤–∏–π –ª–æ–≥–µ—Ä —Ç—Ä–µ–π–¥—É\n\n# üîÅ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö (–∑ Binance –∞–±–æ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª—É)\ndata_path = 'data/binance_data.csv'\ntry:\n    df = pd.read_csv(data_path)\nexcept:\n    data_path = 'data/historical_data.csv'\n    df = pd.read_csv(data_path)\n\nprint(f\"üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –¥–∞–Ω—ñ –∑: {data_path}\")\n\n# –û–±—Ä–æ–±–∫–∞ —á–∞—Å—É —Ç–∞ –∫–æ–ª–æ–Ω–æ–∫\ndf.index = pd.to_datetime(df['timestamp'] if 'timestamp' in df.columns else df.index)\n\n# üßÆ –û–±—á–∏—Å–ª–µ–Ω–Ω—è TSI\n# üîÅ –¢–ï–°–¢\n\ndef calculate_tsi(close, long=25, short=13):\n    diff = close.diff()\n    abs_diff = diff.abs()\n    double_smoothed_diff = diff.ewm(span=short).mean().ewm(span=long).mean()\n    double_smoothed_abs = abs_diff.ewm(span=short).mean().ewm(span=long).mean()\n    tsi = 100 * (double_smoothed_diff / double_smoothed_abs)\n    return tsi\n\ndf['tsi'] = calculate_tsi(df['close'])\n\nresults = []\nwindow = 50\n\ntrades_executed = []\nconfidence_memory = {}\n\nfor i in range(window, len(df)):\n    slice_df = df.iloc[:i].copy()\n    current_time = df.index[i]\n    current_price = df['close'].iloc[i]\n    volume_high = slice_df['volume'].iloc[-1] > slice_df['volume'].rolling(20).mean().iloc[-1]\n\n    tsi_signal = find_tsi_divergence(slice_df)\n    tsi_divergence = bool(tsi_signal['divergence'])\n\n    lux_result = get_lux_structure_signal(slice_df)\n\n    # üß† –ö–ª—é—á —Ç—Ä–µ–π–¥—É –¥–ª—è –ø–∞–º º—è—Ç—ñ\n    trade_key = f\"{tsi_signal['divergence']}_{lux_result['BOS']}_{lux_result['CHoCH']}_{volume_high}\"\n    confidence = confidence_score_update(trade_key, None, confidence_memory)\n\n    if (lux_result['BOS'] or lux_result['CHoCH']) and confidence >= 0.5:\n        decision = 'buy' if lux_result['direction'] == 'up' else 'sell'\n        print(f\"‚úÖ –í—Ö—ñ–¥ ({decision.upper()}) | –ß–∞—Å: {current_time} | –ù–∞–ø—Ä—è–º: {lux_result['direction']}\")\n\n        entry_price = current_price\n        tp = round(entry_price * (1.01 if decision == 'buy' else 0.99), 2)\n        sl = round(entry_price * (0.995 if decision == 'buy' else 1.005), 2)\n        rr_ratio = round(abs(tp - entry_price) / abs(entry_price - sl), 2)\n\n        log_trade({\n            'time': current_time.isoformat(),\n            'entry': decision,\n            'price': entry_price,\n            'tp': tp,\n            'sl': sl,\n            'rr': rr_ratio,\n            'tsi_divergence': tsi_signal['divergence'],\n            'lux_structure': 'BOS' if lux_result['BOS'] else 'CHoCH' if lux_result['CHoCH'] else None,\n            'direction': lux_result['direction'],\n            'volume_high': volume_high,\n            'confidence_score': confidence\n        })\n\n        pnl = tp - entry_price if decision == 'buy' else entry_price - tp\n        trades_executed.append({\n            'entry': decision,\n            'entry_price': entry_price,\n            'tp': tp,\n            'sl': sl,\n            'confidence': confidence,\n            'pnl': pnl\n        })\n\n        # üß† –ü—ñ–¥–≤–∏—â–µ–Ω–Ω—è –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ\n        confidence_score_update(trade_key, True, confidence_memory)\n    else:\n        decision = 'hold'\n        tp = sl = rr_ratio = None\n        print(f\"‚õî –ü—Ä–æ–ø—É—Å–∫ | {current_time}\")\n        with open('debug_log.txt', 'a', encoding='utf-8') as dbg:\n            dbg.write(f\"‚õî NO ENTRY | Time: {current_time}\\n\")\n            if not tsi_divergence:\n                dbg.write(\"–ü—Ä–∏—á–∏–Ω–∞: TSI-–¥–∏–≤–µ—Ä–≥–µ–Ω—Ü—ñ—è –≤—ñ–¥—Å—É—Ç–Ω—è\\n\")\n            if not volume_high:\n                dbg.write(\"–ü—Ä–∏—á–∏–Ω–∞: –Ω–µ–¥–æ—Å—Ç–∞—Ç–Ω—ñ–π –æ–± º—î–º\\n\")\n            if not (lux_result['BOS'] or lux_result['CHoCH']):\n                dbg.write(\"–ü—Ä–∏—á–∏–Ω–∞: LuxAlgo –Ω–µ –¥–∞–≤ BOS/CHoCH\\n\")\n            if confidence < 0.5:\n                dbg.write(f\"–ü—Ä–∏—á–∏–Ω–∞: –Ω–∏–∑—å–∫–∏–π confidence_score = {confidence}\\n\")\n            dbg.write(\"---\\n\")\n\n        # üß† –ó–Ω–∏–∂–µ–Ω–Ω—è –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ\n        confidence_score_update(trade_key, False, confidence_memory)\n\n    results.append({\n        'time': current_time.isoformat(),\n        'entry': decision,\n        'price': current_price,\n        'tp': tp,\n        'sl': sl,\n        'rr': rr_ratio,\n        'tsi_divergence': tsi_signal['divergence'],\n        'lux_structure': 'BOS' if lux_result['BOS'] else 'CHoCH' if lux_result['CHoCH'] else None,\n        'direction': lux_result['direction'],\n        'volume_high': volume_high,\n        'confidence_score': confidence\n    })\n\npd.DataFrame(results).to_csv('results.csv', index=False)\nprint(\"üìä –ë–µ–∫—Ç–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–æ ‚Üí results.csv\")\n\n# üìà performance.csv: –ø—ñ–¥—Å—É–º–∫–æ–≤–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\nif trades_executed:\n    df_perf = pd.DataFrame(trades_executed)\n    total_pnl = round(df_perf['pnl'].sum(), 2)\n    winrate = round((df_perf['pnl'] > 0).mean() * 100, 2)\n    avg_profit = round(df_perf[df_perf['pnl'] > 0]['pnl'].mean(), 2)\n    avg_loss = round(df_perf[df_perf['pnl'] <= 0]['pnl'].mean(), 2)\n\n    pd.DataFrame([{\n        'Total Trades': len(df_perf),\n        'Total PnL': total_pnl,\n        'Winrate (%)': winrate,\n        'Avg Profit': avg_profit,\n        'Avg Loss': avg_loss\n    }]).to_csv('performance.csv', index=False)\n\n    print(\"üìà performance.csv –∑–±–µ—Ä–µ–∂–µ–Ω–æ\")\nelse:\n    print(\"‚ö†Ô∏è –ñ–æ–¥–Ω–æ—ó —É–≥–æ–¥–∏ –Ω–µ –±—É–ª–æ –≤–∏–∫–æ–Ω–∞–Ω–æ ‚Üí performance.csv –Ω–µ —Å—Ç–≤–æ—Ä–µ–Ω–æ\")\n",
      ".\\run_macro_selftest.py": "import json\nimport os\nfrom gpt_agent_cache import handle_command\n\ndef list_macro_test_files(folder=\"macro_tests\"):\n    test_files = []\n    for root, _, files in os.walk(folder):\n        for file in files:\n            if file.endswith(\".json\"):\n                test_files.append(os.path.join(root, file))\n    return test_files\n\ndef run_all_macro_tests():\n    test_files = list_macro_test_files()\n    passed = 0\n    failed = 0\n\n    for path in test_files:\n        print(f\"\\nüîç –ó–∞–ø—É—Å–∫ –º–∞–∫—Ä–æ: {path}\")\n        try:\n            with open(path, \"r\", encoding=\"utf-8\") as f:\n                test_data = json.load(f)\n\n            steps = test_data.get(\"steps\", [])\n            cmd = {\"action\": \"macro\", \"steps\": steps}\n            print(\"üîÅ –ö—Ä–æ–∫–∏ –º–∞–∫—Ä–æ—Å–∞:\")\n            for step in steps:\n                print(step)\n\n            result = handle_command(cmd)\n            test_passed = result.get(\"status\") == \"success\"\n\n            # üîç –û—á—ñ–∫—É–≤–∞–Ω–µ: —Ñ–∞–π–ª\n            expected_file = test_data.get(\"expected_file\")\n            if expected_file and not os.path.exists(expected_file):\n                print(f\"‚ùå –û—á—ñ–∫—É–≤–∞–Ω–∏–π —Ñ–∞–π–ª '{expected_file}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ\")\n                test_passed = False\n\n            # üîç –û—á—ñ–∫—É–≤–∞–Ω–µ: –∫–æ–¥ —É —Ñ–∞–π–ª—ñ\n            expected_code = test_data.get(\"expected_code\")\n            if expected_file and expected_code:\n                try:\n                    with open(expected_file, \"r\", encoding=\"utf-8\") as f:\n                        content = f.read()\n                        if expected_code not in content:\n                            print(f\"‚ùå –ö–æ–¥ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ —É '{expected_file}'\")\n                            test_passed = False\n                except Exception as e:\n                    print(f\"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —á–∏—Ç–∞–Ω–Ω—ñ —Ñ–∞–π–ª—É '{expected_file}':\", e)\n                    test_passed = False\n\n            # ‚úÖ –ù–û–í–ê –ª–æ–≥—ñ–∫–∞ ‚Äî —Ç—ñ–ª—å–∫–∏ RAW output\n            expected_output = test_data.get(\"expected_output\")\n            if expected_output:\n                print(\"üßæ FULL RAW result:\", json.dumps(result, indent=2, ensure_ascii=False))\n                parsed_outputs = []\n                for r in result.get(\"results\", []):\n                    if isinstance(r, dict):\n                        inner_results = r.get(\"results\", [])\n                        for inner in inner_results:\n                            if isinstance(inner, dict) and inner.get(\"parsed_result\"):\n                                parsed_outputs.append(inner[\"parsed_result\"])\n\n                print(\"üì§ Parsed —Ä–µ–∑—É–ª—å—Ç–∞—Ç:\", parsed_outputs)\n                print(\"üì§ RAW —Ä–µ–∑—É–ª—å—Ç–∞—Ç:\", [repr(p) for p in parsed_outputs])\n                print(\"üîç –û—á—ñ–∫—É–≤–∞–Ω–æ:\", repr(expected_output))\n                if expected_output not in parsed_outputs:\n                    print(f\"‚ùå –û—á—ñ–∫—É–≤–∞–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: '{expected_output}'\")\n                    test_passed = False\n\n            if test_passed:\n                print(\"‚úÖ –¢–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω–æ\")\n                passed += 1\n            else:\n                print(\"‚ùå –¢–µ—Å—Ç –ù–ï –ø—Ä–æ–π–¥–µ–Ω–æ\")\n                failed += 1\n\n        except Exception as e:\n            print(\"üí• –í–∏–Ω—è—Ç–æ–∫ –ø—Ä–∏ –≤–∏–∫–æ–Ω–∞–Ω–Ω—ñ:\", e)\n            failed += 1\n\n    print(f\"\\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç–∏: {passed} –ø—Ä–æ–π—à–ª–æ, {failed} –∑ –ø–æ–º–∏–ª–∫–∞–º–∏\")\n\nif __name__ == \"__main__\":\n    run_all_macro_tests()\n",
      ".\\script.py": "from utils.greetings import greet_user\n\nname = \"Alice\"\ngreet_user(name)\n",
      ".\\test1.py": "# –¢–µ—Å—Ç–æ–≤–∏–π —Ñ–∞–π–ª –¥–ª—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó\n# [BEN] Validation logic inserted here",
      ".\\test2.py": "# –¢–µ—Å—Ç–æ–≤–∏–π —Ñ–∞–π–ª –¥–ª—è exceptions\n# [BEN] Exception handling logic inserted here",
      ".\\test3.py": "# –¢–µ—Å—Ç–æ–≤–∏–π —Ñ–∞–π–ª –¥–ª—è logging\n# [BEN] Logging logic inserted here",
      ".\\test_append.py": "# –ü–æ—Ä–æ–∂–Ω—ñ–π —Ñ–∞–π–ª –¥–ª—è —Ç–µ—Å—Ç—Édef test_func():\ndef test_func():\n    return True\n",
      ".\\test_ben_module.py": "# –¶–µ–π —Ñ–∞–π–ª —Å—Ç–≤–æ—Ä–µ–Ω–∏–π –¥–ª—è —Ç–µ—Å—Ç—É —Ñ—É–Ω–∫—Ü—ñ—ó update_code\n\n# [BEN] Validation logic inserted here\nprint('–í—Å—Ç–∞–≤–ª–µ–Ω–æ –Ω–∞ 3-–π —Ä—è–¥–æ–∫')\n# [BEN] Validation logic inserted here\n# [BEN] Validation logic inserted here\n# [BEN] Validation logic inserted here\n# [BEN] Validation logic inserted here\n# [BEN] Exception handling logic inserted here\n# [BEN] Validation logic inserted here",
      ".\\test_file_check.py": "# üÜï –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ —Å—Ç–≤–æ—Ä–µ–Ω–∏–π —Ñ–∞–π–ª\n",
      ".\\test_gpt.py": "# test_gpt.py\n\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\nimport os\n\n# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–º—ñ–Ω–Ω–∏—Ö —ñ–∑ .env\nload_dotenv(\"C:/Users/DC/env_files/env\")\n\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\nres = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": \"Say hello\"}]\n)\n\nprint(res.choices[0].message.content)\n",
      ".\\test_macro.py": "\ndef test_macro():\n    print('–ü—Ä–∏–≤—ñ—Ç —ñ–∑ –º–∞–∫—Ä–æ—Å—É!')\n",
      ".\\tsi_divergence.py": "import pandas as pd\nfrom scipy.signal import argrelextrema\nimport numpy as np\n\ndef find_tsi_divergence(df: pd.DataFrame, order: int = 5):\n    \"\"\"\n    –ó–Ω–∞—Ö–æ–¥–∏—Ç—å TSI-–¥–∏–≤–µ—Ä–≥–µ–Ω—Ü—ñ—ó –º—ñ–∂ —Ü—ñ–Ω–æ—é —Ç–∞ —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–º TSI\n    \"\"\"\n    if 'close' not in df.columns or 'tsi' not in df.columns:\n        return {'divergence': None}\n\n    df = df.copy()\n    df['price_max'] = df['close'].iloc[argrelextrema(df['close'].values, np.greater_equal, order=order)[0]]\n    df['price_min'] = df['close'].iloc[argrelextrema(df['close'].values, np.less_equal, order=order)[0]]\n    df['tsi_max'] = df['tsi'].iloc[argrelextrema(df['tsi'].values, np.greater_equal, order=order)[0]]\n    df['tsi_min'] = df['tsi'].iloc[argrelextrema(df['tsi'].values, np.less_equal, order=order)[0]]\n\n    # Bearish divergence: higher high in price, lower high in TSI\n    price_highs = df.dropna(subset=['price_max'])[-2:]\n    tsi_highs = df.dropna(subset=['tsi_max'])[-2:]\n    if len(price_highs) == 2 and len(tsi_highs) == 2:\n        if price_highs['price_max'].iloc[1] > price_highs['price_max'].iloc[0] and \\\n           tsi_highs['tsi_max'].iloc[1] < tsi_highs['tsi_max'].iloc[0]:\n            return {\n                'divergence': 'bearish',\n                'price_point_1': price_highs['price_max'].iloc[0],\n                'price_point_2': price_highs['price_max'].iloc[1],\n                'tsi_point_1': tsi_highs['tsi_max'].iloc[0],\n                'tsi_point_2': tsi_highs['tsi_max'].iloc[1]\n            }\n\n    # Bullish divergence: lower low in price, higher low in TSI\n    price_lows = df.dropna(subset=['price_min'])[-2:]\n    tsi_lows = df.dropna(subset=['tsi_min'])[-2:]\n    if len(price_lows) == 2 and len(tsi_lows) == 2:\n        if price_lows['price_min'].iloc[1] < price_lows['price_min'].iloc[0] and \\\n           tsi_lows['tsi_min'].iloc[1] > tsi_lows['tsi_min'].iloc[0]:\n            return {\n                'divergence': 'bullish',\n                'price_point_1': price_lows['price_min'].iloc[0],\n                'price_point_2': price_lows['price_min'].iloc[1],\n                'tsi_point_1': tsi_lows['tsi_min'].iloc[0],\n                'tsi_point_2': tsi_lows['tsi_min'].iloc[1]\n            }\n\n    return {'divergence': None}",
      ".\\–Ω–µ—ñ—Å–Ω—É—é—á–∏–π_—Ñ–∞–π–ª.py": "print('Hello')",
      ".\\ben_gui_desktop\\ben_gui.py": "import os\nimport sys\nimport os\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nimport json\nimport tkinter as tk\nfrom tkinter import ttk, scrolledtext\n\n\nclass BenGUI:\n    def __init__(self, root):\n        self.root = root\n        root.title(\"Ben Assistant GUI\")\n        root.geometry(\"700x500\")\n\n        # –í–≤—ñ–¥\n        self.action_var = tk.StringVar()\n        self.filename_var = tk.StringVar()\n        self.content_var = tk.StringVar()\n\n        ttk.Label(root, text=\"Action:\").pack()\n        ttk.Entry(root, textvariable=self.action_var).pack(fill=tk.X)\n\n        ttk.Label(root, text=\"Filename (optional):\").pack()\n        ttk.Entry(root, textvariable=self.filename_var).pack(fill=tk.X)\n\n        ttk.Label(root, text=\"Content (optional):\").pack()\n        ttk.Entry(root, textvariable=self.content_var).pack(fill=tk.X)\n\n        ttk.Button(root, text=\"üì© –ù–∞–¥—ñ—Å–ª–∞—Ç–∏ –∫–æ–º–∞–Ω–¥—É\", command=self.send_command).pack(pady=10)\n\n        ttk.Label(root, text=\"–í—ñ–¥–ø–æ–≤—ñ–¥—å:\").pack()\n        self.response_area = scrolledtext.ScrolledText(root, wrap=tk.WORD, height=15)\n        self.response_area.pack(fill=tk.BOTH, expand=True)\n\n    def send_command(self):\n        command = {\n            \"action\": self.action_var.get(),\n            \"filename\": self.filename_var.get(),\n            \"content\": self.content_var.get()\n        }\n        command = {k: v for k, v in command.items() if v.strip()}\n        with open(request_file, \"w\", encoding=\"utf-8\") as f:\n            json.dump([command], f, indent=2)\n        self.response_area.insert(tk.END, f\"üì§ –í—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–æ: {json.dumps(command)}\\n\")\n        self.response_area.see(tk.END)\n\n        self.root.after(1000, self.load_response)\n\n    def load_response(self):\n        if os.path.exists(response_file):\n            with open(response_file, \"r\", encoding=\"utf-8\") as f:\n                try:\n                    data = json.load(f)\n                    self.response_area.insert(tk.END, f\"‚úÖ –í—ñ–¥–ø–æ–≤—ñ–¥—å: {json.dumps(data, indent=2, ensure_ascii=False)}\\n\")\n                    self.response_area.see(tk.END)\n                except Exception as e:\n                    self.response_area.insert(tk.END, f\"‚ùå Error reading response: {e}\\n\")\n\nif __name__ == \"__main__\":\n    root = tk.Tk()\n    app = BenGUI(root)\n    root.mainloop()",
      ".\\ben_gui_desktop\\main_gui.py": "def enable_ctrl_shortcuts(widget):\n    widget.bind(\"<Control-c>\", lambda e: widget.event_generate(\"<<Copy>>\"))\n    widget.bind(\"<Control-v>\", lambda e: widget.event_generate(\"<<Paste>>\"))\n    widget.bind(\"<Control-x>\", lambda e: widget.event_generate(\"<<Cut>>\"))\n\ndef apply_shortcuts_recursively(widget):\n    if isinstance(widget, (tk.Entry, tk.Text, scrolledtext.ScrolledText)):\n        enable_ctrl_shortcuts(widget)\n    if hasattr(widget, \"winfo_children\"):\n        for child in widget.winfo_children():\n            apply_shortcuts_recursively(child)\n\n# –í–∫–ª—é—á–∏—Ç–∏ –≥–∞—Ä—è—á—ñ –∫–ª–∞–≤—ñ—à—ñ –¥–ª—è –≤—Å—ñ—Ö –≤—ñ–¥–∂–µ—Ç—ñ–≤\napply_shortcuts_recursively(scrollable_frame)\n",
      ".\\ben_gui_desktop\\template_manager.py": "from jinja2 import Environment, FileSystemLoader\nimport os\n\nTEMPLATE_DIR = os.path.join(os.path.dirname(__file__), \"templates\")\nenv = Environment(loader=FileSystemLoader(TEMPLATE_DIR))\n\ndef render_template(template_name, context):\n    try:\n        template = env.get_template(template_name)\n        return template.render(context)\n    except Exception as e:\n        return f\"‚ùå Template rendering error: {e}\"",
      ".\\ben_gui_desktop\\widgets\\action_selector.py": "import tkinter as tk\nfrom tkinter import ttk\n\nclass ActionSelector(ttk.Frame):\n    def __init__(self, parent, on_action_change):\n        super().__init__(parent)\n        self.on_action_change = on_action_change\n\n        ttk.Label(self, text=\"–û–±–µ—Ä—ñ—Ç—å –¥—ñ—é:\").pack(anchor=\"w\")\n\n        self.action_var = tk.StringVar()\n        self.combo = ttk.Combobox(self, textvariable=self.action_var)\n        self.combo['values'] = [\n            \"create_file\", \"append_file\", \"update_code\", \"update_code_bulk\",\n            \"replace_in_file\", \"delete_file\", \"rename_file\", \"macro\",\n            \"list_history\", \"view_sql_history\", \"run_python\"\n        ]\n        self.combo.bind(\"<<ComboboxSelected>>\", self.action_selected)\n        self.combo.pack(fill=tk.X)\n\n    def action_selected(self, event):\n        selected = self.action_var.get()\n        self.on_action_change(selected)\n\n    def get_selected_action(self):\n        return self.action_var.get()",
      ".\\ben_gui_desktop\\widgets\\git_log_viewer.py": "import tkinter as tk\nfrom tkinter import ttk, scrolledtext\nimport subprocess\n\nclass GitLogViewer(ttk.Frame):\n    def __init__(self, parent):\n        super().__init__(parent)\n        ttk.Label(self, text=\"üïò Git Log\").pack(anchor=\"w\")\n        self.text_area = scrolledtext.ScrolledText(self, height=10, wrap=tk.WORD)\n        self.text_area.pack(fill=tk.BOTH, expand=True)\n\n        refresh_btn = ttk.Button(self, text=\"üîÑ –û–Ω–æ–≤–∏—Ç–∏ Git Log\", command=self.load_git_log)\n        refresh_btn.pack(pady=5)\n\n    def load_git_log(self):\n        try:\n            output = subprocess.check_output([\"git\", \"log\", \"-n\", \"10\", \"--oneline\"], stderr=subprocess.STDOUT, text=True)\n            self.text_area.delete(\"1.0\", tk.END)\n            self.text_area.insert(tk.END, output)\n            self.text_area.see(tk.END)\n        except subprocess.CalledProcessError as e:\n            self.text_area.insert(tk.END, f\"‚ùå Git Error: {e.output}\\n\")",
      ".\\ben_gui_desktop\\widgets\\history_viewer.py": "import tkinter as tk\nfrom tkinter import ttk, scrolledtext\n\nclass HistoryViewer(ttk.Frame):\n    def __init__(self, parent, label_text):\n        super().__init__(parent)\n        ttk.Label(self, text=label_text).pack(anchor=\"w\")\n        self.text_area = scrolledtext.ScrolledText(self, height=10, wrap=tk.WORD)\n        self.text_area.pack(fill=tk.BOTH, expand=True)\n\n    def update_history(self, data):\n        self.text_area.delete(\"1.0\", tk.END)\n        for item in data:\n            self.text_area.insert(tk.END, f\"{item}\\n\")\n        self.text_area.see(tk.END)",
      ".\\ben_gui_desktop\\widgets\\macro_builder.py": "import threading\nimport tkinter as tk\nfrom tkinter import ttk, messagebox, simpledialog\nimport json\nimport time\nimport os\nfrom datetime import datetime, timezone\ntimestamp = datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S\")\n# üí° GPT: DO NOT DELETE ‚Äî used in generate_macro_from_prompt()\nimport requests\nfrom logic.gpt_macro_engine import GPTMacroEngine\nfrom dotenv import load_dotenv\nload_dotenv()\n\nUSE_OPENAI_API = True  # üîÅ –ü–µ—Ä–µ–º–∏–∫–∞—á –º—ñ–∂ OpenAI API —Ç–∞ –ª–æ–∫–∞–ª—å–Ω–∏–º GPT-—Å–µ—Ä–≤–µ—Ä–æ–º\n\nclass DragDropListbox(tk.Listbox):\n    def __init__(self, master, **kw):\n        kw['selectmode'] = tk.SINGLE\n        super().__init__(master, kw)\n        self.bind('<Button-1>', self.set_current)\n        self.bind('<B1-Motion>', self.shift_selection)\n        self.curIndex = None\n\n    def set_current(self, event):\n        self.curIndex = self.nearest(event.y)\n\n    def shift_selection(self, event):\n        i = self.nearest(event.y)\n        if i < self.curIndex:\n            x = self.get(i)\n            self.delete(i)\n            self.insert(i + 1, x)\n            self.curIndex = i\n        elif i > self.curIndex:\n            x = self.get(i)\n            self.delete(i)\n            self.insert(i - 1, x)\n            self.curIndex = i\n\nclass MacroBuilder(ttk.Frame):\n    def __init__(self, parent, response_area):\n        super().__init__(parent)\n        self.response_area = response_area\n        self.steps = []\n        self.known_files = set()\n\n        ttk.Label(self, text=\"üß± Macro Builder\", font=(\"Helvetica\", 14, \"bold\")).pack(anchor=\"w\", pady=(0, 5))\n\n        self.listbox = DragDropListbox(self)\n        self.listbox.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n\n        form_frame = ttk.Frame(self)\n        form_frame.pack(fill=tk.X, padx=5)\n\n        ttk.Label(form_frame, text=\"Action:\").pack(side=tk.LEFT)\n        self.action_var = tk.StringVar()\n        self.action_entry = ttk.Entry(form_frame, textvariable=self.action_var)\n        self.action_entry.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(5, 5))\n        ttk.Button(form_frame, text=\"‚ûï Add\", command=self.add_step).pack(side=tk.LEFT)\n        ttk.Button(form_frame, text=\"üóë Remove\", command=self.remove_selected).pack(side=tk.LEFT, padx=(5, 0))\n\n        self.fields_frame = ttk.Frame(self)\n        self.fields_frame.pack(fill=tk.X, padx=5, pady=5)\n        self.field_vars = {\n            \"action\": tk.StringVar(),\n            \"filename\": tk.StringVar(),\n            \"pattern\": tk.StringVar(),\n            \"replacement\": tk.StringVar(),\n            \"content\": tk.StringVar(),\n            \"delay\": tk.StringVar(),\n            \"if\": tk.StringVar()\n        }\n\n        for label, var in self.field_vars.items():\n            row = ttk.Frame(self.fields_frame)\n            row.pack(fill=tk.X, pady=2)\n            ttk.Label(row, text=label.capitalize() + \":\").pack(side=tk.LEFT, padx=(0, 5))\n            entry = ttk.Entry(row, textvariable=var)\n            entry.pack(side=tk.LEFT, fill=tk.X, expand=True)\n\n        ttk.Button(self, text=\"‚ûï Add Full Step\", command=self.add_full_step).pack(pady=5)\n        ttk.Button(self, text=\"üß™ Preview & Validate\", command=self.preview_macro).pack(pady=5)\n        ttk.Button(self, text=\"üìÇ Save Macro\", command=self.save_macro).pack(pady=5)\n        ttk.Button(self, text=\"üìÇ Show Known Files\", command=self.show_known_files).pack(pady=5)\n        ttk.Button(self, text=\"ü§ñ GPT Macro Generator\", command=self.generate_macro_from_prompt).pack(pady=5)\n\n    def add_step(self):\n        action = self.action_var.get().strip()\n        if action:\n            self.steps.append({\"action\": action})\n            self.listbox.insert(tk.END, action)\n            self.action_var.set(\"\")\n\n    def add_full_step(self):\n        step = {}\n        for key, var in self.field_vars.items():\n            value = var.get().strip()\n            if value:\n                if key == \"delay\":\n                    try:\n                        step[key] = float(value)\n                    except ValueError:\n                        self.response_area.insert(tk.END, f\"‚ö†Ô∏è –ù–µ–≤—ñ—Ä–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è delay: {value}\\n\")\n                        return\n                else:\n                    step[key] = value\n        if step:\n            step[\"description\"] = f\"–î—ñ—è: {step.get('action', '')} –Ω–∞ {step.get('filename', '')}\"\n            step[\"timestamp\"] = datetime.utcnow().isoformat()\n            step[\"type\"] = \"custom\"\n            \n            self.steps.append(step)\n            self.listbox.insert(tk.END, step.get(\"action\", \"[No action]\"))\n            for var in self.field_vars.values():\n                var.set(\"\")\n    def remove_selected(self):\n        selected = self.listbox.curselection()\n        if not selected:\n            return\n        index = selected[0]\n        self.listbox.delete(index)\n        del self.steps[index]\n\n    def preview_macro(self):\n        try:\n            msg = f\"üß™ –ü—Ä–µ–≤ º—é –º–∞–∫—Ä–æ—Å—É: {len(self.steps)} –∫—Ä–æ–∫—ñ–≤\\n\"\n            for i, step in enumerate(self.steps, 1):\n                msg += f\"  {i}. {step.get('action', '...')}\"\n                if \"delay\" in step:\n                    msg += f\" (‚è≥ delay: {step['delay']}s)\"\n                if \"if\" in step:\n                    msg += f\" [if: {step['if']}]\"\n                msg += \"\\n\"\n            self.response_area.insert(tk.END, msg)\n        except Exception as e:\n            self.response_area.insert(tk.END, f\"‚ùå –ü–æ–º–∏–ª–∫–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó –º–∞–∫—Ä–æ—Å—É: {e}\\n\")\n        self.response_area.see(tk.END)\n\n    def save_macro(self):\n        if not self.steps:\n            messagebox.showerror(\"Error\", \"No steps to save\")\n            return\n        macro = {\n            \"action\": \"macro\",\n            \"steps\": self.steps\n        }\n        try:\n            with open(\"macro_command.json\", \"w\", encoding=\"utf-8\") as f:\n                json.dump(macro, f, indent=2)\n            messagebox.showinfo(\"Saved\", \"‚úÖ Macro saved to macro_command.json\")\n        except Exception as e:\n            messagebox.showerror(\"Error\", f\"‚ùå Failed to save macro: {e}\")\n\n    def show_known_files(self):\n        try:\n            file_list = sorted(self.known_files)\n            msg = \"üìÇ –í—ñ–¥–æ–º—ñ —Ñ–∞–π–ª–∏:\\n\" + \"\\n\".join(file_list)\n            self.response_area.insert(tk.END, msg + \"\\n\")\n            self.response_area.see(tk.END)\n        except Exception as e:\n            self.response_area.insert(tk.END, f\"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø–µ—Ä–µ–≥–ª—è–¥—É —Ñ–∞–π–ª—ñ–≤: {e}\\n\")\n\n    def save_known_files(self):\n        try:\n            with open(\".ben_memory.json\", \"r\", encoding=\"utf-8\") as f:\n                memory = json.load(f)\n        except:\n            memory = {}\n        memory[\"known_files\"] = sorted(self.known_files)\n        with open(\".ben_memory.json\", \"w\", encoding=\"utf-8\") as f:\n            json.dump(memory, f, indent=2)\n\n    def log_debug(self, message):\n        from datetime import datetime, timezone\n        with open(\"debug.log\", \"a\", encoding=\"utf-8\") as log:\n            timestamp = datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S\")\n            log.write(f\"[{timestamp}] {message}\\n\")\n\n    def generate_macro_from_prompt(self):\n        prompt = simpledialog.askstring(\"GPT Macro\", \"–í–≤–µ–¥—ñ—Ç—å –∑–∞–ø–∏—Ç –¥–ª—è GPT:\")\n        if not prompt:\n            return\n        self.response_area.insert(tk.END, \"‚è≥ GPT –¥—É–º–∞—î...\\n\")\n        threading.Thread(target=self._run_gpt_macro, args=(prompt,), daemon=True).start()\n\n    def _run_gpt_macro(self, prompt):\n        try:\n            engine = GPTMacroEngine()\n            steps = engine.generate_macro(prompt)\n            self.steps.extend(steps)\n            self.response_area.insert(tk.END, f\"ü§ñ –î–æ–¥–∞–Ω–æ {len(steps)} –∫—Ä–æ–∫—ñ–≤ –≤—ñ–¥ GPT\\n\")\n            self.preview_macro()\n        except Exception as e:\n            self.response_area.insert(tk.END, f\"‚ùå GPT –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è –ø–æ–º–∏–ª–∫–∞: {e}\\n\")\n        self.response_area.see(tk.END)\n\n    def run_macro(self):\n        try:\n            with open(\"macro_command.json\", \"r\", encoding=\"utf-8\") as f:\n                macro = json.load(f)\n                macro_name = macro.get(\"name\", \"–ë–µ–∑ –Ω–∞–∑–≤–∏\")\n                steps = macro.get(\"steps\", [])\n                self.response_area.insert(tk.END, f\"üß† –ó–∞–ø—É—Å–∫ –º–∞–∫—Ä–æ—Å—É '{macro_name}' ‚Äî {len(steps)} –∫—Ä–æ–∫—ñ–≤\\n\")\n                self.response_area.see(tk.END)\n                self.log_debug(f\"‚ñ∂Ô∏è –°—Ç–∞—Ä—Ç –º–∞–∫—Ä–æ—Å—É '{macro_name}' –∑ {len(steps)} –∫—Ä–æ–∫—ñ–≤\")\n\n            for step in steps:\n                try:\n                    condition = step.get(\"if\")\n                    if condition:\n                        if not eval(condition, {}, {\"previous_status\": \"success\"}):\n                            msg = f\"‚è≠ –ü—Ä–æ–ø—É—â–µ–Ω–æ —á–µ—Ä–µ–∑ if: {condition}\"\n                            self.response_area.insert(tk.END, msg + \"\\n\")\n                            self.response_area.see(tk.END)\n                            self.log_debug(msg)\n                            continue\n\n                    delay = step.get(\"delay\", 0)\n                    if delay > 0:\n                        msg = f\"‚è≥ –ó–∞—Ç—Ä–∏–º–∫–∞ {delay} —Å–µ–∫ –ø–µ—Ä–µ–¥ –¥—ñ—î—é: {step.get('action', '...')}\"\n                        self.response_area.insert(tk.END, msg + \"\\n\")\n                        self.response_area.see(tk.END)\n                        self.log_debug(msg)\n                        time.sleep(delay)\n\n                    if step.get(\"action\") == \"rollback\":\n                        filename = step.get(\"filename\")\n                        if filename:\n                            backup_path = os.path.join(\"backups\", filename)\n                            if not os.path.exists(backup_path):\n                                msg = f\"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ rollback ‚Äî –Ω–µ–º–∞—î —Ä–µ–∑–µ—Ä–≤–Ω–æ—ó –∫–æ–ø—ñ—ó –¥–ª—è '{filename}'\"\n                                self.response_area.insert(tk.END, msg + \"\\n\")\n                                self.response_area.see(tk.END)\n                                self.log_debug(msg)\n                                continue\n\n                    if not step.get(\"action\"):\n                        msg = \"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ –∫—Ä–æ–∫ ‚Äî –≤—ñ–¥—Å—É—Ç–Ω—ñ–π 'action'\"\n                        self.response_area.insert(tk.END, msg + \"\\n\")\n                        self.log_debug(msg)\n                        continue\n\n                    if step.get(\"action\") in [\"update_code\", \"insert\"]:\n                        if not step.get(\"content\"):\n                            msg = \"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ update ‚Äî –≤—ñ–¥—Å—É—Ç–Ω—ñ–π 'content'\"\n                            self.response_area.insert(tk.END, msg + \"\\n\")\n                            self.log_debug(msg)\n                            continue\n\n                    if step.get(\"filename\"):\n                        path = step.get(\"filename\")\n                        self.known_files.add(path)\n                        if not os.path.exists(path):\n                            msg = f\"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ ‚Äî —Ñ–∞–π–ª '{path}' –Ω–µ —ñ—Å–Ω—É—î\"\n                            self.response_area.insert(tk.END, msg + \"\\n\")\n                            self.log_debug(msg)\n                            continue\n\n                    with open(\"request.json\", \"w\", encoding=\"utf-8\") as f:\n                        json.dump([step], f, indent=2)\n                    msg = f\"üì§ –ö—Ä–æ–∫: {step.get('action', '...')} –Ω–∞–¥—ñ—Å–ª–∞–Ω–æ\"\n                    self.response_area.insert(tk.END, msg + \"\\n\")\n                    self.response_area.see(tk.END)\n                    self.log_debug(msg)\n                    time.sleep(1.5)\n                except Exception as step_err:\n                    self.log_debug(f\"‚ùå –ü–æ–º–∏–ª–∫–∞ –∫—Ä–æ–∫—É: {step_err}\")\n                    self.response_area.insert(tk.END, f\"‚ùå –ü–æ–º–∏–ª–∫–∞ –∫—Ä–æ–∫—É: {step_err}\\n\")\n\n            self.save_known_files()\n\n        except Exception as e:\n            self.log_debug(f\"‚ùå –ü–æ–º–∏–ª–∫–∞ –º–∞–∫—Ä–æ—Å—É: {e}\")\n            messagebox.showerror(\"–ü–æ–º–∏–ª–∫–∞\", f\"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –≤–∏–∫–æ–Ω–∞—Ç–∏ –º–∞–∫—Ä–æ—Å: {e}\")\n",
      ".\\ben_gui_desktop\\widgets\\parameter_form.py": "import tkinter as tk\nfrom tkinter import ttk\n\nclass ParameterForm(ttk.Frame):\n    def __init__(self, parent):\n        super().__init__(parent)\n        self.entries = {}\n        self.fields = [\n            \"filename\", \"content\", \"pattern\", \"replacement\",\n            \"update_type\", \"insert_at_line\", \"rollback_on_fail\"\n        ]\n\n        for field in self.fields:\n            row = ttk.Frame(self)\n            row.pack(fill=tk.X, pady=2)\n\n            ttk.Label(row, text=field + \":\", width=18).pack(side=tk.LEFT)\n            entry = ttk.Entry(row)\n            entry.pack(fill=tk.X, expand=True)\n            self.entries[field] = entry\n\n    def get_command_fields(self):\n        result = {}\n        for field, entry in self.entries.items():\n            value = entry.get().strip()\n            if value:\n                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –ø–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ rollback_on_fail –≤ bool\n                if field == \"rollback_on_fail\":\n                    result[field] = value.lower() in [\"true\", \"1\", \"yes\"]\n                elif field == \"insert_at_line\":\n                    try:\n                        result[field] = int(value)\n                    except ValueError:\n                        pass  # –Ü–≥–Ω–æ—Ä—É—î–º–æ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–µ —á–∏—Å–ª–æ\n                else:\n                    result[field] = value\n        return result\n\n    def clear(self):\n        for entry in self.entries.values():\n            entry.delete(0, tk.END)",
      ".\\ben_gui_desktop\\widgets\\template_editor.py": "import tkinter as tk\nfrom tkinter import ttk, messagebox, scrolledtext\nimport os\n\nclass TemplateEditor(ttk.Frame):\n    def __init__(self, parent):\n        super().__init__(parent)\n\n        self.template_dir = os.path.join(os.path.dirname(__file__), '..', 'templates')\n        self.current_template = None\n        self.unsaved_changes = False\n\n        ttk.Label(self, text=\"üìÅ Template Editor\", font=(\"Helvetica\", 14, \"bold\")).pack(anchor=\"w\", pady=(0, 5))\n\n        top_frame = ttk.Frame(self)\n        top_frame.pack(fill=tk.X)\n\n        self.template_selector = ttk.Combobox(top_frame, state=\"readonly\")\n        self.template_selector.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(0, 5))\n        self.template_selector.bind(\"<<ComboboxSelected>>\", self.load_selected_template)\n\n        ttk.Button(top_frame, text=\"üÜï New Template\", command=self.create_new_template).pack(side=tk.LEFT, padx=(5, 0))\n\n        ttk.Button(top_frame, text=\"üîÑ Refresh List\", command=self.refresh_list).pack(side=tk.LEFT)\n\n        self.editor = scrolledtext.ScrolledText(self, wrap=tk.WORD, height=12)\n        self.editor.pack(fill=tk.BOTH, expand=True, pady=5)\n        self.editor.bind(\"<Key>\", lambda e: self.set_unsaved())\n\n        save_btn = ttk.Button(self, text=\"üíæ Save\", command=self.save_template)\n        save_btn.pack(pady=5)\n\n        self.refresh_list()\n        parent.protocol(\"WM_DELETE_WINDOW\", self.on_close)\n\n    def refresh_list(self):\n        try:\n            files = [f for f in os.listdir(self.template_dir) if f.endswith(\".j2\")]\n            self.template_selector[\"values\"] = files\n            if files:\n                self.template_selector.current(0)\n                self.load_selected_template()\n        except Exception as e:\n            messagebox.showerror(\"Error\", f\"‚ùå Failed to load templates: {e}\")\n\n    def load_selected_template(self, event=None):\n        if self.unsaved_changes:\n            if not messagebox.askyesno(\"Unsaved\", \"‚ö†Ô∏è Unsaved changes. Discard?\"):\n                return\n        name = self.template_selector.get()\n        path = os.path.join(self.template_dir, name)\n        try:\n            with open(path, \"r\", encoding=\"utf-8\") as f:\n                content = f.read()\n            self.editor.delete(\"1.0\", tk.END)\n            self.editor.insert(tk.END, content)\n            self.current_template = name\n            self.unsaved_changes = False\n        except Exception as e:\n            messagebox.showerror(\"Error\", f\"‚ùå Failed to load: {e}\")\n\n    def save_template(self):\n        if not self.current_template:\n            return\n        try:\n            content = self.editor.get(\"1.0\", tk.END)\n            path = os.path.join(self.template_dir, self.current_template)\n            with open(path, \"w\", encoding=\"utf-8\") as f:\n                f.write(content)\n            self.unsaved_changes = False\n            messagebox.showinfo(\"Saved\", f\"‚úÖ Saved {self.current_template}\")\n        except Exception as e:\n            messagebox.showerror(\"Error\", f\"‚ùå Failed to save: {e}\")\n\n    def set_unsaved(self):\n        self.unsaved_changes = True\n\n    def on_close(self):\n        if self.unsaved_changes:\n            if not messagebox.askyesno(\"Exit\", \"‚ö†Ô∏è Unsaved changes. Exit anyway?\"):\n                return\n        self.master.destroy()",
      ".\\ben_gui_desktop\\widgets\\user_profile_panel.py": "import tkinter as tk\nfrom tkinter import ttk\n\nclass UserProfilePanel(ttk.Frame):\n    def __init__(self, parent):\n        super().__init__(parent)\n\n        style = ttk.Style()\n        style.configure(\"TLabel\", font=(\"Helvetica\", 11))\n        style.configure(\"TCombobox\", padding=6)\n        style.configure(\"TCheckbutton\", padding=6)\n\n        ttk.Label(self, text=\"üë§ –ü—Ä–æ—Ñ—ñ–ª—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞\", font=(\"Helvetica\", 14, \"bold\")).pack(anchor=\"w\", pady=(0, 10))\n\n        # –¢–µ–º–∞ —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É\n        ttk.Label(self, text=\"üé® –¢–µ–º–∞ —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É:\").pack(anchor=\"w\")\n        self.theme_var = tk.StringVar(value=\"light\")\n        ttk.Combobox(self, textvariable=self.theme_var, values=[\"light\", \"dark\", \"system\"]).pack(fill=tk.X, pady=5)\n# –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è —Ç–µ–º–∏ –ø—Ä–∏ –∑–º—ñ–Ω—ñ\n        def apply_theme(event=None):\n            selected = self.theme_var.get()\n            if selected == \"dark\":\n                parent.tk_setPalette(background=\"#1e1e1e\", foreground=\"#ffffff\")\n            elif selected == \"light\":\n                parent.tk_setPalette(background=\"#ffffff\", foreground=\"#000000\")\n            else:\n                parent.tk_setPalette(background=None, foreground=None)\n\n        self.theme_var.trace_add(\"write\", lambda *args: apply_theme())\n        apply_theme()\n\n        # –†–æ–ª—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞\n        ttk.Label(self, text=\"üîê –†–æ–ª—å:\").pack(anchor=\"w\")\n        self.role_var = tk.StringVar(value=\"developer\")\n        ttk.Combobox(self, textvariable=self.role_var, values=[\"developer\", \"admin\", \"viewer\"]).pack(fill=tk.X, pady=5)\n\n        # –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –∂—É—Ä–Ω–∞–ª—É\n        ttk.Label(self, text=\"üîç –§—ñ–ª—å—Ç—Ä –ø–æ–¥—ñ–π:\").pack(anchor=\"w\")\n        self.filter_var = tk.StringVar(value=\"all\")\n        ttk.Combobox(self, textvariable=self.filter_var, values=[\"all\", \"commands\", \"errors\", \"system\"]).pack(fill=tk.X, pady=5)\n\n        # –ü—Ä–æ–≥–∞–ª–∏–Ω–∏ –¥–ª—è –µ—Å—Ç–µ—Ç–∏–∫–∏\n        ttk.Label(self, text=\"\").pack(pady=10)\n\n    def get_profile_settings(self):\n        return {\n            \"theme\": self.theme_var.get(),\n            \"role\": self.role_var.get(),\n            \"filter\": self.filter_var.get()\n        }",
      ".\\ben_gui_desktop\\widgets\\__init__.py": "# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –º–æ–¥—É–ª—è widgets\n",
      ".\\handlers\\auto_fix.py": "import os\n\ndef auto_fix_parameters(cmd):\n    \"\"\"\n    –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤–∏–ø—Ä–∞–≤–ª—è—î –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –≤ –∫–æ–º–∞–Ω–¥—ñ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, 'unknown', None).\n    –ü–æ–≤–µ—Ä—Ç–∞—î –æ–Ω–æ–≤–ª–µ–Ω—É –∫–æ–º–∞–Ω–¥—É.\n    \"\"\"\n    if not isinstance(cmd, dict):\n        return cmd\n\n    fixed = dict(cmd)  # –∫–æ–ø—ñ—è\n    parameters = fixed.get(\"parameters\", {})\n\n    # –í–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è file_path\n    file_path = parameters.get(\"file_path\") or fixed.get(\"file_path\") or fixed.get(\"filename\")\n    if not file_path or file_path == \"unknown\":\n        parameters[\"file_path\"] = \"recent_actions.log\"\n\n    # –í–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è prompt\n    prompt = parameters.get(\"prompt\") or parameters.get(\"question\") or fixed.get(\"prompt\")\n    if (not prompt or prompt == \"unknown\") and fixed.get(\"action\") == \"ask_gpt\":\n        parameters[\"prompt\"] = \"–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π prompt: –ø–æ—è—Å–Ω–∏ –ª–æ–≥—ñ–∫—É –∫–æ–¥—É –∞–±–æ –≤–∏–ø—Ä–∞–≤ –ø–æ–º–∏–ª–∫—É.\"\n\n    # –í–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è –∫–æ–º–∞–Ω–¥ –¥–ª—è run_shell\n    if fixed.get(\"action\") == \"run_shell\":\n        command = fixed.get(\"command\") or parameters.get(\"command\")\n        if not command or command == \"unknown\":\n            parameters[\"command\"] = \"echo –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∞ –∫–æ–º–∞–Ω–¥–∞: –Ω—ñ—á–æ–≥–æ –Ω–µ –±—É–ª–æ –≤–∫–∞–∑–∞–Ω–æ.\"\n\n    # –í–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è –≤–º—ñ—Å—Ç—É create_file\n    if fixed.get(\"action\") == \"create_file\":\n        content = parameters.get(\"content\")\n        if not content or content == \"unknown\":\n            parameters[\"content\"] = \"# –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π —à–∞–±–ª–æ–Ω —Ñ–∞–π–ª—É\\nprint('Hello, world!')\"\n\n    fixed[\"parameters\"] = parameters\n    return fixed\n",
      ".\\handlers\\auto_guess.py": "import os\nimport re\n\ndef auto_guess_missing_parameters(cmd):\n    parameters = cmd.get(\"parameters\", {})\n\n    for key in [\"file_path\", \"name\", \"code\"]:\n        val = cmd.get(key) or parameters.get(key)\n        if isinstance(val, str) and any(bad in val.lower() for bad in [\"–≤–∫–∞–∂—ñ—Ç—å\", \"path/to\", \"—ñ–º'—è\", \"–Ω–∞–∑–≤—É\"]):\n            if key == \"file_path\":\n                for fname in os.listdir():\n                    if fname.endswith(\".py\") and fname not in [\"gpt_agent_cache.py\", \"auto_feedback.py\"]:\n                        parameters[\"file_path\"] = fname\n                        break\n                else:\n                    parameters[\"file_path\"] = \"example.py\"\n\n            elif key == \"name\":\n                code_text = parameters.get(\"code\", \"\")\n                match = re.search(r\"def\\s+(\\w+)\", code_text)\n                if match:\n                    parameters[\"name\"] = match.group(1)\n\n            elif key == \"code\":\n                continue\n\n    # ‚õëÔ∏è –°—Ç–≤–æ—Ä–∏—Ç–∏ —Ñ–∞–π–ª, —è–∫—â–æ –≤—ñ–Ω –Ω–µ —ñ—Å–Ω—É—î\n    if \"file_path\" in parameters:\n        fp = parameters[\"file_path\"]\n        if not os.path.exists(fp):\n            dir_path = os.path.dirname(fp)\n            if dir_path:\n                os.makedirs(dir_path, exist_ok=True)\n            with open(fp, \"w\", encoding=\"utf-8\") as f:\n                f.write(\"# üÜï –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ —Å—Ç–≤–æ—Ä–µ–Ω–∏–π —Ñ–∞–π–ª\\n\")\n\n\n    # üîÅ fallback –¥–ª—è name, —è–∫—â–æ —î code, –∞–ª–µ –Ω–µ–º–∞—î name\n    if \"name\" not in parameters or not parameters[\"name\"]:\n        code_text = parameters.get(\"code\", \"\")\n        match = re.search(r\"def\\s+(\\w+)\", code_text)\n        if match:\n            parameters[\"name\"] = match.group(1)\n\n    cmd[\"parameters\"] = parameters\n    return cmd",
      ".\\handlers\\file_creation.py": "import os\nimport time\n\ndef handle_create_file(cmd, base_path=\".\"):\n    filename = cmd.get(\"filename\")\n    content = cmd.get(\"content\", \"\")\n    if not filename:\n        return {\"status\": \"error\", \"message\": \"‚ùå –ù–µ –≤–∫–∞–∑–∞–Ω–æ —ñ–º'—è —Ñ–∞–π–ª—É\"}\n\n    full_file_path = os.path.join(base_path, filename)\n\n    try:\n        with open(full_file_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(content)\n            f.flush()\n            os.fsync(f.fileno())  # üíæ –ó–∞–ø–∏—Å –Ω–∞ –¥–∏—Å–∫\n\n        time.sleep(0.1)  # ‚è≥ –î–∞—î–º–æ —á–∞—Å\n\n        return {\"status\": \"success\", \"message\": f\"‚úÖ Created file '{filename}'\"}\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": f\"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è —Å—Ç–≤–æ—Ä–∏—Ç–∏ —Ñ–∞–π–ª: {e}\"}\n\ndef handle_create_and_finalize_script(cmd, base_path=\".\"):\n    try:\n        script_name = cmd.get(\"file_path\") or cmd.get(\"parameters\", {}).get(\"file_path\")\n        script_content = cmd.get(\"content\") or cmd.get(\"parameters\", {}).get(\"content\")\n\n        if not script_name:\n            return {\"status\": \"error\", \"message\": \"‚ùå –ù–µ –≤–∫–∞–∑–∞–Ω–æ —ñ–º º—è —Å–∫—Ä–∏–ø—Ç—É (file_path)\"}\n\n        full_path = os.path.join(base_path, script_name)\n        os.makedirs(os.path.dirname(full_path), exist_ok=True)\n\n        with open(full_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(script_content or \"\")\n\n        # –§—ñ–Ω–∞–ª—ñ–∑–∞—Ü—ñ–π–Ω—ñ –¥—ñ—ó (–º–æ–∂–Ω–∞ –¥–æ–¥–∞—Ç–∏ –±—É–¥—å-—â–æ, –Ω–∞–ø—Ä–∏–∫–ª–∞–¥: chmod, –ª–æ–≥—É–≤–∞–Ω–Ω—è)\n\n        return {\"status\": \"success\", \"message\": f\"üéâ –°–∫—Ä–∏–ø—Ç —Å—Ç–≤–æ—Ä–µ–Ω–æ —Ç–∞ —Ñ—ñ–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–æ: {script_name}\"}\n\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": f\"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—ñ —Å–∫—Ä–∏–ø—Ç—É: {str(e)}\"}\n",
      ".\\handlers\\hello.py": "import json\nimport os\n\nprint(\"‚úÖ hello.py RUNNING\")\n\nresult = {\"parsed_result\": \"Hello\"}\noutput_path = os.path.abspath(\"last_result.json\")\nprint(f\"üì¶ Writing to: {output_path}\")\n\nwith open(output_path, \"w\", encoding=\"utf-8\") as f:\n    json.dump(result, f)\nprint(\"‚úÖ DONE writing last_result.json\")\n",
      ".\\handlers\\macro_builder.py": "# handlers/macro_builder.py\nimport json\nfrom config import API_KEY\nfrom openai import OpenAI\n\ndef handle_macro_build(cmd):\n    prompt = cmd.get(\"prompt\") or cmd.get(\"parameters\", {}).get(\"prompt\")\n    if not prompt:\n        return {\"status\": \"error\", \"message\": \"‚ùå –ù–µ –≤–∫–∞–∑–∞–Ω–æ prompt –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –º–∞–∫—Ä–æ—Å—É\"}\n\n    try:\n        client = OpenAI(api_key=API_KEY)\n\n        system_prompt = \"\"\"\n–¢–∏ –∞—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –º–∞–∫—Ä–æ–∫–æ–º–∞–Ω–¥ –¥–ª—è –∫–æ–¥—É–≤–∞–ª—å–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞.\n–ù–∞ –æ—Å–Ω–æ–≤—ñ –∑–∞–ø–∏—Ç—É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ —Å—Ç–≤–æ—Ä–∏ JSON-–º–∞—Å–∏–≤ macro-–∫—Ä–æ–∫—ñ–≤ —É —Ñ–æ—Ä–º–∞—Ç—ñ:\n\n[\n  {\"action\": \"create_file\", \"filename\": \"example.py\", \"content\": \"...\"},\n  {\"action\": \"update_code\", \"file_path\": \"example.py\", \"update_type\": \"logging\"},\n  {\"action\": \"run_python\", \"filename\": \"example.py\"}\n]\n\n–ü–æ–≤–µ—Ä–Ω–∏ –¢–Ü–õ–¨–ö–ò –º–∞—Å–∏–≤ JSON –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω—å.\n\"\"\"\n\n        response = client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=[\n                {\"role\": \"system\", \"content\": system_prompt},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n        )\n\n        steps = json.loads(response.choices[0].message.content.strip())\n\n        # üíæ –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —É —Ñ–∞–π–ª –¥–ª—è –Ω–∞–æ—á–Ω–æ—Å—Ç—ñ\n        with open(\"macro_output.json\", \"w\", encoding=\"utf-8\") as f:\n            json.dump(steps, f, indent=2, ensure_ascii=False)\n\n        return {\n            \"status\": \"success\",\n            \"message\": \"‚úÖ Macro-–∫—Ä–æ–∫–∏ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ\",\n            \"steps\": steps\n        }\n\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": f\"‚ùå –ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –º–∞–∫—Ä–æ–∫–æ–º–∞–Ω–¥–∏: {str(e)}\"}\n",
      ".\\handlers\\memory_manager.py": "# handlers/memory_manager.py\nimport json\nimport os\n\nMEMORY_PATH = \"long_term_memory.json\"\n\n\ndef load_memory():\n    if not os.path.exists(MEMORY_PATH):\n        return {\n            \"user_preferences\": [],\n            \"forbidden_behaviors\": [],\n            \"key_commands\": [],\n            \"reminders\": []\n        }\n    with open(MEMORY_PATH, \"r\", encoding=\"utf-8\") as f:\n        return json.load(f)\n\n\ndef save_memory(memory):\n    with open(MEMORY_PATH, \"w\", encoding=\"utf-8\") as f:\n        json.dump(memory, f, indent=2, ensure_ascii=False)\n\n\ndef remember_phrase(phrase):\n    memory = load_memory()\n    memory[\"reminders\"].append(phrase)\n    save_memory(memory)\n    return f\"üß† –ó–∞–ø–∞–º º—è—Ç–∞–≤: {phrase}\"\n\n\ndef recall_memory():\n    memory = load_memory()\n    return memory.get(\"reminders\", [])\n\n\ndef forget_phrase(phrase):\n    memory = load_memory()\n    if phrase in memory[\"reminders\"]:\n        memory[\"reminders\"].remove(phrase)\n    save_memory(memory)\n    return f\"üß† –ó–∞–±—É–≤: {phrase}\"\n\n\ndef is_forbidden_action(action):\n    memory = load_memory()\n    return action in memory.get(\"forbidden_behaviors\", [])\n",
      ".\\handlers\\retry_logic.py": "import os\nimport json\n\ndef handle_retry_last_action_with_fix(cmd, base_path=\".\"):\n    from .auto_fix import auto_fix_parameters\n    from gpt_agent_cache import handle_command\n\n    memory_file = os.path.join(base_path, \".ben_memory.json\")\n    if not os.path.exists(memory_file):\n        return {\"status\": \"error\", \"message\": \"‚ùå –§–∞–π–ª –ø–∞–º º—è—Ç—ñ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ\"}\n\n    with open(memory_file, \"r\", encoding=\"utf-8\") as f:\n        memory = json.load(f)\n\n    if not memory:\n        return {\"status\": \"error\", \"message\": \"‚ùå –ù–µ–º–∞—î –æ—Å—Ç–∞–Ω–Ω—å–æ—ó –¥—ñ—ó –¥–ª—è –ø–æ–≤—Ç–æ—Ä—É\"}\n\n    last_cmd = memory[-1]\n    fixed_cmd = auto_fix_parameters(last_cmd)\n\n    result = handle_command(fixed_cmd)\n    return {\n        \"status\": \"retry\",\n        \"original\": last_cmd,\n        \"fixed\": fixed_cmd,\n        \"result\": result\n    }\n",
      ".\\handlers\\run_python.py": "import os\nimport subprocess\nimport json\nimport time\n\ndef handle_run_python(cmd):\n    filename = cmd.get(\"filename\") or cmd.get(\"parameters\", {}).get(\"filename\")\n    if not filename:\n        return {\"status\": \"error\", \"message\": \"‚ùå –ù–µ –≤–∫–∞–∑–∞–Ω–æ —Ñ–∞–π–ª –¥–ª—è –≤–∏–∫–æ–Ω–∞–Ω–Ω—è\"}\n\n    full_file_path = os.path.abspath(filename)\n    if not os.path.exists(full_file_path):\n        return {\"status\": \"error\", \"message\": f\"‚ùå –§–∞–π–ª '{filename}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ\"}\n\n    try:\n        process = subprocess.run(\n            [\"python\", \"-u\", full_file_path],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            env={**os.environ, \"PYTHONUNBUFFERED\": \"1\"}\n        )\n\n        time.sleep(0.1)\n\n        parsed_result = \"\"\n        last_result_path = os.path.join(os.path.dirname(full_file_path), \"last_result.json\")\n\n        if os.path.exists(last_result_path):\n            try:\n                with open(last_result_path, \"r\", encoding=\"utf-8\") as f:\n                    data = json.load(f)\n                    parsed_result = data.get(\"parsed_result\", \"\")\n            except Exception as read_err:\n                print(f\"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —á–∏—Ç–∞–Ω–Ω—ñ last_result.json: {read_err}\")\n\n        return {\n            \"status\": \"success\" if process.returncode == 0 else \"error\",\n            \"results\": [{\"parsed_result\": parsed_result}] if parsed_result else [],\n            \"output\": process.stdout,\n            \"errors\": process.stderr\n        }\n\n    except Exception as e:\n        return {\n            \"status\": \"error\",\n            \"message\": f\"‚ùå –í–∏–Ω—è—Ç–æ–∫ –ø—Ä–∏ –≤–∏–∫–æ–Ω–∞–Ω–Ω—ñ: {e}\"\n        }\n",
      ".\\handlers\\scan_all.py": "import os\n\ndef handle_scan_all_files(params=None):\n    \"\"\"\n    –°–∫–∞–Ω—É—î –≤—Å—ñ .py —Ñ–∞–π–ª–∏ –≤ –ø–æ—Ç–æ—á–Ω—ñ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó —Ç–∞ –ø—ñ–¥–ø–∞–ø–∫–∞—Ö, –ø–æ–≤–µ—Ä—Ç–∞—î —Å–ª–æ–≤–Ω–∏–∫ {—à–ª—è—Ö: –≤–º—ñ—Å—Ç}\n    \"\"\"\n    result = {}\n    for root, _, files in os.walk(\".\"):\n        for file in files:\n            if file.endswith(\".py\"):\n                path = os.path.join(root, file)\n                try:\n                    with open(path, \"r\", encoding=\"utf-8\") as f:\n                        content = f.read()\n                    result[path] = content\n                except Exception as e:\n                    result[path] = f\"[ERROR reading file: {e}]\"\n    return {\n        \"status\": \"ok\",\n        \"message\": \"üìÇ –£—Å–ø—ñ—à–Ω–æ –ø—Ä–æ—Å–∫–∞–Ω–æ–≤–∞–Ω–æ –≤—Å—ñ —Ñ–∞–π–ª–∏\",\n        \"files\": result\n    }\n",
      ".\\handlers\\__init__.py": "",
      ".\\logic\\gpt_macro_engine.py": "import os\nimport json\nimport requests\n\nclass GPTMacroEngine:\n    def __init__(self, api_key=None):\n        self.api_key = api_key or os.getenv(\"OPENAI_API_KEY\")\n\n    def generate_macro(self, prompt):\n        api_url = \"https://api.openai.com/v1/chat/completions\"\n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        payload = {\n            \"model\": \"gpt-3.5-turbo\",\n            \"messages\": [\n                {\"role\": \"system\", \"content\": \"You generate macro steps in JSON for code automation.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ],\n            \"temperature\": 0.5\n        }\n\n        res = requests.post(api_url, headers=headers, json=payload)\n        res.raise_for_status()\n        content = res.json()[\"choices\"][0][\"message\"][\"content\"]\n        parsed = json.loads(content)\n        steps = parsed.get(\"steps\", parsed if isinstance(parsed, list) else [])\n        return steps",
      ".\\structure\\structure.py": "import pandas as pd\n\ndef detect_market_structure(df):\n    \"\"\"\n    –í–∏–∑–Ω–∞—á–∞—î –æ—Å—Ç–∞–Ω–Ω—é —Ä–∏–Ω–∫–æ–≤—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É:\n    HH, LH (–ø–æ high) –∞–±–æ LL, HL (–ø–æ low)\n    \"\"\"\n    df = df.copy()\n\n    # --- –í–∏–∑–Ω–∞—á–∞—î–º–æ –ª–æ–∫–∞–ª—å–Ω—ñ high/low\n    df[\"hh\"] = (df[\"high\"] > df[\"high\"].shift(1)) & (df[\"high\"] > df[\"high\"].shift(-1))\n    df[\"ll\"] = (df[\"low\"] < df[\"low\"].shift(1)) & (df[\"low\"] < df[\"low\"].shift(-1))\n\n    # --- –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ –∑–Ω–∞–π–¥–µ–Ω—ñ –ø—ñ–≤–æ—Ç–∏\n    last_high = None\n    last_low = None\n    structure = None\n\n    for i in range(len(df)):\n        if df[\"hh\"].iloc[i]:\n            current_high = df[\"high\"].iloc[i]\n            if last_high is None:\n                last_high = current_high\n                structure = \"HH\"\n            else:\n                structure = \"HH\" if current_high > last_high else \"LH\"\n                last_high = current_high\n\n        elif df[\"ll\"].iloc[i]:\n            current_low = df[\"low\"].iloc[i]\n            if last_low is None:\n                last_low = current_low\n                structure = \"LL\"\n            else:\n                structure = \"HL\" if current_low > last_low else \"LL\"\n                last_low = current_low\n\n    return structure if structure else \"‚ÑπÔ∏è –ù–µ–º–∞—î —Å—Ç—Ä—É–∫—Ç—É—Ä–∏\"\n",
      ".\\tests\\test_sync_check.py": "# üÜï –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ —Å—Ç–≤–æ—Ä–µ–Ω–∏–π —Ñ–∞–π–ª\n",
      ".\\utils\\greetings.py": "\ndef greet_user(name):\n    print(f\"Hello, {name}!\")\n",
      ".\\utils\\json_tools.py": "import re\n\ndef clean_json_text(text):\n    lines = text.splitlines()\n    cleaned_lines = []\n    for line in lines:\n        # –í–∏–¥–∞–ª—è—î // —Ç—ñ–ª—å–∫–∏ —è–∫—â–æ –Ω–µ –≤ –ª–∞–ø–∫–∞—Ö\n        in_string = False\n        new_line = \"\"\n        i = 0\n        while i < len(line):\n            if line[i] == '\"' and (i == 0 or line[i-1] != '\\\\'):\n                in_string = not in_string\n            if not in_string and line[i:i+2] == \"//\":\n                break  # –∫–æ–º–µ–Ω—Ç–∞—Ä –∑–∞ –º–µ–∂–∞–º–∏ —Ä—è–¥–∫–∞ ‚Äî –æ–±—Ä—ñ–∑–∞—î–º–æ\n            new_line += line[i]\n            i += 1\n        cleaned_lines.append(new_line)\n    return \"\\n\".join(cleaned_lines)\n",
      ".\\utils\\log_utils.py": "import os\nfrom datetime import datetime, timezone\nfrom config import history_file\n\ndef log_action(message: str):\n    \"\"\"\n    –õ–æ–≥—É—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è —É —Ñ–∞–π–ª —ñ—Å—Ç–æ—Ä—ñ—ó –∑ —Ç–∞–π–º—à—Ç–∞–º–ø–æ–º —É UTC.\n    \"\"\"\n    timestamp = datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S\")\n    log_line = f\"[{timestamp}] {message}\\n\"\n\n    try:\n        with open(history_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(log_line)\n    except Exception as e:\n        print(f\"‚ö†Ô∏è Log write error: {e}\")\n"
    }
  }
]